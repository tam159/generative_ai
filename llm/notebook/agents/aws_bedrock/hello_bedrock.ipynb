{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-08T04:16:48.314482Z",
     "start_time": "2025-06-08T04:16:48.251442Z"
    }
   },
   "source": [
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import sys\n",
    "from botocore.exceptions import ClientError"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T04:16:49.045233Z",
     "start_time": "2025-06-08T04:16:49.034712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "4c5747b1c13ddfdb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T04:16:49.739318Z",
     "start_time": "2025-06-08T04:16:49.734481Z"
    }
   },
   "cell_type": "code",
   "source": "region = \"us-east-1\"",
   "id": "84cbbbce06130478",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Lists the available Amazon Bedrock models.",
   "id": "cc651e7e55fa3ffb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T04:16:50.460523Z",
     "start_time": "2025-06-08T04:16:50.452527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_foundation_models(bedrock_client):\n",
    "    \"\"\"\n",
    "    Gets a list of available Amazon Bedrock foundation models.\n",
    "\n",
    "    :return: The list of available bedrock foundation models.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = bedrock_client.list_foundation_models()\n",
    "        models = response[\"modelSummaries\"]\n",
    "        logger.info(\"Got %s foundation models.\", len(models))\n",
    "        return models\n",
    "\n",
    "    except ClientError:\n",
    "        logger.error(\"Couldn't list foundation models.\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Entry point for the example. Uses the AWS SDK for Python (Boto3)\n",
    "    to create an Amazon Bedrock client. Then lists the available Bedrock models\n",
    "    in the region set in the callers profile and credentials.\n",
    "    \"\"\"\n",
    "\n",
    "    bedrock_client = boto3.client(service_name=\"bedrock\", region_name=region)\n",
    "\n",
    "    fm_models = list_foundation_models(bedrock_client)\n",
    "    for model in fm_models:\n",
    "        print(f\"Model: {model['modelName']}\")\n",
    "        print(json.dumps(model, indent=2))\n",
    "        print(\"---------------------------\\n\")\n",
    "\n",
    "    logger.info(\"Done.\")"
   ],
   "id": "8259bf20d482bc99",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T04:16:53.890339Z",
     "start_time": "2025-06-08T04:16:52.202065Z"
    }
   },
   "cell_type": "code",
   "source": "main()",
   "id": "10fa24a46c5e8570",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in environment variables.\n",
      "INFO:__main__:Got 90 foundation models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Titan Text Large\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large\",\n",
      "  \"modelId\": \"amazon.titan-tg1-large\",\n",
      "  \"modelName\": \"Titan Text Large\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Image Generator G1\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1:0\",\n",
      "  \"modelId\": \"amazon.titan-image-generator-v1:0\",\n",
      "  \"modelName\": \"Titan Image Generator G1\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Image Generator G1\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1\",\n",
      "  \"modelId\": \"amazon.titan-image-generator-v1\",\n",
      "  \"modelName\": \"Titan Image Generator G1\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Image Generator G1 v2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v2:0\",\n",
      "  \"modelId\": \"amazon.titan-image-generator-v2:0\",\n",
      "  \"modelName\": \"Titan Image Generator G1 v2\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\",\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Premier\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:8k\",\n",
      "  \"modelId\": \"amazon.nova-premier-v1:0:8k\",\n",
      "  \"modelName\": \"Nova Premier\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Premier\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:20k\",\n",
      "  \"modelId\": \"amazon.nova-premier-v1:0:20k\",\n",
      "  \"modelName\": \"Nova Premier\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Premier\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:1000k\",\n",
      "  \"modelId\": \"amazon.nova-premier-v1:0:1000k\",\n",
      "  \"modelName\": \"Nova Premier\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Premier\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:mm\",\n",
      "  \"modelId\": \"amazon.nova-premier-v1:0:mm\",\n",
      "  \"modelName\": \"Nova Premier\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Premier\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-premier-v1:0\",\n",
      "  \"modelName\": \"Nova Premier\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text G1 - Premier\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-premier-v1:0\",\n",
      "  \"modelId\": \"amazon.titan-text-premier-v1:0\",\n",
      "  \"modelName\": \"Titan Text G1 - Premier\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Pro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0:24k\",\n",
      "  \"modelId\": \"amazon.nova-pro-v1:0:24k\",\n",
      "  \"modelName\": \"Nova Pro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Pro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0:300k\",\n",
      "  \"modelId\": \"amazon.nova-pro-v1:0:300k\",\n",
      "  \"modelName\": \"Nova Pro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\",\n",
      "    \"DISTILLATION\",\n",
      "    \"PREFERENCE_FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Pro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-pro-v1:0\",\n",
      "  \"modelName\": \"Nova Pro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\",\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Lite\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0:24k\",\n",
      "  \"modelId\": \"amazon.nova-lite-v1:0:24k\",\n",
      "  \"modelName\": \"Nova Lite\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Lite\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0:300k\",\n",
      "  \"modelId\": \"amazon.nova-lite-v1:0:300k\",\n",
      "  \"modelName\": \"Nova Lite\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\",\n",
      "    \"DISTILLATION\",\n",
      "    \"PREFERENCE_FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Lite\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-lite-v1:0\",\n",
      "  \"modelName\": \"Nova Lite\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\",\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Canvas\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-canvas-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-canvas-v1:0\",\n",
      "  \"modelName\": \"Nova Canvas\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\",\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Reel\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-reel-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-reel-v1:0\",\n",
      "  \"modelName\": \"Nova Reel\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Reel\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-reel-v1:1\",\n",
      "  \"modelId\": \"amazon.nova-reel-v1:1\",\n",
      "  \"modelName\": \"Nova Reel\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Micro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0:24k\",\n",
      "  \"modelId\": \"amazon.nova-micro-v1:0:24k\",\n",
      "  \"modelName\": \"Nova Micro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Micro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0:128k\",\n",
      "  \"modelId\": \"amazon.nova-micro-v1:0:128k\",\n",
      "  \"modelName\": \"Nova Micro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\",\n",
      "    \"DISTILLATION\",\n",
      "    \"PREFERENCE_FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Micro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-micro-v1:0\",\n",
      "  \"modelName\": \"Nova Micro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\",\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Sonic\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-sonic-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-sonic-v1:0\",\n",
      "  \"modelName\": \"Nova Sonic\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"SPEECH\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"SPEECH\",\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text Embeddings v2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02\",\n",
      "  \"modelId\": \"amazon.titan-embed-g1-text-02\",\n",
      "  \"modelName\": \"Titan Text Embeddings v2\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text G1 - Lite\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k\",\n",
      "  \"modelId\": \"amazon.titan-text-lite-v1:0:4k\",\n",
      "  \"modelName\": \"Titan Text G1 - Lite\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\",\n",
      "    \"CONTINUED_PRE_TRAINING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text G1 - Lite\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1\",\n",
      "  \"modelId\": \"amazon.titan-text-lite-v1\",\n",
      "  \"modelName\": \"Titan Text G1 - Lite\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text G1 - Express\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k\",\n",
      "  \"modelId\": \"amazon.titan-text-express-v1:0:8k\",\n",
      "  \"modelName\": \"Titan Text G1 - Express\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\",\n",
      "    \"CONTINUED_PRE_TRAINING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text G1 - Express\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1\",\n",
      "  \"modelId\": \"amazon.titan-text-express-v1\",\n",
      "  \"modelName\": \"Titan Text G1 - Express\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Embeddings G1 - Text\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1:2:8k\",\n",
      "  \"modelId\": \"amazon.titan-embed-text-v1:2:8k\",\n",
      "  \"modelName\": \"Titan Embeddings G1 - Text\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Embeddings G1 - Text\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1\",\n",
      "  \"modelId\": \"amazon.titan-embed-text-v1\",\n",
      "  \"modelName\": \"Titan Embeddings G1 - Text\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text Embeddings V2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0:8k\",\n",
      "  \"modelId\": \"amazon.titan-embed-text-v2:0:8k\",\n",
      "  \"modelName\": \"Titan Text Embeddings V2\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text Embeddings V2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0\",\n",
      "  \"modelId\": \"amazon.titan-embed-text-v2:0\",\n",
      "  \"modelName\": \"Titan Text Embeddings V2\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Multimodal Embeddings G1\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0\",\n",
      "  \"modelId\": \"amazon.titan-embed-image-v1:0\",\n",
      "  \"modelName\": \"Titan Multimodal Embeddings G1\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Multimodal Embeddings G1\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1\",\n",
      "  \"modelId\": \"amazon.titan-embed-image-v1\",\n",
      "  \"modelName\": \"Titan Multimodal Embeddings G1\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: SDXL 1.0\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1:0\",\n",
      "  \"modelId\": \"stability.stable-diffusion-xl-v1:0\",\n",
      "  \"modelName\": \"SDXL 1.0\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: SDXL 1.0\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1\",\n",
      "  \"modelId\": \"stability.stable-diffusion-xl-v1\",\n",
      "  \"modelName\": \"SDXL 1.0\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Jamba-Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-instruct-v1:0\",\n",
      "  \"modelId\": \"ai21.jamba-instruct-v1:0\",\n",
      "  \"modelName\": \"Jamba-Instruct\",\n",
      "  \"providerName\": \"AI21 Labs\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Jamba 1.5 Large\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-large-v1:0\",\n",
      "  \"modelId\": \"ai21.jamba-1-5-large-v1:0\",\n",
      "  \"modelName\": \"Jamba 1.5 Large\",\n",
      "  \"providerName\": \"AI21 Labs\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Jamba 1.5 Mini\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-mini-v1:0\",\n",
      "  \"modelId\": \"ai21.jamba-1-5-mini-v1:0\",\n",
      "  \"modelName\": \"Jamba 1.5 Mini\",\n",
      "  \"providerName\": \"AI21 Labs\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude Instant\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1:2:100k\",\n",
      "  \"modelId\": \"anthropic.claude-instant-v1:2:100k\",\n",
      "  \"modelName\": \"Claude Instant\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude Instant\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1\",\n",
      "  \"modelId\": \"anthropic.claude-instant-v1\",\n",
      "  \"modelName\": \"Claude Instant\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:18k\",\n",
      "  \"modelId\": \"anthropic.claude-v2:0:18k\",\n",
      "  \"modelName\": \"Claude\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:100k\",\n",
      "  \"modelId\": \"anthropic.claude-v2:0:100k\",\n",
      "  \"modelName\": \"Claude\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:18k\",\n",
      "  \"modelId\": \"anthropic.claude-v2:1:18k\",\n",
      "  \"modelName\": \"Claude\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:200k\",\n",
      "  \"modelId\": \"anthropic.claude-v2:1:200k\",\n",
      "  \"modelName\": \"Claude\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1\",\n",
      "  \"modelId\": \"anthropic.claude-v2:1\",\n",
      "  \"modelName\": \"Claude\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2\",\n",
      "  \"modelId\": \"anthropic.claude-v2\",\n",
      "  \"modelName\": \"Claude\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Sonnet\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:28k\",\n",
      "  \"modelId\": \"anthropic.claude-3-sonnet-20240229-v1:0:28k\",\n",
      "  \"modelName\": \"Claude 3 Sonnet\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Sonnet\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:200k\",\n",
      "  \"modelId\": \"anthropic.claude-3-sonnet-20240229-v1:0:200k\",\n",
      "  \"modelName\": \"Claude 3 Sonnet\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Sonnet\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
      "  \"modelName\": \"Claude 3 Sonnet\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Haiku\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:48k\",\n",
      "  \"modelId\": \"anthropic.claude-3-haiku-20240307-v1:0:48k\",\n",
      "  \"modelName\": \"Claude 3 Haiku\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Haiku\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:200k\",\n",
      "  \"modelId\": \"anthropic.claude-3-haiku-20240307-v1:0:200k\",\n",
      "  \"modelName\": \"Claude 3 Haiku\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Haiku\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
      "  \"modelName\": \"Claude 3 Haiku\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Opus\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:12k\",\n",
      "  \"modelId\": \"anthropic.claude-3-opus-20240229-v1:0:12k\",\n",
      "  \"modelName\": \"Claude 3 Opus\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Opus\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:28k\",\n",
      "  \"modelId\": \"anthropic.claude-3-opus-20240229-v1:0:28k\",\n",
      "  \"modelName\": \"Claude 3 Opus\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Opus\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:200k\",\n",
      "  \"modelId\": \"anthropic.claude-3-opus-20240229-v1:0:200k\",\n",
      "  \"modelName\": \"Claude 3 Opus\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Opus\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-opus-20240229-v1:0\",\n",
      "  \"modelName\": \"Claude 3 Opus\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3.5 Sonnet\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
      "  \"modelName\": \"Claude 3.5 Sonnet\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\",\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3.5 Sonnet v2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
      "  \"modelName\": \"Claude 3.5 Sonnet v2\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3.7 Sonnet\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
      "  \"modelName\": \"Claude 3.7 Sonnet\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3.5 Haiku\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
      "  \"modelName\": \"Claude 3.5 Haiku\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude Opus 4\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-opus-4-20250514-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-opus-4-20250514-v1:0\",\n",
      "  \"modelName\": \"Claude Opus 4\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude Sonnet 4\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "  \"modelName\": \"Claude Sonnet 4\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Command\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14:7:4k\",\n",
      "  \"modelId\": \"cohere.command-text-v14:7:4k\",\n",
      "  \"modelName\": \"Command\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Command\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14\",\n",
      "  \"modelId\": \"cohere.command-text-v14\",\n",
      "  \"modelName\": \"Command\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Command R\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-v1:0\",\n",
      "  \"modelId\": \"cohere.command-r-v1:0\",\n",
      "  \"modelName\": \"Command R\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Command R+\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-plus-v1:0\",\n",
      "  \"modelId\": \"cohere.command-r-plus-v1:0\",\n",
      "  \"modelName\": \"Command R+\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Command Light\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14:7:4k\",\n",
      "  \"modelId\": \"cohere.command-light-text-v14:7:4k\",\n",
      "  \"modelName\": \"Command Light\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Command Light\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14\",\n",
      "  \"modelId\": \"cohere.command-light-text-v14\",\n",
      "  \"modelName\": \"Command Light\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Embed English\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3:0:512\",\n",
      "  \"modelId\": \"cohere.embed-english-v3:0:512\",\n",
      "  \"modelName\": \"Embed English\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Embed English\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3\",\n",
      "  \"modelId\": \"cohere.embed-english-v3\",\n",
      "  \"modelName\": \"Embed English\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Embed Multilingual\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3:0:512\",\n",
      "  \"modelId\": \"cohere.embed-multilingual-v3:0:512\",\n",
      "  \"modelName\": \"Embed Multilingual\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Embed Multilingual\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3\",\n",
      "  \"modelId\": \"cohere.embed-multilingual-v3\",\n",
      "  \"modelName\": \"Embed Multilingual\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: DeepSeek-R1\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/deepseek.r1-v1:0\",\n",
      "  \"modelId\": \"deepseek.r1-v1:0\",\n",
      "  \"modelName\": \"DeepSeek-R1\",\n",
      "  \"providerName\": \"DeepSeek\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3 8B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-8b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-8b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3 8B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3 70B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-70b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-70b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3 70B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.1 8B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-1-8b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-1-8b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.1 8B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.1 70B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-1-70b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-1-70b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.1 70B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.2 11B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-11b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-2-11b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.2 11B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.2 90B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-90b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-2-90b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.2 90B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.2 1B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-1b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-2-1b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.2 1B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.2 3B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-3b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-2-3b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.2 3B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.3 70B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-3-70b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-3-70b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.3 70B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 4 Scout 17B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-scout-17b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama4-scout-17b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 4 Scout 17B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 4 Maverick 17B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-maverick-17b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama4-maverick-17b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 4 Maverick 17B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Mistral 7B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-7b-instruct-v0:2\",\n",
      "  \"modelId\": \"mistral.mistral-7b-instruct-v0:2\",\n",
      "  \"modelName\": \"Mistral 7B Instruct\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Mixtral 8x7B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.mixtral-8x7b-instruct-v0:1\",\n",
      "  \"modelId\": \"mistral.mixtral-8x7b-instruct-v0:1\",\n",
      "  \"modelName\": \"Mixtral 8x7B Instruct\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Mistral Large (24.02)\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-large-2402-v1:0\",\n",
      "  \"modelId\": \"mistral.mistral-large-2402-v1:0\",\n",
      "  \"modelName\": \"Mistral Large (24.02)\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Mistral Small (24.02)\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-small-2402-v1:0\",\n",
      "  \"modelId\": \"mistral.mistral-small-2402-v1:0\",\n",
      "  \"modelName\": \"Mistral Small (24.02)\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Pixtral Large (25.02)\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.pixtral-large-2502-v1:0\",\n",
      "  \"modelId\": \"mistral.pixtral-large-2502-v1:0\",\n",
      "  \"modelName\": \"Pixtral Large (25.02)\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Done.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T04:16:54.971377Z",
     "start_time": "2025-06-08T04:16:54.968035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the model ID, e.g., Claude 3 Sonnet.\n",
    "model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\""
   ],
   "id": "884c8df33b0835c0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Invoke Anthropic Claude on Amazon Bedrock using Bedrock's Converse API",
   "id": "b458a9bac3b1877f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T04:16:59.790183Z",
     "start_time": "2025-06-08T04:16:57.233392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a Bedrock Runtime client in the AWS Region you want to use.\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "\n",
    "# Start a conversation with the user message.\n",
    "user_message = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}],\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Send the message to the model, using a basic inference configuration.\n",
    "    response = client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=conversation,\n",
    "        inferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\n",
    "    )\n",
    "\n",
    "    # Extract and print the response text.\n",
    "    response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "\n"
   ],
   "id": "9e68737e3fbedd84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \"hello world\" program serves as a simple introduction to a programming language by demonstrating the basic syntax needed to output text.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Invoke Anthropic Claude on Amazon Bedrock using Bedrock's Converse API with a response stream",
   "id": "a5ce17acfefbe784"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:19:41.777183Z",
     "start_time": "2025-05-28T12:19:39.891349Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 'hello world' program serves as a simple introduction to a programming language or environment by demonstrating basic syntax and output functionality."
     ]
    }
   ],
   "execution_count": 11,
   "source": [
    "# Use the Conversation API to send a text message to Anthropic Claude\n",
    "# and print the response stream.\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create a Bedrock Runtime client in the AWS Region you want to use.\n",
    "client = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "# Start a conversation with the user message.\n",
    "user_message = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}],\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Send the message to the model, using a basic inference configuration.\n",
    "    streaming_response = client.converse_stream(\n",
    "        modelId=model_id,\n",
    "        messages=conversation,\n",
    "        inferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\n",
    "    )\n",
    "\n",
    "    # Extract and print the streamed response text in real-time.\n",
    "    for chunk in streaming_response[\"stream\"]:\n",
    "        if \"contentBlockDelta\" in chunk:\n",
    "            text = chunk[\"contentBlockDelta\"][\"delta\"][\"text\"]\n",
    "            print(text, end=\"\")\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "\n"
   ],
   "id": "ffa7f3b4066a75d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Send and process a document with Anthropic Claude on Amazon Bedrock",
   "id": "999db66882418ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:24:38.285048Z",
     "start_time": "2025-05-28T12:24:27.000516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Send and process a document with Anthropic Claude on Amazon Bedrock.\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create a Bedrock Runtime client in the AWS Region you want to use.\n",
    "client = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "# Load the document\n",
    "with open(\"example-data/2022-Shareholder-Letter.pdf\", \"rb\") as file:\n",
    "    document_bytes = file.read()\n",
    "\n",
    "# Start a conversation with a user message and the document\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"text\": \"What's in this document?\"},\n",
    "            {\n",
    "                \"document\": {\n",
    "                    # Available formats: html, md, pdf, doc/docx, xls/xlsx, csv, and txt\n",
    "                    \"format\": \"pdf\",\n",
    "                    \"name\": \"2022-Shareholder-Letter\",\n",
    "                    \"source\": {\"bytes\": document_bytes},\n",
    "                }\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Send the message to the model, using a basic inference configuration.\n",
    "    response = client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=conversation,\n",
    "        inferenceConfig={\"maxTokens\": 500, \"temperature\": 0.3},\n",
    "    )\n",
    "\n",
    "    # Extract and print the response text.\n",
    "    response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)"
   ],
   "id": "8c54ad3ec38b67bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document is the 2022 shareholder letter from Amazon's CEO Andy Jassy. The letter provides an overview of Amazon's performance, challenges, and strategic priorities in 2022, as well as outlining the company's future plans and investments. Key points include:\n",
      "\n",
      "1. Reflection on 2022's macroeconomic challenges and Amazon's response\n",
      "2. Discussion of cost optimization efforts and structural changes in fulfillment networks\n",
      "3. Updates on major business segments like AWS, Advertising, and International expansion\n",
      "4. Information on new and growing initiatives like Amazon Healthcare and Project Kuiper\n",
      "5. Emphasis on long-term investments in areas like Generative AI and Large Language Models\n",
      "6. Reaffirmation of Amazon's customer-centric approach and long-term focus\n",
      "\n",
      "The letter also includes a reprint of Amazon's original 1997 shareholder letter, which outlines the company's foundational principles and long-term orientation.\n",
      "\n",
      "Overall, the document provides insight into Amazon's current state, future direction, and ongoing commitment to innovation and customer service.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conversation with Text using Converse API and model specific parameters",
   "id": "a928e6e7d414d731"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:27:07.236352Z",
     "start_time": "2025-05-28T12:27:07.227740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_conversation(bedrock_client,\n",
    "                          model_id,\n",
    "                          system_prompts,\n",
    "                          messages):\n",
    "    \"\"\"\n",
    "    Sends messages to a model.\n",
    "    Args:\n",
    "        bedrock_client: The Boto3 Bedrock runtime client.\n",
    "        model_id (str): The model ID to use.\n",
    "        system_prompts (JSON) : The system prompts for the model to use.\n",
    "        messages (JSON) : The messages to send to the model.\n",
    "\n",
    "    Returns:\n",
    "        response (JSON): The conversation that the model generated.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Generating message with model {model_id}')\n",
    "\n",
    "    # Inference parameters to use.\n",
    "    temperature = 0.5\n",
    "    top_k = 200\n",
    "\n",
    "    # Base inference parameters to use which are common across all FMs.\n",
    "    inference_config = {\"temperature\": temperature}\n",
    "\n",
    "    # Additional inference parameters to use for Anthropic Claude Models.\n",
    "    additional_model_fields = {\"top_k\": top_k}\n",
    "\n",
    "    # Send the message.\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        system=system_prompts,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields\n",
    "    )\n",
    "\n",
    "    # Log token usage.\n",
    "    token_usage = response['usage']\n",
    "    print(f\"Input tokens: {token_usage['inputTokens']}\")\n",
    "    print(f\"Output tokens: {token_usage['outputTokens']}\")\n",
    "    print(f\"Total tokens: {token_usage['totalTokens']}\")\n",
    "    print(f\"Stop reason: {response['stopReason']}\")\n",
    "\n",
    "    return response"
   ],
   "id": "c22c39649061efa7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:27:22.418849Z",
     "start_time": "2025-05-28T12:27:18.319739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup the system prompts and messages to send to the model.\n",
    "system_prompts = [{\"text\": \"You are an app that creates playlists for a radio station that plays rock and pop music.\"\n",
    "                    \"Only return song names and the artist.\"}]\n",
    "message_1 = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"Create a list of 3 pop songs.\"}]\n",
    "}\n",
    "message_2 = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"Make sure the songs are by artists from the United Kingdom.\"}]\n",
    "}\n",
    "messages = []\n",
    "\n",
    "try:\n",
    "\n",
    "    bedrock_client = boto3.client(service_name='bedrock-runtime', region_name = region)\n",
    "\n",
    "    # Start the conversation with the 1st message.\n",
    "    messages.append(message_1)\n",
    "    response = generate_conversation(\n",
    "        bedrock_client, model_id, system_prompts, messages)\n",
    "\n",
    "    # Add the response message to the conversation.\n",
    "    output_message = response['output']['message']\n",
    "    messages.append(output_message)\n",
    "\n",
    "    # Continue the conversation with the 2nd message.\n",
    "    messages.append(message_2)\n",
    "    response = generate_conversation(\n",
    "        bedrock_client, model_id, system_prompts, messages)\n",
    "\n",
    "    output_message = response['output']['message']\n",
    "    messages.append(output_message)\n",
    "\n",
    "    # Show the complete conversation.\n",
    "    for message in messages:\n",
    "        print(f\"Role: {message['role']}\")\n",
    "        for content in message['content']:\n",
    "            print(f\"Text: {content['text']}\")\n",
    "        print()\n",
    "\n",
    "except ClientError as err:\n",
    "    message = err.response['Error']['Message']\n",
    "    print(f\"A client error occured: {message}\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        f\"Finished generating text with model {model_id}.\")"
   ],
   "id": "4df23a5c800ff8e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating message with model anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Input tokens: 45\n",
      "Output tokens: 55\n",
      "Total tokens: 100\n",
      "Stop reason: end_turn\n",
      "Generating message with model anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Input tokens: 115\n",
      "Output tokens: 71\n",
      "Total tokens: 186\n",
      "Stop reason: end_turn\n",
      "Role: user\n",
      "Text: Create a list of 3 pop songs.\n",
      "\n",
      "Role: assistant\n",
      "Text: Here's a list of 3 pop songs:\n",
      "\n",
      "1. \"As It Was\" by Harry Styles\n",
      "2. \"Blinding Lights\" by The Weeknd\n",
      "3. \"Shape of You\" by Ed Sheeran\n",
      "\n",
      "Role: user\n",
      "Text: Make sure the songs are by artists from the United Kingdom.\n",
      "\n",
      "Role: assistant\n",
      "Text: I apologize for the oversight. Here's a list of 3 pop songs by artists from the United Kingdom:\n",
      "\n",
      "1. \"Watermelon Sugar\" by Harry Styles\n",
      "2. \"Someone You Loved\" by Lewis Capaldi\n",
      "3. \"Don't Start Now\" by Dua Lipa\n",
      "\n",
      "Finished generating text with model anthropic.claude-3-5-sonnet-20240620-v1:0.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conversation with Image using Converse API",
   "id": "daecba6bfad439ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:27:50.608940Z",
     "start_time": "2025-05-28T12:27:50.601355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def image_conversation(bedrock_client,\n",
    "                          model_id,\n",
    "                          input_text,\n",
    "                          input_image):\n",
    "    \"\"\"\n",
    "    Sends a message to a model.\n",
    "    Args:\n",
    "        bedrock_client: The Boto3 Bedrock runtime client.\n",
    "        model_id (str): The model ID to use.\n",
    "        input text : The input message.\n",
    "        input_image : The input image.\n",
    "\n",
    "    Returns:\n",
    "        response (JSON): The conversation that the model generated.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Generating message with model {model_id}\")\n",
    "\n",
    "    # Message to send.\n",
    "\n",
    "    with open(input_image, \"rb\") as f:\n",
    "        image = f.read()\n",
    "\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": input_text\n",
    "            },\n",
    "            {\n",
    "                    \"image\": {\n",
    "                        \"format\": 'jpeg',\n",
    "                        \"source\": {\n",
    "                            \"bytes\": image\n",
    "                        }\n",
    "                    }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    messages = [message]\n",
    "\n",
    "    # Send the message.\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response"
   ],
   "id": "4cbb18d0bd26182d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:28:23.163561Z",
     "start_time": "2025-05-28T12:28:15.269428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_text = \"What's in this image?\"\n",
    "input_image = \"example-data/sample_image.jpg\"\n",
    "\n",
    "try:\n",
    "\n",
    "    bedrock_client = boto3.client(service_name=\"bedrock-runtime\", region_name = region)\n",
    "\n",
    "    response = image_conversation(\n",
    "        bedrock_client, model_id, input_text, input_image)\n",
    "\n",
    "    output_message = response['output']['message']\n",
    "\n",
    "    print(f\"Role: {output_message['role']}\")\n",
    "\n",
    "    for content in output_message['content']:\n",
    "        print(f\"Text: {content['text']}\")\n",
    "\n",
    "    token_usage = response['usage']\n",
    "    print(f\"Input tokens:  {token_usage['inputTokens']}\")\n",
    "    print(f\"Output tokens:  {token_usage['outputTokens']}\")\n",
    "    print(f\"Total tokens:  {token_usage['totalTokens']}\")\n",
    "    print(f\"Stop reason: {response['stopReason']}\")\n",
    "\n",
    "except ClientError as err:\n",
    "    message = err.response['Error']['Message']\n",
    "    logger.error(\"A client error occurred: %s\", message)\n",
    "    print(f\"A client error occured: {message}\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        f\"Finished generating text with model {model_id}.\")"
   ],
   "id": "1b1b55a3b25c6172",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating message with model anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Role: assistant\n",
      "Text: This image shows a group of nine dogs sitting together in a grassy field. The dogs are of various breeds and colors, including what appear to be border collies, terriers, and possibly a shepherd mix. They're arranged in a line, facing the camera, with a beautiful green field and colorful flowers in the background. Some of the dogs have their tongues out, giving them a happy, friendly appearance. The scene looks idyllic, with the lush grass and wildflowers creating a picturesque setting for this diverse group of canines. It's a charming portrait that showcases the variety and beauty of different dog breeds.\n",
      "Input tokens:  1048\n",
      "Output tokens:  136\n",
      "Total tokens:  1184\n",
      "Stop reason: end_turn\n",
      "Finished generating text with model anthropic.claude-3-5-sonnet-20240620-v1:0.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# A tool use demo illustrating how to connect AI models on Amazon Bedrock with a custom tool or API",
   "id": "d6187869fe802ce2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "This demo illustrates a tool use scenario using Amazon Bedrock's Converse API and a weather tool.\n",
    "The script interacts with a foundation model on Amazon Bedrock to provide weather information based on user\n",
    "input. It uses the Open-Meteo API (https://open-meteo.com) to retrieve current weather data for a given location.\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "import logging\n",
    "from enum import Enum\n",
    "\n",
    "import utils.tool_use_print_utils as output\n",
    "import weather_tool\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n",
    "\n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "\n",
    "# For the most recent list of models supported by the Converse API's tool use functionality, visit:\n",
    "# https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html\n",
    "class SupportedModels(Enum):\n",
    "    CLAUDE_OPUS = \"anthropic.claude-3-opus-20240229-v1:0\"\n",
    "    CLAUDE_SONNET = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    CLAUDE_HAIKU = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "    COHERE_COMMAND_R = \"cohere.command-r-v1:0\"\n",
    "    COHERE_COMMAND_R_PLUS = \"cohere.command-r-plus-v1:0\"\n",
    "\n",
    "\n",
    "# Set the model ID, e.g., Claude 3 Haiku.\n",
    "MODEL_ID = SupportedModels.CLAUDE_HAIKU.value\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a weather assistant that provides current weather data for user-specified locations using only\n",
    "the Weather_Tool, which expects latitude and longitude. Infer the coordinates from the location yourself.\n",
    "If the user provides coordinates, infer the approximate location and refer to it in your response.\n",
    "To use the tool, you strictly apply the provided tool specification.\n",
    "\n",
    "- Explain your step-by-step process, and give brief updates before each step.\n",
    "- Only use the Weather_Tool for data. Never guess or make up information.\n",
    "- Repeat the tool use for subsequent requests if necessary.\n",
    "- If the tool errors, apologize, explain weather is unavailable, and suggest other options.\n",
    "- Report temperatures in C (F) and wind in km/h (mph). Keep weather reports concise. Sparingly use\n",
    "  emojis where appropriate.\n",
    "- Only respond to weather queries. Remind off-topic users of your purpose.\n",
    "- Never claim to search online, access external data, or use tools besides Weather_Tool.\n",
    "- Complete the entire process until you have all required data before sending the complete response.\n",
    "\"\"\"\n",
    "\n",
    "# The maximum number of recursive calls allowed in the tool_use_demo function.\n",
    "# This helps prevent infinite loops and potential performance issues.\n",
    "MAX_RECURSIONS = 5\n",
    "\n",
    "\n",
    "class ToolUseDemo:\n",
    "    \"\"\"\n",
    "    Demonstrates the tool use feature with the Amazon Bedrock Converse API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Prepare the system prompt\n",
    "        self.system_prompt = [{\"text\": SYSTEM_PROMPT}]\n",
    "\n",
    "        # Prepare the tool configuration with the weather tool's specification\n",
    "        self.tool_config = {\"tools\": [weather_tool.get_tool_spec()]}\n",
    "\n",
    "        # Create a Bedrock Runtime client in the specified AWS Region.\n",
    "        self.bedrockRuntimeClient = boto3.client(\n",
    "            \"bedrock-runtime\", region_name=AWS_REGION\n",
    "        )\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Starts the conversation with the user and handles the interaction with Bedrock.\n",
    "        \"\"\"\n",
    "        # Print the greeting and a short user guide\n",
    "        output.header()\n",
    "\n",
    "        # Start with an emtpy conversation\n",
    "        conversation = []\n",
    "\n",
    "        # Get the first user input\n",
    "        user_input = self._get_user_input()\n",
    "\n",
    "        while user_input is not None:\n",
    "            # Create a new message with the user input and append it to the conversation\n",
    "            message = {\"role\": \"user\", \"content\": [{\"text\": user_input}]}\n",
    "            conversation.append(message)\n",
    "\n",
    "            # Send the conversation to Amazon Bedrock\n",
    "            bedrock_response = self._send_conversation_to_bedrock(conversation)\n",
    "\n",
    "            # Recursively handle the model's response until the model has returned\n",
    "            # its final response or the recursion counter has reached 0\n",
    "            self._process_model_response(\n",
    "                bedrock_response, conversation, max_recursion=MAX_RECURSIONS\n",
    "            )\n",
    "\n",
    "            # Repeat the loop until the user decides to exit the application\n",
    "            user_input = self._get_user_input()\n",
    "\n",
    "        output.footer()\n",
    "\n",
    "    def _send_conversation_to_bedrock(self, conversation):\n",
    "        \"\"\"\n",
    "        Sends the conversation, the system prompt, and the tool spec to Amazon Bedrock, and returns the response.\n",
    "\n",
    "        :param conversation: The conversation history including the next message to send.\n",
    "        :return: The response from Amazon Bedrock.\n",
    "        \"\"\"\n",
    "        output.call_to_bedrock(conversation)\n",
    "\n",
    "        # Send the conversation, system prompt, and tool configuration, and return the response\n",
    "        return self.bedrockRuntimeClient.converse(\n",
    "            modelId=MODEL_ID,\n",
    "            messages=conversation,\n",
    "            system=self.system_prompt,\n",
    "            toolConfig=self.tool_config,\n",
    "        )\n",
    "\n",
    "    def _process_model_response(\n",
    "        self, model_response, conversation, max_recursion=MAX_RECURSIONS\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Processes the response received via Amazon Bedrock and performs the necessary actions\n",
    "        based on the stop reason.\n",
    "\n",
    "        :param model_response: The model's response returned via Amazon Bedrock.\n",
    "        :param conversation: The conversation history.\n",
    "        :param max_recursion: The maximum number of recursive calls allowed.\n",
    "        \"\"\"\n",
    "\n",
    "        if max_recursion <= 0:\n",
    "            # Stop the process, the number of recursive calls could indicate an infinite loop\n",
    "            logging.warning(\n",
    "                \"Warning: Maximum number of recursions reached. Please try again.\"\n",
    "            )\n",
    "            exit(1)\n",
    "\n",
    "        # Append the model's response to the ongoing conversation\n",
    "        message = model_response[\"output\"][\"message\"]\n",
    "        conversation.append(message)\n",
    "\n",
    "        if model_response[\"stopReason\"] == \"tool_use\":\n",
    "            # If the stop reason is \"tool_use\", forward everything to the tool use handler\n",
    "            self._handle_tool_use(message, conversation, max_recursion)\n",
    "\n",
    "        if model_response[\"stopReason\"] == \"end_turn\":\n",
    "            # If the stop reason is \"end_turn\", print the model's response text, and finish the process\n",
    "            output.model_response(message[\"content\"][0][\"text\"])\n",
    "            return\n",
    "\n",
    "    def _handle_tool_use(\n",
    "        self, model_response, conversation, max_recursion=MAX_RECURSIONS\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Handles the tool use case by invoking the specified tool and sending the tool's response back to Bedrock.\n",
    "        The tool response is appended to the conversation, and the conversation is sent back to Amazon Bedrock for further processing.\n",
    "\n",
    "        :param model_response: The model's response containing the tool use request.\n",
    "        :param conversation: The conversation history.\n",
    "        :param max_recursion: The maximum number of recursive calls allowed.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize an empty list of tool results\n",
    "        tool_results = []\n",
    "\n",
    "        # The model's response can consist of multiple content blocks\n",
    "        for content_block in model_response[\"content\"]:\n",
    "            if \"text\" in content_block:\n",
    "                # If the content block contains text, print it to the console\n",
    "                output.model_response(content_block[\"text\"])\n",
    "\n",
    "            if \"toolUse\" in content_block:\n",
    "                # If the content block is a tool use request, forward it to the tool\n",
    "                tool_response = self._invoke_tool(content_block[\"toolUse\"])\n",
    "\n",
    "                # Add the tool use ID and the tool's response to the list of results\n",
    "                tool_results.append(\n",
    "                    {\n",
    "                        \"toolResult\": {\n",
    "                            \"toolUseId\": (tool_response[\"toolUseId\"]),\n",
    "                            \"content\": [{\"json\": tool_response[\"content\"]}],\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Embed the tool results in a new user message\n",
    "        message = {\"role\": \"user\", \"content\": tool_results}\n",
    "\n",
    "        # Append the new message to the ongoing conversation\n",
    "        conversation.append(message)\n",
    "\n",
    "        # Send the conversation to Amazon Bedrock\n",
    "        response = self._send_conversation_to_bedrock(conversation)\n",
    "\n",
    "        # Recursively handle the model's response until the model has returned\n",
    "        # its final response or the recursion counter has reached 0\n",
    "        self._process_model_response(response, conversation, max_recursion - 1)\n",
    "\n",
    "    def _invoke_tool(self, payload):\n",
    "        \"\"\"\n",
    "        Invokes the specified tool with the given payload and returns the tool's response.\n",
    "        If the requested tool does not exist, an error message is returned.\n",
    "\n",
    "        :param payload: The payload containing the tool name and input data.\n",
    "        :return: The tool's response or an error message.\n",
    "        \"\"\"\n",
    "        tool_name = payload[\"name\"]\n",
    "\n",
    "        if tool_name == \"Weather_Tool\":\n",
    "            input_data = payload[\"input\"]\n",
    "            output.tool_use(tool_name, input_data)\n",
    "\n",
    "            # Invoke the weather tool with the input data provided by\n",
    "            response = weather_tool.fetch_weather_data(input_data)\n",
    "        else:\n",
    "            error_message = (\n",
    "                f\"The requested tool with name '{tool_name}' does not exist.\"\n",
    "            )\n",
    "            response = {\"error\": \"true\", \"message\": error_message}\n",
    "\n",
    "        return {\"toolUseId\": payload[\"toolUseId\"], \"content\": response}\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_user_input(prompt=\"Your weather info request\"):\n",
    "        \"\"\"\n",
    "        Prompts the user for input and returns the user's response.\n",
    "        Returns None if the user enters 'x' to exit.\n",
    "\n",
    "        :param prompt: The prompt to display to the user.\n",
    "        :return: The user's input or None if the user chooses to exit.\n",
    "        \"\"\"\n",
    "        output.separator()\n",
    "        user_input = input(f\"{prompt} (x to exit): \")\n",
    "\n",
    "        if user_input == \"\":\n",
    "            prompt = \"Please enter your weather info request, e.g. the name of a city\"\n",
    "            return ToolUseDemo._get_user_input(prompt)\n",
    "\n",
    "        elif user_input.lower() == \"x\":\n",
    "            return None\n",
    "\n",
    "        else:\n",
    "            return user_input\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tool_use_demo = ToolUseDemo()\n",
    "    tool_use_demo.run()\n",
    "\n"
   ],
   "id": "52da1c4dfe708821"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
