{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:32:16.699296Z",
     "start_time": "2025-02-02T15:32:16.195489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "from dotenv import load_dotenv"
   ],
   "id": "8ad15ff92cdd33",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:32:16.723060Z",
     "start_time": "2025-02-02T15:32:16.712108Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "18ad11d6c7abef90",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:33:38.848759Z",
     "start_time": "2025-02-02T15:33:38.842353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "api_key = os.getenv(\"NVIDIA_API_KEY\")\n",
    "api_key2 = os.getenv(\"NGC_PERSONAL_KEY\")\n",
    "api_key3 = os.getenv(\"NGC_API_KEY\")"
   ],
   "id": "12a459a70d9657d8",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-02T15:34:18.950368Z",
     "start_time": "2025-02-02T15:34:18.947648Z"
    }
   },
   "source": [
    "client = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.1-405b-instruct\",\n",
    "  api_key=api_key2,\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:34:21.318176Z",
     "start_time": "2025-02-02T15:34:19.318078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in client.stream([{\"role\":\"user\",\"content\":\"Write a limerick about the wonders of GPU computing.\"}]):\n",
    "  print(chunk.content, end=\"\")"
   ],
   "id": "91212fd2ab1b2ab0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a limerick about GPU computing:\n",
      "\n",
      "There once was a GPU so fine,\n",
      "Whose parallel processing was divine.\n",
      "It crunched with great zest,\n",
      "Through data at rest,\n",
      "And made complex tasks truly shine."
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:33:00.938340Z",
     "start_time": "2025-02-02T15:33:00.935044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = ChatNVIDIA(\n",
    "  model=\"nvidia/nemotron-4-340b-instruct\",\n",
    "  api_key=api_key2,\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")"
   ],
   "id": "d9ced09fa6aa4cc7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:33:13.539154Z",
     "start_time": "2025-02-02T15:33:02.492610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in client.stream([{\"role\":\"user\",\"content\":\"Write a limerick about the wonders of GPU computing.\"}]):\n",
    "  print(chunk.content, end=\"\")"
   ],
   "id": "51d081a295be9e1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of computing, where data's the king,\n",
      "GPU power makes everything sing.\n",
      "Parallel processing, so neat,\n",
      "Makes complex tasks a treat,\n",
      "A wonder of tech, it's truly a thing!\n",
      "\n",
      "With thousands of cores, in silicon etched,\n",
      "Through machine learning, they're well-matched.\n",
      "Nvidia, AMD, in the race,\n",
      "To accelerate every place,\n",
      "GPU computing, a marvel, is hatched.\n",
      "\n",
      "From gaming to AI, and scientific research,\n",
      "GPUs help us leap, not just lurch.\n",
      "So here's to the engineers, so bright,\n",
      "Who brought us this marvel, pure delight,\n",
      "GPU computing, a true gem, we search!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:33:21.638190Z",
     "start_time": "2025-02-02T15:33:21.632787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = ChatNVIDIA(\n",
    "  model=\"ai21labs/jamba-1.5-large-instruct\",\n",
    "  api_key=api_key2,\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")"
   ],
   "id": "e5eb3cc8d6b9cca5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:33:23.306016Z",
     "start_time": "2025-02-02T15:33:22.138284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in client.stream([{\"role\":\"user\",\"content\":\"Write a limerick about the wonders of GPU computing.\"}]):\n",
    "  print(chunk.content, end=\"\")"
   ],
   "id": "125131157ecc0646",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the realm of the digital scene,\n",
      "Where data flows like a vast, endless stream,\n",
      "GPUs blaze with might,\n",
      "Processing with light,\n",
      "Unleashing the power, a computing dream."
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:33:24.499893Z",
     "start_time": "2025-02-02T15:33:24.496549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = ChatNVIDIA(\n",
    "  model=\"mistralai/mixtral-8x22b-instruct-v0.1\",\n",
    "  api_key=api_key2,\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")"
   ],
   "id": "cf1415bea51585cf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:33:26.587114Z",
     "start_time": "2025-02-02T15:33:25.516649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in client.stream([{\"role\":\"user\",\"content\":\"Write a limerick about the wonders of GPU computing.\"}]):\n",
    "  print(chunk.content, end=\"\")"
   ],
   "id": "a6f5172aa05bddd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There once was a GPU so fine,\n",
      "In the world of compute, it did shine.\n",
      "With its parallel might,\n",
      "It processed with light,\n",
      "In the realm of data, it'd dine."
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:33:27.466148Z",
     "start_time": "2025-02-02T15:33:27.463190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = ChatNVIDIA(\n",
    "  model=\"01-ai/yi-large\",\n",
    "  api_key=api_key2,\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")"
   ],
   "id": "741858087e057b62",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:33:29.543119Z",
     "start_time": "2025-02-02T15:33:28.317990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in client.stream([{\"role\":\"user\",\"content\":\"Write a limerick about the wonders of GPU computing.\"}]):\n",
    "  print(chunk.content, end=\"\")"
   ],
   "id": "e8679ae36784197",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a lab with a GPU so grand,\n",
      "A scientist's work was no longer bland.\n",
      "With parallel might,\n",
      "Through the night, it did fight,\n",
      "Solving problems, making the future more bland."
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ad24b951489f354b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
