{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Group Chat with GPTAssistantAgent\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "In this notebook, we demonstrate how to get multiple `GPTAssistantAgent` converse through group chat.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install \"pyautogen==0.2.0b5\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T04:06:18.452600Z",
     "start_time": "2023-12-24T04:06:17.380990Z"
    }
   },
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-1106-preview\", \"gpt-4-32k\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well).\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": \"<your OpenAI API key>\",\n",
    "    },  # OpenAI API endpoint for gpt-4\n",
    "]\n",
    "```\n",
    "\n",
    "Currently Azure OpenAI does not support assistant api. You can set the value of config_list in any way you prefer. Please refer to this [notebook](https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb) for full code examples of the different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GPTAssistantAgent and GroupChat"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'model': 'gpt-4-1106-preview'}]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_list_gpt4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T04:06:55.408893Z",
     "start_time": "2023-12-24T04:06:55.392976Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T04:08:25.554396Z",
     "start_time": "2023-12-24T04:08:23.348380Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "assistant Coder does not exist, creating a new assistant\n",
      "assistant Data_analyst does not exist, creating a new assistant\n"
     ]
    }
   ],
   "source": [
    "from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent\n",
    "from autogen.agentchat import AssistantAgent\n",
    "\n",
    "# Define user proxy agent\n",
    "llm_config = {\"config_list\": config_list_gpt4, \"cache_seed\": 45}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "   name=\"User_proxy\",\n",
    "   system_message=\"A human admin.\",\n",
    "   code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n",
    "   human_input_mode=\"TERMINATE\"\n",
    ")\n",
    "\n",
    "# define two GPTAssistants\n",
    "coder = GPTAssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_gpt4,\n",
    "    },\n",
    "    instructions=AssistantAgent.DEFAULT_SYSTEM_MESSAGE\n",
    ")\n",
    "\n",
    "analyst = GPTAssistantAgent(\n",
    "    name=\"Data_analyst\",\n",
    "    instructions=\"You are a data analyst that offers insight into data.\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_gpt4,\n",
    "    },\n",
    ")\n",
    "# define group chat\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, analyst], messages=[], max_round=10)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Group Chat\n",
    "Now all is set, we can initiate group chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-24T04:11:22.160685Z",
     "start_time": "2023-12-24T04:10:05.682778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mUser_proxy\u001B[0m (to chat_manager):\n",
      "\n",
      "Get the number of issues and pull requests for the repository 'microsoft/autogen' over the past three weeks and offer analysis to the data. You should print the data in csv format grouped by weeks.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mCoder\u001B[0m (to chat_manager):\n",
      "\n",
      "First, we will need to fetch the data from GitHub's API for the 'microsoft/autogen' repository. To do this, we will write a Python script that makes requests to GitHub's API to retrieve the number of issues and pull requests created in the past three weeks. Once we have the data, we can group it by weeks and format it in CSV.\n",
      "\n",
      "Before writing the code, it is important to note that GitHub's API has a rate limit, and for unauthenticated requests, the rate limit allows for up to 60 requests per hour. If you haven't exceeded this limit, we can proceed with the script.\n",
      "\n",
      "Let's start by writing a Python script to fetch the required information:\n",
      "\n",
      "```python\n",
      "# filename: github_data_fetch.py\n",
      "import requests\n",
      "from datetime import datetime, timedelta\n",
      "import csv\n",
      "\n",
      "# Function to fetch the number of issues and pull requests for a given date range\n",
      "def fetch_data(repo, start_date, end_date):\n",
      "    # Endpoint for issues and pull requests\n",
      "    base_url = f\"https://api.github.com/repos/{repo}\"\n",
      "    issues_url = f\"{base_url}/issues\"\n",
      "    pulls_url = f\"{base_url}/pulls\"\n",
      "\n",
      "    # Parameters for filtering by date range and state\n",
      "    params = {\n",
      "        'since': start_date.isoformat(),\n",
      "        'state': 'all',\n",
      "    }\n",
      "\n",
      "    # Fetch issues and pull requests\n",
      "    issues_response = requests.get(issues_url, params=params)\n",
      "    pulls_response = requests.get(pulls_url, params=params)\n",
      "\n",
      "    issues = issues_response.json()\n",
      "    pulls = pulls_response.json()\n",
      "\n",
      "    return issues, pulls\n",
      "\n",
      "def filter_data_by_week(issues, pulls, weeks):\n",
      "    # Dictionary to hold week data\n",
      "    data_by_week = {week: {'issues': 0, 'pull_requests': 0} for week in weeks}\n",
      "\n",
      "    # Function to determine the week key for a given date\n",
      "    def get_week_key(date, weeks):\n",
      "        for week in weeks:\n",
      "            if week[0] <= date <= week[1]:\n",
      "                return week\n",
      "        return None\n",
      "\n",
      "    # Count issues and pull requests per week\n",
      "    for issue in issues:\n",
      "        created_at = datetime.strptime(issue['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
      "        week_key = get_week_key(created_at, weeks)\n",
      "        if week_key:\n",
      "            data_by_week[week_key]['issues'] += 1\n",
      "\n",
      "    for pr in pulls:\n",
      "        created_at = datetime.strptime(pr['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
      "        week_key = get_week_key(created_at, weeks)\n",
      "        if week_key:\n",
      "            data_by_week[week_key]['pull_requests'] += 1\n",
      "\n",
      "    return data_by_week\n",
      "\n",
      "def main():\n",
      "    # Constants\n",
      "    repo = 'microsoft/autogen'\n",
      "    today = datetime.now()\n",
      "    three_weeks_ago = today - timedelta(weeks=3)\n",
      "    \n",
      "    # Create a list of week ranges\n",
      "    weeks = [(three_weeks_ago + timedelta(weeks=i), three_weeks_ago + timedelta(weeks=i+1)-timedelta(seconds=1)) for i in range(3)]\n",
      "\n",
      "    # Fetch data\n",
      "    issues, pulls = fetch_data(repo, three_weeks_ago, today)\n",
      "    \n",
      "    # Filter the data by week\n",
      "    data_by_week = filter_data_by_week(issues, pulls, weeks)\n",
      "\n",
      "    # CSV output\n",
      "    csv_filename = 'github_data.csv'\n",
      "    with open(csv_filename, 'w', newline='') as file:\n",
      "        writer = csv.writer(file)\n",
      "        writer.writerow(['Week', 'Issues', 'Pull Requests'])\n",
      "        \n",
      "        for week, data in data_by_week.items():\n",
      "            start_date = week[0].strftime('%Y-%m-%d')\n",
      "            end_date = week[1].strftime('%Y-%m-%d')\n",
      "            writer.writerow([f\"{start_date} to {end_date}\", data['issues'], data['pull_requests']])\n",
      "\n",
      "main()\n",
      "```\n",
      "\n",
      "Make sure to run the above script to collect the data and create a CSV file. Since GitHub's API returns paginated results, we might need additional logic to handle pagination if the number of issues or pull requests exceed the per-page limit. However, for this exercise, we assume the number is within the limits.\n",
      "\n",
      "After you've executed the above script, it will write the fetched data into 'github_data.csv' file in the CSV format. We'll analyze the data afterwards.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mData_analyst\u001B[0m (to chat_manager):\n",
      "\n",
      "I apologize for the mistake, but I cannot directly execute codes or scripts or access external APIs as an AI developed by OpenAI. However, you can run the provided Python script yourself to collect the required data from the GitHub API. Make sure to check GitHub's documentation on authentication if you are making many requests to avoid rate limiting issues.\n",
      "\n",
      "Once you have the data in your CSV file after running the script, you could perform the analysis by looking at trends over the three-week period. You might ask questions such as:\n",
      "\n",
      "1. Is there an increase or decrease in the number of issues and pull requests over the weeks?\n",
      "2. Are issues being closed at the same rate as they are opened?\n",
      "3. What is the ratio of pull requests to issues? Is the community actively contributing more than reporting problems?\n",
      "4. If the number of pull requests is increasing, it might suggest an active development or improvement phase in the project.\n",
      "\n",
      "Performing such analysis would help you understand the activity and engagement within the 'microsoft/autogen' repository. You would need to plot graphs or calculate percentages to glean deeper insights from your data.\n",
      "\n",
      "Remember that the script provided here operates under a few assumptions, such as:\n",
      "- The repository 'microsoft/autogen' is public and accessible via the GitHub API without authentication.\n",
      "- The number of issues and pull requests created within the past three weeks is under the limit for unpaginated results from GitHub's API.\n",
      "- The Python script might need to be adjusted if the assumptions are incorrect or if you experience any API rate limits.\n",
      "\n",
      "If you require further analysis based on the actual data or have any other questions, feel free to provide the output CSV data, and I'll be able to assist you accordingly.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001B[0m\n",
      "\u001B[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "execute_code was called without specifying a value for use_docker. Since the python docker package is not available, code will be run natively. Note: this fallback behavior is subject to change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mUser_proxy\u001B[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001B[0m\n",
      "\u001B[33mUser_proxy\u001B[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mData_analyst\u001B[0m (to chat_manager):\n",
      "\n",
      "It appears that you may have attempted to run the code provided earlier but didn't share any output. Since I can't execute code or interact with external APIs, I'm unable to retrieve or directly present the output from the execution myself.\n",
      "\n",
      "If you have run the provided Python script, it should have produced a CSV file named 'github_data.csv' containing the data for the issues and pull requests by week. If you would like me to assist you with analyzing that data or have any other questions regarding data analysis, please summarize the content of the CSV file or describe how you would like to proceed further, and I'll be glad to help you interpret the information.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001B[0m\n",
      "\u001B[33mUser_proxy\u001B[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mData_analyst\u001B[0m (to chat_manager):\n",
      "\n",
      "It seems there might have been a confusion in our communication. If you have any questions, require assistance with a data analysis concept, or need information regarding GitHub, programming, or other topics, please let me know how I can assist you. If you need to analyze data, feel free to provide the dataset or describe the scenario, and I'd be happy to help you with the analysis.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mData_analyst\u001B[0m (to chat_manager):\n",
      "\n",
      "It appears you have tried to communicate with an empty message. If you have any data analysis requests, questions, or need clarification on any topic, please provide the necessary details, and I'll be glad to help you. If you've obtained any data that you wish to discuss or analyze, please share the details, and we can continue from there.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001B[0m\n",
      "\u001B[33mUser_proxy\u001B[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(manager, message=\"Get the number of issues and pull requests for the repository 'microsoft/autogen' over the past three weeks and offer analysis to the data. You should print the data in csv format grouped by weeks.\")\n",
    "# type exit to terminate the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
