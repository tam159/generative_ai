{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a1aae78-88a6-4133-b905-7e46c8e3772f",
   "metadata": {},
   "source": [
    "# Introduction to LangGraph\n",
    "\n",
    "In this tutorial, we will build a support chatbot in LangGraph that can:\n",
    "\n",
    "- Answer common questions by searching the web\n",
    "- Maintain conversation state across calls\n",
    "- Route complex queries to a human for review\n",
    "- Use custom state to control its behavior\n",
    "- Rewind and explore alternative conversation paths\n",
    "\n",
    "We'll start with a basic chatbot and progressively add more sophisticated capabilities, introducing key LangGraph concepts along the way.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "id": "6f11d631-8679-4f28-822f-cdf1f2ddc21c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:24.751241Z",
     "start_time": "2024-05-19T04:15:24.747292Z"
    }
   },
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install -U langgraph langsmith\n",
    "\n",
    "# Used for this tutorial; not a requirement for LangGraph\n",
    "# %pip install -U langchain_anthropic"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "a6d1e870-1bc0-4d44-86c0-96681ccf6113",
   "metadata": {},
   "source": [
    "Next, set your API keys:"
   ]
  },
  {
   "cell_type": "code",
   "id": "705d4020-6ee8-44cc-b1a5-8c34e7172fc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:31.261730Z",
     "start_time": "2024-05-19T04:15:31.259946Z"
    }
   },
   "source": [
    "# import getpass\n",
    "# import os\n",
    "\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"ANTHROPIC_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "a98c72cf-33f9-4a37-9634-6c93a7c28815",
   "metadata": {},
   "source": "(Encouraged) [LangSmith](https://smith.langchain.com/) makes it a lot easier to see what's going on \"under the hood.\""
  },
  {
   "cell_type": "code",
   "id": "13cba9af-0572-41df-92f8-d6f56d5b5322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:32.209318Z",
     "start_time": "2024-05-19T04:15:32.207640Z"
    }
   },
   "source": [
    "# _set_env(\"LANGSMITH_API_KEY\")\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Tutorial\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:32.876332Z",
     "start_time": "2024-05-19T04:15:32.871694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv"
   ],
   "id": "bb1530c74a495459",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:33.197904Z",
     "start_time": "2024-05-19T04:15:33.193775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "509cbee407e9d198",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "ef7bcad1-1274-4b7c-a2e9-365180ef3a31",
   "metadata": {},
   "source": [
    "## Part 1: Build a Basic Chatbot\n",
    "\n",
    "We'll first create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Though simple, it will illustrate the core concepts of building with LangGraph. By the end of this section, you will have a built rudimentary chatbot.\n",
    "\n",
    "Start by creating a `StateGraph`. A `StateGraph` object defines the structure of our chatbot as a \"state machine\". We'll add `nodes` to represent the llm and functions our chatbot can call and `edges` to specify how the bot should transition between these functions."
   ]
  },
  {
   "cell_type": "code",
   "id": "e58df974-7579-4f25-9d91-66389b94eba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:34.467087Z",
     "start_time": "2024-05-19T04:15:33.987450Z"
    }
   },
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "4137feed-746e-4c72-a34a-f7a699ad5dcf",
   "metadata": {},
   "source": [
    "**Notice** that we've defined our `State` as a TypedDict with a single key: `messages`. The `messages` key is annotated with the [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) function, which tells LangGraph to append new messages to the existing list, rather than overwriting it.\n",
    "\n",
    "So now our graph knows two things:\n",
    "\n",
    "1. Every `node` we define will receive the current `State` as input and return a value that updates that state.\n",
    "2. `messages` will be _appended_ to the current list, rather than directly overwritten. This is communicated via the prebuilt [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) function in the `Annotated` syntax.\n",
    "\n",
    "Next, add a \"`chatbot`\" node. Nodes represent units of work. They are typically regular python functions."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:57.576687Z",
     "start_time": "2024-05-19T04:15:57.173864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-4o\"\n",
    ")"
   ],
   "id": "604a79c63f446461",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:15:58.336156Z",
     "start_time": "2024-05-19T04:15:57.578797Z"
    }
   },
   "cell_type": "code",
   "source": "llm.invoke(\"hi\")",
   "id": "e961cce2cef14f6d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_729ea513f7', 'finish_reason': 'stop', 'logprobs': None}, id='run-753463a5-27d5-46de-b8d8-2a3c4c09e7a3-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "bc8c9137-8261-42ea-8e83-3590981d23e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:16:17.300334Z",
     "start_time": "2024-05-19T04:16:17.296918Z"
    }
   },
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "b6c1dcd9-fb86-4649-81b4-ff6ce20a2e46",
   "metadata": {},
   "source": [
    "**Notice** how the `chatbot` node function takes the current `State` as input and returns an updated `messages` list. This is the basic pattern for all LangGraph node functions.\n",
    "\n",
    "The `add_messages` function in our `State` will append the llm's response messages to whatever messages are already in the state.\n",
    "\n",
    "Next, add an `entry` point. This tells our graph **where to start its work** each time we run it."
   ]
  },
  {
   "cell_type": "code",
   "id": "e331e10d-ebcf-4144-9bd3-999b4d656dd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:16:25.059393Z",
     "start_time": "2024-05-19T04:16:25.057421Z"
    }
   },
   "source": [
    "graph_builder.set_entry_point(\"chatbot\")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "0499c318-d1e6-46fa-a652-8f9e65313355",
   "metadata": {},
   "source": [
    "Similarly, set a `finish` point. This instructs the graph **\"any time this node is run, you can exit.\"**"
   ]
  },
  {
   "cell_type": "code",
   "id": "075f0929-3591-4852-b2d3-eaadde40662d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:16:30.631637Z",
     "start_time": "2024-05-19T04:16:30.628689Z"
    }
   },
   "source": [
    "graph_builder.set_finish_point(\"chatbot\")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "65a9b88c-2c53-4d95-8eb1-d544a8946f65",
   "metadata": {},
   "source": [
    "Finally, we'll want to be able to run our graph. To do so, call \"`compile()`\" on the graph builder. This creates a \"`CompiledGraph`\" we can use invoke on our state."
   ]
  },
  {
   "cell_type": "code",
   "id": "0bb67a01-cf5c-4625-8c07-6e8c0af50fca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:16:31.641371Z",
     "start_time": "2024-05-19T04:16:31.639353Z"
    }
   },
   "source": [
    "graph = graph_builder.compile()"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "0c39407b-d6f6-48a4-b1f6-31fc7f88b275",
   "metadata": {},
   "source": [
    "You can visualize the graph using the `get_graph` method and one of the \"draw\" methods, like `draw_ascii` or `draw_png`. The `draw` methods each require additional dependencies."
   ]
  },
  {
   "cell_type": "code",
   "id": "32e4f36e-72ce-4ade-bd7e-94880e0d456b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:16:34.432263Z",
     "start_time": "2024-05-19T04:16:32.839639Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ],
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "a98097a3-a126-4081-b21e-697ec1185fff",
   "metadata": {},
   "source": [
    "Now let's run the chatbot! \n",
    "\n",
    "**Tip:** You can exit the chat loop at any time by typing \"quit\", \"exit\", or \"q\"."
   ]
  },
  {
   "cell_type": "code",
   "id": "7afb4c9a-7404-4e92-9945-36f372015f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:16:53.566884Z",
     "start_time": "2024-05-19T04:16:36.890817Z"
    }
   },
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": (\"user\", user_input)}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \"Tam\" could refer to a variety of people, characters, or things depending on the context. Here are a few possibilities:\n",
      "\n",
      "1. **Tam O'Shanter**: A character from a famous poem by Robert Burns, a Scottish poet. The poem tells the story of Tam, who encounters witches and other supernatural beings on his way home from a tavern.\n",
      "\n",
      "2. **Tam Lin**: A character from a Scottish folk ballad. Tam Lin is a young man captured by the Queen of the Fairies and later rescued by his true love, Janet.\n",
      "\n",
      "3. **Tam (short for Tamara or Tammy)**: A common given name that could refer to any number of people.\n",
      "\n",
      "4. **Tam (hat)**: A type of hat, often associated with Scottish culture, also known as a tam o'shanter.\n",
      "\n",
      "5. **Tam (abbreviation)**: Could be an abbreviation for various organizations, terms, or names, such as TAM Airlines (a Brazilian airline), Total Addressable Market (a business term), or others.\n",
      "\n",
      "If you have a specific context or additional information, I can provide a more precise answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! How can I assist you today?\n",
      "Goodbye!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "98e1cdb5-869a-41ea-9dab-e28cfc524499",
   "metadata": {},
   "source": [
    "**Congratulations!** You've built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a [LangSmith Trace](https://smith.langchain.com/public/29ab0177-1177-4d25-9341-17ae7d94e0e0/r) for the call above at the provided link.\n",
    "\n",
    "However, you may have noticed that the bot's knowledge is limited to what's in its training data. In the next part, we'll add a web search tool to expand the bot's knowledge and make it more capable.\n",
    "\n",
    "Below is the full code for this section for your reference:"
   ]
  },
  {
   "cell_type": "code",
   "id": "e014741f-cfad-4045-b6fa-ebd74ae93a5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:17:46.642343Z",
     "start_time": "2024-05-19T04:17:46.616460Z"
    }
   },
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "f22c5d4a-3134-413c-81fe-dd9752fbeb66",
   "metadata": {},
   "source": [
    "## Part 2: Enhancing the Chatbot with Tools\n",
    "\n",
    "To handle queries our chatbot can't answer \"from memory\", we'll integrate a web search tool. Our bot can use this tool to find relevant information and provide better responses.\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "Before we start, make sure you have the necessary packages installed and API keys set up:\n",
    "\n",
    "First, install the requirements to use the [Tavily Search Engine](https://python.langchain.com/docs/integrations/tools/tavily_search/), and set your [TAVILY_API_KEY](https://tavily.com/)."
   ]
  },
  {
   "cell_type": "code",
   "id": "7451151f-41fc-4af0-9359-024ae51b7225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:18:22.204251Z",
     "start_time": "2024-05-19T04:18:22.202572Z"
    }
   },
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install -U tavily-python"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "0c52923c-5665-4f8c-a1ba-9799e369c49e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:18:24.511862Z",
     "start_time": "2024-05-19T04:18:24.510115Z"
    }
   },
   "source": "# _set_env(\"TAVILY_API_KEY\")",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "591ce9ba-c431-4165-b815-25c944ef7cdb",
   "metadata": {},
   "source": [
    "Next, define the tool:"
   ]
  },
  {
   "cell_type": "code",
   "id": "35c8978e-c07d-4dd0-a97b-0ce3a723eea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:18:35.261618Z",
     "start_time": "2024-05-19T04:18:32.446157Z"
    }
   },
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://python.langchain.com/v0.1/docs/langgraph/',\n",
       "  'content': 'One of the central concepts of LangGraph is state. Each graph execution creates a state that is passed between nodes in the graph as they execute, and each node updates this internal state with its return value after it executes. The way that the graph updates its internal state is defined by either the type of graph chosen or a custom function.'},\n",
       " {'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
       "  'content': 'Nodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making ...'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "7f503f02-d23d-42e8-9b5d-eb2681b242f4",
   "metadata": {},
   "source": [
    "The results are page summaries our chat bot can use to answer questions.\n",
    "\n",
    "\n",
    "Next, we'll start defining our graph. The following is all **the same as in Part 1**, except we have added `bind_tools` on our LLM. This lets the LLM know the correct JSON format to use if it wants to use our search engine."
   ]
  },
  {
   "cell_type": "code",
   "id": "dc5af88b-47d2-43bf-9a2c-6c07506b1732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:20:43.217055Z",
     "start_time": "2024-05-19T04:20:43.147335Z"
    }
   },
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "d1e84cfc-b1b2-48e3-8550-152a408c3926",
   "metadata": {},
   "source": [
    "Next we need to create a function to actually run the tools if they are called. We'll do this by adding the tools to a new node.\n",
    "\n",
    "Below, implement a `BasicToolNode` that checks the most recent message in the state and calls tools if the message contains `tool_calls. It relies on the LLM's `tool_calling` support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\n",
    "\n",
    "We will later replace this with LangGraph's prebuilt [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode) to speed things up, but building it ourselves first is instructive."
   ]
  },
  {
   "cell_type": "code",
   "id": "12f1fc14-cd91-4cd4-9f2e-1d007f8beafc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:31:40.765993Z",
     "start_time": "2024-05-19T04:31:40.762500Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "b049afc4-7757-40ba-8e00-589d378e816d",
   "metadata": {},
   "source": [
    "With the tool node added, we can define the `conditional_edges`. \n",
    "\n",
    "Recall that **edges** route the control flow from one node to the next. **Conditional edges** usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph `state` and return a string or list of strings indicating which node(s) to call next.\n",
    "\n",
    "Below, call define a router function called `route_tools`, that checks for tool_calls in the chatbot's output. Provide this function to the graph by calling `add_conditional_edges`, which tells the graph that whenever the `chatbot` node completes to check this function to see where to go next. \n",
    "\n",
    "The condition will route to `action` if tool calls are present and \"`__end__`\" if not.\n",
    "\n",
    "Later, we will replace this with the prebuilt [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition) to be more concise, but implementing it ourselves first makes things more clear. "
   ]
  },
  {
   "cell_type": "code",
   "id": "d662df94-66ac-4c6c-92f0-4c93620f1c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:59:13.151998Z",
     "start_time": "2024-05-19T04:59:13.147699Z"
    }
   },
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    ") -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"Use in the conditional_edge to route to the ToolNode if the last message\n",
    "\n",
    "    has tool calls. Otherwise, route to the end.\"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"__end__\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "a2aa67c2-dd1b-4bf2-8c64-eea44296d15f",
   "metadata": {},
   "source": [
    "**Notice** that conditional edges start from a single node. This tells the graph \"any time the '`chatbot`' node runs, either go to 'action' if it calls a tool, or end the loop if it responds directly. \n",
    "\n",
    "The prebuilt `tools_condition` returns the \"`__end__`\" string if no tool calls are made. When the graph transitions to `__end__`, it has no more tasks to complete and ceases execution. Because the condition can return `__end__`, we don't need to explicitly set a `finish_point` this time. Our graph already has a way to finish!\n",
    "\n",
    "Let's visualize the graph we've built. The following function has some additional dependencies to run that are unimportant for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "id": "8b49509c-9d97-457c-a76a-c495fb30ccbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T05:05:56.496002Z",
     "start_time": "2024-05-19T05:05:54.925570Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ],
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "c59593ef-5073-4279-931e-828dae971f23",
   "metadata": {},
   "source": [
    "Now we can ask the bot questions outside its training data."
   ]
  },
  {
   "cell_type": "code",
   "id": "051dc374-67cc-4371-9dd1-221e07593148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T05:08:45.492451Z",
     "start_time": "2024-05-19T05:08:09.781595Z"
    }
   },
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "Assistant: [{\"url\": \"https://langchain-ai.github.io/langgraph/\", \"content\": \"LangGraph is framework agnostic (each node is a regular python function). It extends the core Runnable API (shared interface for streaming, async, and batch calls) to make it easy to: Seamless state management across multiple turns of conversation or tool usage. The ability to flexibly route between nodes based on dynamic criteria.\"}, {\"url\": \"https://blog.langchain.dev/langgraph-multi-agent-workflows/\", \"content\": \"As a part of the launch, we highlighted two simple runtimes: one that is the equivalent of the AgentExecutor in langchain, and a second that was a version of that aimed at message passing and chat models.\\n It's important to note that these three examples are only a few of the possible examples we could highlight - there are almost assuredly other examples out there and we look forward to seeing what the community comes up with!\\n LangGraph: Multi-Agent Workflows\\nLinks\\nLast week we highlighted LangGraph - a new package (available in both Python and JS) to better enable creation of LLM workflows containing cycles, which are a critical component of most agent runtimes. \\\"\\nAnother key difference between Autogen and LangGraph is that LangGraph is fully integrated into the LangChain ecosystem, meaning you take fully advantage of all the LangChain integrations and LangSmith observability.\\n As part of this launch, we're also excited to highlight a few applications built on top of LangGraph that utilize the concept of multiple agents.\\n\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: LangGraph is a framework-agnostic tool designed to facilitate the creation and management of complex workflows involving multiple agents, particularly in the context of language models and AI. Here are some key features and aspects of LangGraph:\n",
      "\n",
      "1. **Framework Agnostic**: Each node in LangGraph is a regular Python function, making it versatile and easy to integrate with various frameworks.\n",
      "2. **Core Runnable API**: It extends the core Runnable API, which provides a shared interface for streaming, asynchronous, and batch calls.\n",
      "3. **State Management**: LangGraph allows for seamless state management across multiple turns of conversation or tool usage.\n",
      "4. **Dynamic Routing**: It offers the ability to flexibly route between nodes based on dynamic criteria.\n",
      "5. **Multi-Agent Workflows**: LangGraph is designed to better enable the creation of LLM (Large Language Model) workflows containing cycles, which are critical for most agent runtimes.\n",
      "6. **Integration with LangChain**: LangGraph is fully integrated into the LangChain ecosystem, allowing users to take full advantage of all LangChain integrations and LangSmith observability.\n",
      "\n",
      "For more detailed information, you can visit the [LangGraph official page](https://langchain-ai.github.io/langgraph/) or read about its applications in [LangGraph: Multi-Agent Workflows](https://blog.langchain.dev/langgraph-multi-agent-workflows/).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "Assistant: [{\"url\": \"https://www.datacamp.com/tutorial/introduction-to-langsmith\", \"content\": \"How it Works, Use Cases, Alternatives & More\\nRichie Cotton\\nHow AI is Changing Cybersecurity with Brian Murphy, CEO of ReliaQuest\\nAdel Nehme\\n32 min\\nAn Introductory Guide to Fine-Tuning LLMs\\nJosep Ferrer\\n12 min\\nSalesforce XGen-7B: A Step-by-Step Tutorial on Using And Fine-Tuning XGen-7B\\nBex Tuychiev\\n15 min\\nGrow your data skills with DataCamp for Mobile\\nMake progress on the go with our mobile courses and daily 5-minute coding challenges.\\n For labeled datasets like the CSV dataset we uploaded, LangSmith offers more comprehensive evaluators for measuring the correctness of the response to a prompt:\\nLet\\u2019s try the last one on our examples:\\nCoTQA criterion returns a score called Contextual accuracy, as depicted in the GIF below (also in the UI):\\nPlease visit the LangChain evaluators section of LangSmith docs to learn much more about evaluators.\\n Once the upload finishes, the dataset will appear in the UI:\\nLet\\u2019s run our custom criterion from the previous section on this dataset as well:\\nIf you go to the dataset page and check out the run, we can see the average scores for each custom criteria:\\nEvaluating Labeled Datasets\\nBuilt-in and custom evaluators written in natural language are mostly for unlabeled datasets. We will use the create_dataset function of the client:\\nNow, let\\u2019s add three inputs that each ask the LLM to create a single flashcard:\\nIf you go over the dataset tab of the UI, you will see each prompt listed with NULL output:\\nNow, let\\u2019s run all the prompts in a single line of code using run_on_dataset function:\\n How it Works, Use Cases, Alternatives & More\\nHow AI is Changing Cybersecurity with Brian Murphy, CEO of ReliaQuest\\nAn Introductory Guide to Fine-Tuning LLMs\\nSalesforce XGen-7B: A Step-by-Step Tutorial on Using And Fine-Tuning XGen-7B\\nStart Your Langchain Journey Today\\nCourse\\nDeveloping LLM Applications with LangChain\\nCourse\\nLarge Language Models (LLMs)\"}, {\"url\": \"https://www.langchain.com/langsmith\", \"content\": \"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter \\ud83e\\udd9c\\ud83d\\udd17 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n\\ud83e\\udd9c\\ud83d\\udd17 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: \\u201cwhat\\u2019s happening with my application?\\u201d\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: LangSmith is a platform associated with LangChain, designed to help developers build and deploy large language model (LLM) applications with confidence. It offers a comprehensive suite of tools for every step of the application lifecycle, including:\n",
      "\n",
      "1. **Prompt Management**: Allows teams to craft, debug, and capture feedback on prompts.\n",
      "2. **Evaluation**: Provides built-in and custom evaluators for measuring the correctness of responses to prompts, especially useful for labeled datasets.\n",
      "3. **Monitoring**: Helps in tracking application-level usage stats, feedback collection, performance comparison, and cost measurement.\n",
      "4. **Collaboration**: Facilitates cross-team collaboration to refine, test, and version prompts in one place.\n",
      "\n",
      "LangSmith aims to turn the development of LLM applications into enterprise-ready products by providing tools for dataset curation, AI-assisted evaluation, and easy benchmarking.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "89da9e85-2e5d-49c2-8cbd-572cbdb89135",
   "metadata": {},
   "source": [
    "**Congrats!** You've created a conversational agent in langgraph that can use a search engine to retrieve updated information when needed. Now it can handle a wider range of user queries. To inspect all the steps your agent just took, check out this [LangSmith trace](https://smith.langchain.com/public/24b94adc-3356-4d9f-8f94-813f8004fdbe/r).\n",
    "\n",
    "Our chatbot still can't remember past interactions on its own, limiting its ability to have coherent, multi-turn conversations. In the next part, we'll add **memory** to address this.\n",
    "\n",
    "\n",
    "The full code for the graph we've created in this section is reproduced below, replacing our `BasicToolNode` for the prebuilt [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode), and our `route_tools` condition with the prebuilt [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8755d551-160e-4f8f-afac-0e4e07ca79ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T05:15:33.423802Z",
     "start_time": "2024-05-19T05:15:33.390320Z"
    }
   },
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "ae45f2aa-396f-4f3f-848b-7750611617f8",
   "metadata": {},
   "source": [
    "## Part 3: Adding Memory to the Chatbot\n",
    "\n",
    "Our chatbot can now use tools to answer user questions, but it doesn't remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\n",
    "\n",
    "LangGraph solves this problem through **persistent checkpointing**. If you provide a `checkpointer` when compiling the graph and a `thread_id` when calling your graph, LangGraph automatically saves the state after each step. When you invoke the graph again using the same `thread_id`, the graph loads its saved state, allowing the chatbot to pick up where it left off. \n",
    "\n",
    "We will see later that **checkpointing** is _much_ more powerful than simple chat memory - it lets you save and resume complex state at any time for error recovery, human-in-the-loop workflows, time travel interactions, and more. But before we get too ahead of ourselves, let's add checkpointing to enable multi-turn conversations.\n",
    "\n",
    "To get started, create a `SqliteSaver` checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "id": "6baafdf6-6803-4305-9381-9dc970468a4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:42:54.587512Z",
     "start_time": "2024-05-19T08:42:54.582471Z"
    }
   },
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "08d3d11a-1b42-4cbb-8e11-2a4294263d90",
   "metadata": {},
   "source": [
    "**Notice** that we've specified `:memory` as the Sqlite DB path. This is convenient for our tutorial (it saves it all in-memory). In a production application, you would likely change this to connect to your own DB and/or use one of the other checkpointer classes.\n",
    "\n",
    "Next define the graph. Now that you've already built your own `BasicToolNode`, we'll replace it with LangGraph's prebuilt `ToolNode` and `tools_condition`, since these do some nice things like parallel API execution. Apart from that, the following is all copied from Part 2."
   ]
  },
  {
   "cell_type": "code",
   "id": "e6a51f1e-00de-4701-8931-de8cf19294ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:45:31.605791Z",
     "start_time": "2024-05-19T08:45:31.580251Z"
    }
   },
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "8a292dfe-764f-4561-90aa-71317d679d3e",
   "metadata": {},
   "source": [
    "Finally, compile the graph with the provided checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "id": "a06548bf-81fa-4436-b4c1-f68601fb4187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:45:36.688017Z",
     "start_time": "2024-05-19T08:45:36.685460Z"
    }
   },
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "df01805c-4458-4474-b13b-59ecfe228f12",
   "metadata": {},
   "source": [
    "Notice the connectivity of the graph hasn't changed since Part 2. All we are doing is checkpointing the `State` as the graph works through each node."
   ]
  },
  {
   "cell_type": "code",
   "id": "761d15fb-d5e2-4d50-a630-126d77e77294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:45:50.550963Z",
     "start_time": "2024-05-19T08:45:48.929494Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ],
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "2c8265ef-e5b4-4c32-9856-5572b5652142",
   "metadata": {},
   "source": [
    "Now you can interact with your bot! First, pick a thread to use as the key for this conversation."
   ]
  },
  {
   "cell_type": "code",
   "id": "be7b5abb-04ef-4d53-83d1-d4d3139cc43a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:46:03.501014Z",
     "start_time": "2024-05-19T08:46:03.499407Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "d0b1a5ee-7fa2-475c-a9db-749694b90ba9",
   "metadata": {},
   "source": [
    "Next, call your chat bot."
   ]
  },
  {
   "cell_type": "code",
   "id": "dba1b168-f8e0-496d-9bd6-37198fb4776e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:48:47.352790Z",
     "start_time": "2024-05-19T08:48:46.599868Z"
    }
   },
   "source": [
    "user_input = \"Hi there! My name is Tam.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hi there! My name is Tam.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hello, Tam! How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "33c6b470-5082-4c3e-b732-34de47c88735",
   "metadata": {},
   "source": [
    "**Note:** The config was provided as the **second positional argument** when calling our graph. It importantly is _not_ nested within the graph inputs (`{'messages': []}`).\n",
    "\n",
    "Let's ask a followup: see if it remembers your name."
   ]
  },
  {
   "cell_type": "code",
   "id": "f5447778-53d7-47f3-801b-f47bcf2185a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:49:18.057802Z",
     "start_time": "2024-05-19T08:49:17.287317Z"
    }
   },
   "source": [
    "user_input = \"Remember my name?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Remember my name?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Got it, Tam! I'll remember your name. How can I help you today?\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "33be4cd8-f96f-4949-9d1f-48054502e5d0",
   "metadata": {},
   "source": [
    "**Notice** that we are't the memory using an external list: it's all handled by the checkpointer! You can inspect the full execution in this [LangSmith trace](https://smith.langchain.com/public/48387889-c002-47a8-9f6a-1f6b298db64b/r) to see what's going on.\n",
    "\n",
    "Don't believe me? Try this using a different config."
   ]
  },
  {
   "cell_type": "code",
   "id": "4527cf9a-b191-4bde-858a-e33a74a48c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:51:54.674850Z",
     "start_time": "2024-05-19T08:51:53.883980Z"
    }
   },
   "source": [
    "# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Remember my name?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "You haven't shared your name with me yet. Could you please tell me your name?\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "5eeccbf0-ed74-4838-a7e9-31910d82b0b2",
   "metadata": {},
   "source": [
    "**Notice** that the **only** change we've made is to modify the `thread_id` in the config. See this call's [LangSmith trace](https://smith.langchain.com/public/4647adf6-3835-4ce3-ba39-26ed4f167411/r) for comparison. \n",
    "\n",
    "By now, we have made a few checkpoints across two different threads. But what goes into a checkpoint? To inspect a graph's `state` for a given config at any time, call `get_state(config)`."
   ]
  },
  {
   "cell_type": "code",
   "id": "0be77c25-1423-4f2d-9b2d-28530cc761a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:57:35.832536Z",
     "start_time": "2024-05-19T08:57:35.828791Z"
    }
   },
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Tam.', id='650c98c3-68ca-45eb-b2c8-b2fa5fa6c895'), AIMessage(content='Hello, Tam! How can I assist you today?', response_metadata={'finish_reason': 'stop', 'logprobs': None, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_729ea513f7', 'token_usage': {'completion_tokens': 12, 'prompt_tokens': 87, 'total_tokens': 99}}, id='run-8eb1ddc8-28e4-4adc-b8c2-2b1f92658afd-0'), HumanMessage(content='Remember my name?', id='81205dfd-a879-4f6f-9fec-ba8ecd0535f5'), AIMessage(content=\"Got it, Tam! I'll remember your name. How can I help you today?\", response_metadata={'finish_reason': 'stop', 'logprobs': None, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_729ea513f7', 'token_usage': {'completion_tokens': 18, 'prompt_tokens': 110, 'total_tokens': 128}}, id='run-d793c66c-f7ba-430b-9b44-6f69071c2045-0')]}, next=(), config={'configurable': {'thread_id': '1', 'thread_ts': '1ef15bca-d7e3-641e-8004-7e150c07a825'}}, metadata={'source': 'loop', 'step': 4, 'writes': {'chatbot': {'messages': [AIMessage(content=\"Got it, Tam! I'll remember your name. How can I help you today?\", response_metadata={'finish_reason': 'stop', 'logprobs': None, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_729ea513f7', 'token_usage': {'completion_tokens': 18, 'prompt_tokens': 110, 'total_tokens': 128}}, id='run-d793c66c-f7ba-430b-9b44-6f69071c2045-0')]}}}, parent_config={'configurable': {'thread_id': '1', 'thread_ts': '1ef15bca-d0a0-6f08-8003-0c6c324a0913'}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "c106bd09-f155-4e15-9120-c60c834106e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:58:33.609309Z",
     "start_time": "2024-05-19T08:58:33.607072Z"
    }
   },
   "source": [
    "snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "627f4998-6780-4cce-8f3c-9a5580888e3a",
   "metadata": {},
   "source": [
    "The snapshot above contains the current state values, corresponding config, and the `next` node to process. In our case, the graph has reached an `__end__` state, so `next` is empty.\n",
    "\n",
    "**Congratulations!** Your chatbot can now maintain conversation state across sessions thanks to LangGraph's checkpointing system. This opens up exciting possibilities for more natural, contextual interactions. LangGraph's checkpointing even handles **arbitrary complex graph states**, which is much more expressive and powerful than simple chat memory.\n",
    "\n",
    "In the next part, we'll introduce human oversight to our bot to handle situations where it may need guidance or verification before proceeding.\n",
    "  \n",
    "Check out the code snippet below to review our graph from this section."
   ]
  },
  {
   "cell_type": "code",
   "id": "9c50a794-3ae5-484c-8edd-50e0d54da982",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T09:01:38.261686Z",
     "start_time": "2024-05-19T09:01:38.237415Z"
    }
   },
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "6f1da240-ec9b-441f-9d47-44c6dc85d540",
   "metadata": {},
   "source": [
    "## Part 4: Human-in-the-loop\n",
    "\n",
    "Agents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\n",
    "\n",
    "LangGraph supports `human-in-the-loop` workflows in a number of ways. In this section, we will use LangGraph's `interrupt_before` functionality to always break the tool node.\n",
    "\n",
    "First, start from our existing code. The following is copied from Part 3."
   ]
  },
  {
   "cell_type": "code",
   "id": "5a81608a-373a-4339-b1c6-65b73a92b983",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:08:00.429230Z",
     "start_time": "2024-05-19T15:08:00.402831Z"
    }
   },
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "813505b2-18c1-46e9-b891-20a34232808b",
   "metadata": {},
   "source": [
    "Now, compile the graph, specifying to `interrupt_before` the `action` node."
   ]
  },
  {
   "cell_type": "code",
   "id": "b0883e32-1a39-4ce9-ae32-bbd66708fd84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:08:35.867868Z",
     "start_time": "2024-05-19T15:08:35.864864Z"
    }
   },
   "source": [
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "9f318020-ab7e-415b-a5e2-eddec6d9f3a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:09:37.981873Z",
     "start_time": "2024-05-19T15:09:37.059531Z"
    }
   },
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_1MM8hjqgHq1N349pObgi55o0)\n",
      " Call ID: call_1MM8hjqgHq1N349pObgi55o0\n",
      "  Args:\n",
      "    query: LangGraph programming language\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "39405637-13b1-40b1-a51e-6d60bf675ff1",
   "metadata": {},
   "source": [
    "Let's inspect the graph state to confirm it worked."
   ]
  },
  {
   "cell_type": "code",
   "id": "9bb7af46-9b4f-4bb1-b8b9-e9ddf7dbc82c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:11:03.609972Z",
     "start_time": "2024-05-19T15:11:03.607213Z"
    }
   },
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "89326046-2b11-4812-8b6d-8780306ec275",
   "metadata": {},
   "source": [
    "**Notice** that unlike last time, the \"next\" node is set to **'action'**. We've interrupted here! Let's check the tool invocation."
   ]
  },
  {
   "cell_type": "code",
   "id": "3facda0a-e6ad-4b28-b627-753ad8c90c15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:11:40.776859Z",
     "start_time": "2024-05-19T15:11:40.774331Z"
    }
   },
   "source": [
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.tool_calls"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph programming language'},\n",
       "  'id': 'call_1MM8hjqgHq1N349pObgi55o0'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "a55a4c70-7226-4be0-8562-391f72bc1f2b",
   "metadata": {},
   "source": [
    "This query seems reasonable. Nothing to filter here. The simplest thing the human can do is just let the graph continue executing. Let's do that below.\n",
    "\n",
    "Next, continue the graph! Passing in `None` will just let the graph continue where it left off, without adding anything new to the state."
   ]
  },
  {
   "cell_type": "code",
   "id": "effb95d9-b7d5-40c5-9253-253d193b23b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:12:46.704427Z",
     "start_time": "2024-05-19T15:12:40.398761Z"
    }
   },
   "source": [
    "# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://langchain-ai.github.io/langgraph/tutorials/\", \"content\": \"These notebooks introduce LangGraph through building various language agents and applications. ... Competitive Programming\\u00b6 Can Language Models Solve Olympiad Programming?: Build an agent with few-shot \\\"episodic memory\\\" and human-in-the-loop collaboration to solve problems from the USA Computing Olympiad; ...\"}, {\"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"4. Scalability: Langgraph is designed to handle large-scale language models with billions of parameters, enabling the development of state-of-the-art NLP applications. 5. Open-Source: Langgraph is an open-source project, allowing developers and researchers to collaborate, contribute, and build upon the framework. 6.\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "LangGraph is a framework designed for building language agents and applications. Here are some key points about it:\n",
      "\n",
      "1. **Introduction and Tutorials**: LangGraph offers a series of tutorials that introduce the framework through various projects, such as building language agents and applications. These tutorials can be found on their [official website](https://langchain-ai.github.io/langgraph/tutorials/).\n",
      "\n",
      "2. **Scalability**: LangGraph is designed to handle large-scale language models with billions of parameters. This makes it suitable for developing state-of-the-art Natural Language Processing (NLP) applications.\n",
      "\n",
      "3. **Open-Source**: LangGraph is an open-source project, which means developers and researchers can collaborate, contribute, and build upon the framework.\n",
      "\n",
      "For more detailed information, you can explore their [introduction tutorial](https://langchain-ai.github.io/langgraph/tutorials/introduction/).\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "21e78a97-474f-4709-b51d-9d5e8323e14c",
   "metadata": {},
   "source": [
    "Review this call's [LangSmith trace](https://smith.langchain.com/public/6a9012c0-bfa2-4fba-8dce-961d233f9512/r) to see the exact work that was done in the above call. Notice that the state is loaded in the first step so that your chatbot can continue where it left off.\n",
    "\n",
    "**Congrats!** You've used an `interrupt` to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since we have already added a **checkpointer**, the graph can be paused **indefinitely** and resumed at any time as if nothing had happened.\n",
    "\n",
    "Next, we'll explore how to further customize the bot's behavior using custom state updates.\n",
    "\n",
    "Below is a copy of the code you used in this section. The only difference between this and the previous parts is the addition of the `interrupt_before` argument."
   ]
  },
  {
   "cell_type": "code",
   "id": "a7228caf-a5aa-4f68-b775-81ea5402aca8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:18:48.773367Z",
     "start_time": "2024-05-19T15:18:48.747770Z"
    }
   },
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import MessageGraph, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "id": "6df38bc4-c177-4ccd-9ec2-83d32bf66722",
   "metadata": {},
   "source": [
    "## Part 5: Manually Updating the State\n",
    "\n",
    "In the previous section, we showed how to interrupt a graph so that a human could inspect its actions. This lets the human `read` the state, but if they want to change they agent's course, they'll need to have `write` access.\n",
    "\n",
    "Thankfully, LangGraph lets you **manually update state**! Updating the state lets you control the agent's trajectory by modifying its actions (even modifying the past!). This capability is particularly useful when you want to correct the agent's mistakes, explore alternative paths, or guide the agent towards a specific goal.\n",
    "\n",
    "We'll show how to update a checkpointed state below. As before, first, define your graph. We'll reuse the exact same graph as before."
   ]
  },
  {
   "cell_type": "code",
   "id": "faa345c6-38a2-42e8-9035-9cf56f7bb5b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:23:11.830360Z",
     "start_time": "2024-05-19T15:23:10.772574Z"
    }
   },
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import MessageGraph, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt **after** actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")\n",
    "\n",
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream({\"messages\": [(\"user\", user_input)]}, config)\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "a6b3bcae-dd04-49da-a4ef-e05634657faf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:23:28.044089Z",
     "start_time": "2024-05-19T15:23:28.039490Z"
    }
   },
   "source": [
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_sdXUj1xKnlGqv4vIy9QWX8SA)\n",
      " Call ID: call_sdXUj1xKnlGqv4vIy9QWX8SA\n",
      "  Args:\n",
      "    query: LangGraph programming language\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "id": "3bf55a26-8c12-477a-9e83-5011d36ac4ee",
   "metadata": {},
   "source": [
    "So far, all of this is an _exact repeat_ of the previous section. The LLM just requested to use the search engine tool and our graph was interrupted. If we proceed as before, the tool will be called to search the web.\n",
    "\n",
    "But what if the user wants to intercede? What if we think the chat bot doesn't need to use the tool? \n",
    "\n",
    "Let's directly provide the correct response!"
   ]
  },
  {
   "cell_type": "code",
   "id": "6a44bedc-ea91-4c22-976c-98b3d5a5e4a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:27:15.217465Z",
     "start_time": "2024-05-19T15:27:15.211319Z"
    }
   },
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "answer = (\n",
    "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs.\"\n",
    ")\n",
    "new_messages = [\n",
    "    # The LLM API expects some ToolMessage to match its tool call. We'll satisfy that here.\n",
    "    ToolMessage(content=answer, tool_call_id=existing_message.tool_calls[0][\"id\"]),\n",
    "    # And then directly \"put words in the LLM's mouth\" by populating its response.\n",
    "    AIMessage(content=answer),\n",
    "]\n",
    "\n",
    "new_messages[-1].pretty_print()\n",
    "graph.update_state(\n",
    "    # Which state to update\n",
    "    config,\n",
    "    # The updated values to provide. The messages in our `State` are \"append-only\", meaning this will be appended\n",
    "    # to the existing state. We will review how to update existing messages in the next section!\n",
    "    {\"messages\": new_messages},\n",
    ")\n",
    "\n",
    "print(\"\\n\\nLast 2 messages;\")\n",
    "print(graph.get_state(config).values[\"messages\"][-2:])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "LangGraph is a library for building stateful, multi-actor applications with LLMs.\n",
      "\n",
      "\n",
      "Last 2 messages;\n",
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='0fd1e5af-be25-4f6c-a5af-0e029ea5d992', tool_call_id='call_sdXUj1xKnlGqv4vIy9QWX8SA'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='a6fa8ac3-9739-4f5a-b964-7a3b187b8ed7')]\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "id": "584de971-6b10-4931-986e-cc35f7adbb3d",
   "metadata": {},
   "source": [
    "Now the graph is complete, since we've provided the final response message! Since state updates simulate a graph step, they even generate corresponding traces. Inspec the [LangSmith trace](https://smith.langchain.com/public/c45207bb-bd26-4c9a-b631-928bbeebfbcb/r) of the `update_state` call above to see what's going on.\n",
    "\n",
    "**Notice** that our new messages is _appended_ to the messages already in the state. Remember how we defined the `State` type?\n",
    "\n",
    "```python\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "```\n",
    "\n",
    "We annotated `messages` with the pre-built `add_messages` function. This instructs the graph to always append values to the existing list, rather than overwriting the list directly. The same logic is applied here, so the messages we passed to `update_state` were appended in the same way!\n",
    "\n",
    "The `update_state` function operates as if it were one of the nodes in your graph! By default, the update operation uses the node that was last executed, but you can manually specify it below. Let's add an update and tell the graph to treat it as if it came from the \"chatbot\"."
   ]
  },
  {
   "cell_type": "code",
   "id": "d16d95c3-b465-42ac-8015-26b669d45d1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:30:45.108871Z",
     "start_time": "2024-05-19T15:30:45.103576Z"
    }
   },
   "source": [
    "graph.update_state(\n",
    "    config,\n",
    "    {\"messages\": [AIMessage(content=\"I'm an AI expert!\")]},\n",
    "    # Which node for this function to act as. It will automatically continue\n",
    "    # processing as if this node just ran.\n",
    "    as_node=\"chatbot\",\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'thread_ts': '1ef15f4c-27ec-68e6-8003-bc1c0b401981'}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "id": "5a1f0056-6b6f-425f-ac1a-0d4b0e9b85cc",
   "metadata": {},
   "source": [
    "Check out the [LangSmith trace](https://smith.langchain.com/public/ce83989f-6e49-4bdd-bcd5-f54ca55c8d00/r/30b1406a-ae5b-4e9e-9fe5-032be6efb92e) for this update call at the provided link. **Notice** from the trace that the graph continues into the `tools_condition` edge. We just told the graph to treat the update `as_node=\"chatbot\"`. If we follow the diagram below and start from the `chatbot` node, we naturally end up in the `tools_condition` edge and then `__end__` since our updated message lacks tool calls."
   ]
  },
  {
   "cell_type": "code",
   "id": "f4009ba6-dc0b-4216-ab0c-fbb104616f73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:32:14.021461Z",
     "start_time": "2024-05-19T15:32:12.123147Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ],
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "id": "96cd4ffa-8fb2-4bd6-bef9-564cbfe7e3ab",
   "metadata": {},
   "source": [
    "Inspect the current state as before to confirm the checkpoint reflects our manual updates."
   ]
  },
  {
   "cell_type": "code",
   "id": "d420e813-a8c7-415d-ab31-5298d42491e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:32:37.017712Z",
     "start_time": "2024-05-19T15:32:37.015148Z"
    }
   },
   "source": [
    "snapshot = graph.get_state(config)\n",
    "print(snapshot.values[\"messages\"][-3:])\n",
    "print(snapshot.next)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='0fd1e5af-be25-4f6c-a5af-0e029ea5d992', tool_call_id='call_sdXUj1xKnlGqv4vIy9QWX8SA'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='a6fa8ac3-9739-4f5a-b964-7a3b187b8ed7'), AIMessage(content=\"I'm an AI expert!\", id='4631aaf2-95fa-4ffe-b958-4800366e70d7')]\n",
      "()\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "380222f4-65fa-4962-afe6-6a715fadb2de",
   "metadata": {},
   "source": [
    "**Notice**: that we've continued to add AI messages to the state. Since we are acting as the `chatbot` and responding with an AIMessage that doesn't contain `tool_calls`, the graph knows that it has entered a finished state (`next` is empty).\n",
    "\n",
    "#### What if you want to **overwrite** existing messages? \n",
    "\n",
    "The [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) function we used to annotate our graph's `State` above controls how updates are made to the `messages` key. This function looks at any message IDs in the new `messages` list. If the ID matches a message in the existing state, [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages) overwrites the existing message with the new content. \n",
    "\n",
    "As an example, let's update the tool invocation to make sure we get good results from our search engine! First, start a new thread:"
   ]
  },
  {
   "cell_type": "code",
   "id": "9fc99c7e-b61d-4aec-9c62-042798185ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:34:18.390599Z",
     "start_time": "2024-05-19T15:34:17.520380Z"
    }
   },
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}  # we'll use thread_id = 2 here\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_oPEV3fZZMS6zkwjfDWp3FRlY)\n",
      " Call ID: call_oPEV3fZZMS6zkwjfDWp3FRlY\n",
      "  Args:\n",
      "    query: LangGraph programming language\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "id": "8b019fc6-7826-4291-9178-6cecb5d7b3d0",
   "metadata": {},
   "source": [
    "**Next,** let's update the tool invocation for our agent. Maybe we want to search for human-in-the-loop workflows in particular."
   ]
  },
  {
   "cell_type": "code",
   "id": "7215533a-b7e2-4b2d-bc1d-5122b1d06b8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:37:03.950891Z",
     "start_time": "2024-05-19T15:37:03.943518Z"
    }
   },
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "print(\"Original\")\n",
    "print(\"Message ID\", existing_message.id)\n",
    "print(existing_message.tool_calls[0])\n",
    "new_tool_call = existing_message.tool_calls[0].copy()\n",
    "new_tool_call[\"args\"][\"query\"] = \"LangGraph human-in-the-loop workflow\"\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[new_tool_call],\n",
    "    # Important! The ID is how LangGraph knows to REPLACE the message in the state rather than APPEND this messages\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "print(\"Updated\")\n",
    "print(new_message.tool_calls[0])\n",
    "print(\"Message ID\", new_message.id)\n",
    "graph.update_state(config, {\"messages\": [new_message]})\n",
    "\n",
    "print(\"\\n\\nTool calls\")\n",
    "graph.get_state(config).values[\"messages\"][-1].tool_calls"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "Message ID run-f5f816e2-6794-49cd-ab28-fda5296e255f-0\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph programming language'}, 'id': 'call_oPEV3fZZMS6zkwjfDWp3FRlY'}\n",
      "Updated\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph human-in-the-loop workflow'}, 'id': 'call_oPEV3fZZMS6zkwjfDWp3FRlY'}\n",
      "Message ID run-f5f816e2-6794-49cd-ab28-fda5296e255f-0\n",
      "\n",
      "\n",
      "Tool calls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph human-in-the-loop workflow'},\n",
       "  'id': 'call_oPEV3fZZMS6zkwjfDWp3FRlY'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "id": "680f0ebd-ebce-4de6-8a9b-37d3d4ef0234",
   "metadata": {},
   "source": [
    "**Notice** that we've modified the AI's tool invocation to search for \"LangGraph human-in-the-loop workflow\" instead of the simple \"LangGraph\".\n",
    "\n",
    "Check out the [LangSmith trace](https://smith.langchain.com/public/cd7c09a6-758d-41d4-8de1-64ab838b2338/r) to see the state update call - you can see our new message has successfully updated the previous AI message.\n",
    "\n",
    "Resume the graph by streaming with an input of `None` and the existing config."
   ]
  },
  {
   "cell_type": "code",
   "id": "03a09bfc-3d90-4e54-878f-22e3cb28a418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:39:47.387015Z",
     "start_time": "2024-05-19T15:39:40.985623Z"
    }
   },
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://langchain-ai.github.io/langgraphjs/concepts/\", \"content\": \"Interruptions let you pause, get, and update the graph's state to enable human-in-the-loop workflows; Configurable parameters allow for runtime control separate from the regular data flow; For more examples and tutorials, check out the LangGraph.js documentation. If you have any questions or run into issues, don't hesitate to reach out on GitHub.\"}, {\"url\": \"https://langchain-ai.github.io/langgraph/how-tos/human-in-the-loop/\", \"content\": \"Human-in-the-loop\\u00b6 When creating LangGraph agents, it is often nice to add a human in the loop component. This can be helpful when giving them access to tools. ... from langgraph.graph import StateGraph, END # Define a new graph workflow = StateGraph (State) # Define the two nodes we will cycle between workflow. add_node (\\\"agent\\\", call_model) ...\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "LangGraph is a tool that allows for the creation of human-in-the-loop workflows, which means it enables interruptions to pause, get, and update the graph's state. This feature is particularly useful for integrating human decision-making into automated processes. Here are some key points:\n",
      "\n",
      "1. **Interruptions**: You can pause the workflow, retrieve the current state, and update it as needed. This is essential for human-in-the-loop scenarios where human intervention is required at certain stages.\n",
      "\n",
      "2. **Configurable Parameters**: LangGraph allows for runtime control through configurable parameters, which are separate from the regular data flow. This provides flexibility in managing the workflow dynamically.\n",
      "\n",
      "3. **Documentation and Support**: The LangGraph.js documentation offers examples and tutorials to help you get started. If you encounter any issues, you can reach out for support on GitHub.\n",
      "\n",
      "For more detailed information, you can refer to the following resources:\n",
      "- [LangGraph Concepts](https://langchain-ai.github.io/langgraphjs/concepts/)\n",
      "- [Human-in-the-loop How-Tos](https://langchain-ai.github.io/langgraph/how-tos/human-in-the-loop/)\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "id": "090b680b-f53f-4af2-a432-45f8c5a10779",
   "metadata": {},
   "source": [
    "Check out the [trace](https://smith.langchain.com/public/2d633326-14ad-4248-a391-2757d01851c4/r/6464f2f2-edb4-4ef3-8f48-ee4e249f2ad0) to see the tool call and later LLM response. **Notice** that now the graph queries the search engine using our updated query term - we were able to manually override the LLM's search here!\n",
    "\n",
    "All of this is reflected in the graph's checkpointed memory, meaning if we continue the conversation, it will recall all the _modified_ state."
   ]
  },
  {
   "cell_type": "code",
   "id": "11d5b934-6d8b-4f52-a3bc-b3daa7207e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T15:42:05.134523Z",
     "start_time": "2024-05-19T15:42:03.108410Z"
    }
   },
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"user\",\n",
    "            \"Remember what I'm learning about?\",\n",
    "        )\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Remember what I'm learning about?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Yes, you're learning about LangGraph. If you have any specific questions or need further details on any aspect of LangGraph, feel free to ask!\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "id": "a5166e1b-96a6-4ac0-88a1-bf32a422134a",
   "metadata": {},
   "source": [
    "**Congratulations!** You've used `interrupt_before` and `update_state` to manually modify the state as a part of a human-in-the-loop workflow. Interruptions and state modifications let you control how the agent behaves. Combined with persistent checkpointing, it means you can `pause` an action and `resume` at any point. Your user doesn't have to be available when the graph interrupts!\n",
    "\n",
    "The graph code for this section is identical to previous ones. The key snippets to remember are to add `.compile(..., interrupt_before=[...])` (or `interrupt_after`) if you want to explicitly pause the graph whenever it reaches a node. Then you can use `update_state` to modify the checkpoint and control how the graph should proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d4c9e-65c8-4093-a6c2-c261475f7c07",
   "metadata": {},
   "source": [
    "## Part 6: Customizing State\n",
    "\n",
    "So far, we've relied on a simple state (it's just a list of messages!). You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state. In this section, we will extend our chat bot with a new node to illustrate this.\n",
    "\n",
    "In the examples above, we involved a human deterministically: the graph __always__ interrupted whenever an tool was invoked. Suppose we wanted our chat bot to have the choice of relying on a human.\n",
    "\n",
    "One way to do this is to create a passthrough \"human\" node, before which the graph will always stop. We will only execute this node if the LLM invokes a \"human\" tool. For our convenience, we will include an \"ask_human\" flag in our graph state that we will flip if the LLM calls this tool.\n",
    "\n",
    "Below, define this new graph, with an updated `State`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf7e042-1718-4625-ae30-a9917f595449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    ask_human: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87f2cb8-c066-4b54-acc4-e8c7399c5f3d",
   "metadata": {},
   "source": [
    "Next, define a schema to show the model to let it decide to request assistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5192e54-6a28-42fe-a8a7-62d45d61f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19c61b-2087-463b-adf8-96dbc193f41c",
   "metadata": {},
   "source": [
    "Next, define the chatbot node. The primary modification here is flip the `ask_human` flag if we see that the chat bot has invoked the `RequestAssistance` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa59b266-14e5-4c75-8b3d-54fac28e8290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wfh/code/lc/langchain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The method `ChatAnthropic.bind_tools` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    ask_human = False\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
    "    ):\n",
    "        ask_human = True\n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca0f57-2519-49c2-9499-888b5a884897",
   "metadata": {},
   "source": [
    "Next, create the graph builder and add the chatbot and tools nodes to the graph, same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4464d2-288b-4689-aaf0-329a55dcb85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=[tool]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a0ff3-b671-45c8-8157-ce5db411d370",
   "metadata": {},
   "source": [
    "Next, create the \"human\" `node`. This `node` function is mostly a placeholder in our graph that will trigger an interrupt. If the human does __not__ manually update the state during the `interrupt`, it inserts a tool message so the LLM knows the user was requested but didn't respond. This node also unsets the `ask_human` flag so the graph knows not to revisit the node unless further requests are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d70b5a4-ce50-47dc-aa43-ffb5c48c46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "    return {\n",
    "        # Append the new messages\n",
    "        \"messages\": new_messages,\n",
    "        # Unset the flag\n",
    "        \"ask_human\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"human\", human_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e5c65-f7b7-48bd-b0b5-fc8e590eca7d",
   "metadata": {},
   "source": [
    "Next, define the conditional logic. The `select_next_node` will route to the `human` node if the flag is set. Otherwise, it lets the prebuilt `tools_condition` function choose the next node.\n",
    "\n",
    "Recall that the `tools_condition` function simply checks to see if the `chatbot` has responded with any `tool_calls` in its response message. If so, it routes to the `action` node. Otherwise, it ends the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586a0d07-8303-47f4-b3cf-3bdd043e762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_node(state: State):\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # Otherwise, we can route as before\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd0bb1-b13e-477e-a08a-a7e657e2c19e",
   "metadata": {},
   "source": [
    "Finally, add the simple directed edges and compile the graph. These edges instruct the graph to **always** flow from node `a`->`b` whenever `a` finishes executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84101737-0048-4635-9f68-45b0c508b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is the same\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # We interrupt before 'human' here instead.\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f855593-8690-4a18-9ef8-7f3ccdc335bf",
   "metadata": {},
   "source": [
    "If you have the visualization dependencies installed, you can see the graph structure below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3220ae2-cba0-4447-96d1-eb0be4684e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b73851-810e-4466-89d8-37fba87e8494",
   "metadata": {},
   "source": [
    "The chat bot can either request help from a human (chatbot->select->human), invoke the search engine tool (chatbot->select->action), or directly respond (chatbot->select->__end__). Once an action or request has been made, the graph will transition back to the `chatbot` node to continue operations.\n",
    "\n",
    "Let's see this graph in action. We will request for expert assistance to illustrate our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1955d79-a1e4-47d0-ba79-b45bd5752a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "I need some expert guidance for building this AI agent. Could you request assistance for me?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "[{'id': 'toolu_017XaQuVsoAyfXeTfDyv55Pc', 'input': {'request': 'I need some expert guidance for building this AI agent.'}, 'name': 'RequestAssistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  RequestAssistance (toolu_017XaQuVsoAyfXeTfDyv55Pc)\n",
      " Call ID: toolu_017XaQuVsoAyfXeTfDyv55Pc\n",
      "  Args:\n",
      "    request: I need some expert guidance for building this AI agent.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I need some expert guidance for building this AI agent. Could you request assistance for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3945ea4-8dbd-4e14-ae2a-34da7f05a0c1",
   "metadata": {},
   "source": [
    "**Notice:** the LLM has invoked the \"`RequestAssistance`\" tool we provided it, and the interrupt has been set. Let's inspect the graph state to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5320ba05-5696-4194-8278-5385c571264d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human',)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2dd02e-f0a6-4f63-a7d6-e49ecf40db21",
   "metadata": {},
   "source": [
    "The graph state is indeed **interrupted** before the `'human'` node. We can act as the \"expert\" in this scenario and manually update the state by adding a new ToolMessage with our input.\n",
    "\n",
    "Next, respond to the chatbot's request by:\n",
    "1. Creating a `ToolMessage` with our response. This will be passed back to the `chatbot`.\n",
    "2. Calling `update_state` to manually update the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cbac924-61ce-4282-9b1c-77f9090ea1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'thread_ts': '2024-05-06T22:31:39.973392+00:00'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = snapshot.values[\"messages\"][-1]\n",
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "tool_message = create_response(human_response, ai_message)\n",
    "graph.update_state(config, {\"messages\": [tool_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79492363-7fc6-4ec7-977d-9030648029bc",
   "metadata": {},
   "source": [
    "You can inspect the state to confirm our response was added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b986c66-1c65-4da8-a404-db7e28f8364e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='I need some expert guidance for building this AI agent. Could you request assistance for me?', id='ab75eb9d-cce7-4e44-8de7-b0b375a86972'),\n",
       " AIMessage(content=[{'id': 'toolu_017XaQuVsoAyfXeTfDyv55Pc', 'input': {'request': 'I need some expert guidance for building this AI agent.'}, 'name': 'RequestAssistance', 'type': 'tool_use'}], response_metadata={'id': 'msg_0199PiK6kmVAbeo1qmephKDq', 'model': 'claude-3-haiku-20240307', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 486, 'output_tokens': 63}}, id='run-ff07f108-5055-4343-8910-2fa40ead3fb9-0', tool_calls=[{'name': 'RequestAssistance', 'args': {'request': 'I need some expert guidance for building this AI agent.'}, 'id': 'toolu_017XaQuVsoAyfXeTfDyv55Pc'}]),\n",
       " ToolMessage(content=\"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\", id='19f2eb9f-a742-46aa-9047-60909c30e64a', tool_call_id='toolu_017XaQuVsoAyfXeTfDyv55Pc')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b8616-de10-44d6-a8f0-3ac73c3c3680",
   "metadata": {},
   "source": [
    "Next, **resume** the graph by invoking it with `None` as the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b32914d-4d60-491f-8e11-1e6867e38ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "It looks like the experts have provided some guidance on how to build your AI agent. They suggested checking out LangGraph, which they say is more reliable and extensible than simple autonomous agents. Please let me know if you need any other assistance - I'm happy to help coordinate with the expert team further.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0559b-d653-4dab-8928-b001004d14cb",
   "metadata": {},
   "source": [
    "**Notice** that the chat bot has incorporated the updated state in its final response. Since **everything** was checkpointed, the \"expert\" human in the loop could perform the update at any time without impacting the graph's execution.\n",
    "\n",
    "**Congratulations!** you've now added an additional node to your assistant graph to let the chat bot decide for itself whether or not it needs to interrupt execution. You did so by updating the graph `State` with a new `ask_human` field and modifying the interruption logic when compiling the graph. This lets you dynamically include a human in the loop while maintaining full **memory** every time you execute the graph.\n",
    "\n",
    "We're almost done with the tutorial, but there is one more concept we'd like to review before finishing that connects `checkpointing` and `state updates`. \n",
    "\n",
    "This section's code is reproduced below for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6516baf8-bbb6-4400-b867-0add1a087342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Union\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    ask_human: bool\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    ask_human = False\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
    "    ):\n",
    "        ask_human = True\n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=[tool]))\n",
    "\n",
    "\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "    return {\n",
    "        # Append the new messages\n",
    "        \"messages\": new_messages,\n",
    "        # Unset the flag\n",
    "        \"ask_human\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "\n",
    "\n",
    "def select_next_node(state: State):\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # Otherwise, we can route as before\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05283db2-2f26-4800-8eda-78a4468a3d8f",
   "metadata": {},
   "source": [
    "## Part 7: Time Travel\n",
    "\n",
    "In a typical chat bot workflow, the user interacts with the bot 1 or more times to accomplish a task. In the previous sections, we saw how to add memory and a human-in-the-loop to be able to checkpoint our graph state and manually override the state to control future responses.\n",
    "\n",
    "But what if you want to let your user start from a previous response and \"branch off\" to explore a separate outcome? Or what if you want users to be able to \"rewind\" your assistant's work to fix some mistakes or try a different strategy (common in applications like autonomous software engineers)?\n",
    "\n",
    "You can create both of these experiences and more using LangGraph's built-in \"time travel\" functionality. \n",
    "\n",
    "In this section, you will \"rewind\" your graph by fetching a checkpoint using the graph's `get_state_history` method. You can then resume execution at this previous point in time.\n",
    "\n",
    "First, recall our chatbot graph. We don't need to make **any** changes from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8a02de-a21b-4ef6-a714-7d6e44435e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Union, Literal\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import AIMessage, BaseMessage, ToolMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    ask_human: bool\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    ask_human = False\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
    "    ):\n",
    "        ask_human = True\n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=[tool]))\n",
    "\n",
    "\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "    return {\n",
    "        # Append the new messages\n",
    "        \"messages\": new_messages,\n",
    "        # Unset the flag\n",
    "        \"ask_human\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "\n",
    "\n",
    "def select_next_node(state: State) -> Literal[\"human\", \"tools\", \"__end__\"]:\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # Otherwise, we can route as before\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7debb4a-2a3a-40b9-a48c-7052ec2c2726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414c482-215e-4cc0-9eef-4a8722d2f468",
   "metadata": {},
   "source": [
    "Let's have our graph take a couple steps. Every step will be checkpointed in its state history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69071b02-c011-4b7f-90b1-8e89e032322d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "[{'text': \"Okay, let me look into LangGraph for you. Here's what I found:\", 'type': 'text'}, {'id': 'toolu_011AQ2FT4RupVka2LVMV3Gci', 'input': {'query': 'LangGraph'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_011AQ2FT4RupVka2LVMV3Gci)\n",
      " Call ID: toolu_011AQ2FT4RupVka2LVMV3Gci\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://langchain-ai.github.io/langgraph/\", \"content\": \"LangGraph is framework agnostic (each node is a regular python function). It extends the core Runnable API (shared interface for streaming, async, and batch calls) to make it easy to: Seamless state management across multiple turns of conversation or tool usage. The ability to flexibly route between nodes based on dynamic criteria.\"}, {\"url\": \"https://blog.langchain.dev/langgraph-multi-agent-workflows/\", \"content\": \"As a part of the launch, we highlighted two simple runtimes: one that is the equivalent of the AgentExecutor in langchain, and a second that was a version of that aimed at message passing and chat models.\\n It's important to note that these three examples are only a few of the possible examples we could highlight - there are almost assuredly other examples out there and we look forward to seeing what the community comes up with!\\n LangGraph: Multi-Agent Workflows\\nLinks\\nLast week we highlighted LangGraph - a new package (available in both Python and JS) to better enable creation of LLM workflows containing cycles, which are a critical component of most agent runtimes. \\\"\\nAnother key difference between Autogen and LangGraph is that LangGraph is fully integrated into the LangChain ecosystem, meaning you take fully advantage of all the LangChain integrations and LangSmith observability.\\n As part of this launch, we're also excited to highlight a few applications built on top of LangGraph that utilize the concept of multiple agents.\\n\"}]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Based on the search results, here's what I've learned about LangGraph:\n",
      "\n",
      "- LangGraph is a framework-agnostic tool that extends the Runnable API to make it easier to manage state and routing between different nodes or agents in a conversational workflow. \n",
      "\n",
      "- It's part of the LangChain ecosystem, so it integrates with other LangChain tools and observability features.\n",
      "\n",
      "- LangGraph enables the creation of multi-agent workflows, where you can have different \"nodes\" or agents that can communicate and pass information to each other.\n",
      "\n",
      "- This allows for more complex conversational flows and the ability to chain together different capabilities, tools, or models.\n",
      "\n",
      "- The key benefits seem to be around state management, flexible routing between agents, and the ability to create more sophisticated and dynamic conversational workflows.\n",
      "\n",
      "Let me know if you need any clarification or have additional questions! I'm happy to do more research on LangGraph if you need further details.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"I'm learning LangGraph. Could you do some research on it for me?\")\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acbec099-e5d2-497f-929e-c548d7bcbf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "[{'text': \"That's great that you're interested in building an autonomous agent using LangGraph! Here are a few additional thoughts on how you could approach that:\", 'type': 'text'}, {'id': 'toolu_01L3V9FhZG5Qx9jqRGfWGtS2', 'input': {'query': 'building autonomous agents with langgraph'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01L3V9FhZG5Qx9jqRGfWGtS2)\n",
      " Call ID: toolu_01L3V9FhZG5Qx9jqRGfWGtS2\n",
      "  Args:\n",
      "    query: building autonomous agents with langgraph\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://github.com/langchain-ai/langgraphjs\", \"content\": \"LangGraph is a library for building stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain.js.It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam.The current interface exposed is one inspired by ...\"}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam.The current interface exposed is one inspired by NetworkX.. The main use is for adding cycles to your LLM ...\"}]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "The key things to keep in mind:\n",
      "\n",
      "1. LangGraph is designed to help coordinate multiple \"agents\" or \"actors\" that can pass information back and forth. This allows you to build more complex, multi-step workflows.\n",
      "\n",
      "2. You'll likely want to define different nodes or agents that handle specific tasks or capabilities. LangGraph makes it easy to route between these agents based on the state of the conversation.\n",
      "\n",
      "3. Make sure to leverage the LangChain ecosystem - things like prompts, memory, agents, tools etc. LangGraph integrates with these to give you a powerful set of building blocks.\n",
      "\n",
      "4. Pay close attention to state management - LangGraph helps you manage state across multiple interactions, which is crucial for an autonomous agent.\n",
      "\n",
      "5. Consider how you'll handle things like user intent, context, and goal-driven behavior. LangGraph gives you the flexibility to implement these kinds of complex behaviors.\n",
      "\n",
      "Let me know if you have any other specific questions as you start prototyping your autonomous agent! I'm happy to provide more guidance.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Ya that's helpful. Maybe I'll build an autonomous agent with it!\")\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e48c77-65f3-4075-8030-ebf943a281f1",
   "metadata": {},
   "source": [
    "Now that we've had the agent take a couple steps, we can `replay` the full state history to see everything that occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0dbed5-210d-40ad-b002-0bc52ef28fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  8 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('action',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('action',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182019e-bae3-4616-ba1b-f845c0ab6636",
   "metadata": {},
   "source": [
    "**Notice** that checkpoints are saved for every step of the graph. This _spans invocations__ so you can rewind across a full thread's history. We've picked out `to_replay` as a state to resume from. This is the state after the `chatbot` node in the second graph invocation above.\n",
    "\n",
    "Resuming from this point should call the **action** node next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8d5521-8d71-4093-a657-4920c790802f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('action',)\n",
      "{'configurable': {'thread_id': '1', 'thread_ts': '2024-05-06T22:33:10.211424+00:00'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c61f5-3a4a-4cce-b81b-43fe1dcc971f",
   "metadata": {},
   "source": [
    "**Notice** that the checkpoint's config (`to_replay.config`) contains a `thread_ts` **timestamp**. Providing this `thread_ts` value tells LangGraph's checkpointer to **load** the state from that moment in time. Let's try it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85f17be3-eaf6-495e-a846-49436916b4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://valentinaalto.medium.com/getting-started-with-langgraph-66388e023754\", \"content\": \"Sign up\\nSign in\\nSign up\\nSign in\\nMember-only story\\nGetting Started with LangGraph\\nBuilding multi-agents application with graph frameworks\\nValentina Alto\\nFollow\\n--\\nShare\\nOver the last year, LangChain has established itself as one of the most popular AI framework available in the market. This new library, introduced in January\\u2026\\n--\\n--\\nWritten by Valentina Alto\\nData&AI Specialist at @Microsoft | MSc in Data Science | AI, Machine Learning and Running enthusiast\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams Since the concept of multi-agent applications \\u2014 the ones exhibiting different agents, each having a specific personality and tools to access \\u2014 is getting real and mainstream (see the rise of libraries projects like AutoGen), LangChain\\u2019s developers introduced a new library to make it easier to manage these kind of agentic applications. Nevertheless, those chains were lacking the capability of introducing cycles into their runtime, meaning that there is no out-of-the-box framework to enable the LLM to reason over the next best action in a kind of for-loop scenario. The main feature of LangChain \\u2014 as the name suggests \\u2014 is its ability to easily create the so-called chains.\"}, {\"url\": \"https://blog.langchain.dev/langgraph-multi-agent-workflows/\", \"content\": \"As a part of the launch, we highlighted two simple runtimes: one that is the equivalent of the AgentExecutor in langchain, and a second that was a version of that aimed at message passing and chat models.\\n It's important to note that these three examples are only a few of the possible examples we could highlight - there are almost assuredly other examples out there and we look forward to seeing what the community comes up with!\\n LangGraph: Multi-Agent Workflows\\nLinks\\nLast week we highlighted LangGraph - a new package (available in both Python and JS) to better enable creation of LLM workflows containing cycles, which are a critical component of most agent runtimes. \\\"\\nAnother key difference between Autogen and LangGraph is that LangGraph is fully integrated into the LangChain ecosystem, meaning you take fully advantage of all the LangChain integrations and LangSmith observability.\\n As part of this launch, we're also excited to highlight a few applications built on top of LangGraph that utilize the concept of multiple agents.\\n\"}]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "The key things I gathered are:\n",
      "\n",
      "- LangGraph is well-suited for building multi-agent applications, where you have different agents with their own capabilities, tools, and personality.\n",
      "\n",
      "- It allows you to create more complex workflows with cycles and feedback loops, which is critical for building autonomous agents that can reason about their next best actions.\n",
      "\n",
      "- The integration with LangChain means you can leverage other useful features like state management, observability, and integrations with various language models and data sources.\n",
      "\n",
      "Some tips for building an autonomous agent with LangGraph:\n",
      "\n",
      "1. Define the different agents/nodes in your workflow and their specific responsibilities/capabilities.\n",
      "2. Set up the connections and routing between the agents so they can pass information and decisions back and forth.\n",
      "3. Implement logic within each agent to assess the current state and determine the optimal next action.\n",
      "4. Use LangChain features like memory and toolkits to give your agents access to relevant information and abilities.\n",
      "5. Monitor the overall system behavior and iteratively improve the agent interactions and decision-making.\n",
      "\n",
      "Let me know if you have any other questions! I'm happy to provide more guidance as you start building your autonomous agent with LangGraph.\n"
     ]
    }
   ],
   "source": [
    "# The `thread_ts` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2501fed-2591-420d-98e0-4a3836fb99a8",
   "metadata": {},
   "source": [
    "Notice that the graph resumed execution from the `**action**` node. You can tell this is the case since the first value printed above is the response from our search engine tool.\n",
    "\n",
    "**Congratulations!** You've now used time-travel checkpoint traversal in LangGraph. Being able to rewind and explore alternative paths opens up a world of possibilities for debugging, experimentation, and interactive applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584d57f-5aad-4507-815f-0b2e4b64b791",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congrats! You've completed the intro tutorial and built a chat bot in LangGraph that supports tool calling, persistent memory, human-in-the-loop interactivity, and even time-travel!\n",
    "\n",
    "The [LangGraph documentation](https://langchain-ai.github.io/langgraph/) is a great resource for diving deeper into the library's capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
