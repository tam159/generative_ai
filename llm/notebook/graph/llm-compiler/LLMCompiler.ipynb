{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8b472b-f3fb-46c2-841f-930a4692697b",
   "metadata": {},
   "source": [
    "# LLMCompiler\n",
    "\n",
    "This notebook shows how to implement [LLMCompiler, by Kim, et. al](https://arxiv.org/abs/2312.04511) in LangGraph.\n",
    "\n",
    "LLMCompiler is an agent architecture designed to **speed up** the execution of agentic tasks by eagerly-executed tasks within a DAG. It also saves costs on redundant token usage by reducing the number of calls to the LLM. Below is an overview of its computational graph:\n",
    "\n",
    "![LLMCompiler Graph](./img/llm-compiler.png)\n",
    "\n",
    "It has 3 main components:\n",
    "\n",
    "1. Planner: stream a DAG of tasks.\n",
    "2. Task Fetching Unit: schedules and executes the tasks as soon as they are executable\n",
    "3. Joiner: Responds to the user or triggers a second plan\n",
    "\n",
    "\n",
    "This notebook walks through each component and shows how to wire them together using LangGraph. The end result will leave a trace [like the following](https://smith.langchain.com/public/218c2677-c719-4147-b0e9-7bc3b5bb2623/r).\n",
    "\n",
    "\n",
    "**First,** install the dependencies, and set up LangSmith for tracing to more easily debug and observe the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bd5497-35ad-44f2-94d9-19ff39a5ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U --quiet langchain_openai langsmith langgraph langchain numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abbd6948-e9a3-47ca-89c7-7ac2fc5eca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import getpass\n",
    "\n",
    "\n",
    "# def _get_pass(var: str):\n",
    "#     if var not in os.environ:\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "# Optional: Debug + trace calls using LangSmith\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"True\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"LLMCompiler\"\n",
    "# _get_pass(\"LANGCHAIN_API_KEY\")\n",
    "# _get_pass(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:59:43.022154Z",
     "start_time": "2024-05-23T09:59:43.015398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv"
   ],
   "id": "16b0d1e823bfd4bd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T09:59:48.797097Z",
     "start_time": "2024-05-23T09:59:48.792414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "7bdf162cb047f456",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "a61b48ee-8c6f-4863-913a-676f659287de",
   "metadata": {},
   "source": [
    "## Part 1: Tools\n",
    "\n",
    "We'll first define the tools for the agent to use in our demo. We'll give it the class search engine + calculator combo.\n",
    "\n",
    "If you don't want to sign up for tavily, you can replace it with the free [DuckDuckGo](https://python.langchain.com/docs/integrations/tools/ddg)."
   ]
  },
  {
   "cell_type": "code",
   "id": "e7476bb2-1a51-42f6-b7ae-82a0300bbf84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:00:54.832590Z",
     "start_time": "2024-05-23T10:00:53.624250Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Imported from the https://github.com/langchain-ai/langgraph/tree/main/examples/plan-and-execute repo\n",
    "from math_tools import get_math_tool\n",
    "\n",
    "# _get_pass(\"TAVILY_API_KEY\")\n",
    "\n",
    "calculate = get_math_tool(ChatOpenAI(model=\"gpt-4o\"))\n",
    "search = TavilySearchResults(\n",
    "    max_results=1,\n",
    "    description='tavily_search_results_json(query=\"the search query\") - a search engine.',\n",
    ")\n",
    "\n",
    "tools = [search, calculate]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "/Users/may/.virtualenvs/generative_ai/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` that is available on ChatModels capable of tool calling. You can read more about the method here: https://python.langchain.com/docs/modules/model_io/chat/structured_output/ Please follow our extraction use case documentation for more guidelines on how to do information extraction with LLMs. https://python.langchain.com/docs/use_cases/extraction/. If you notice other issues, please provide feedback here: https://github.com/langchain-ai/langchain/discussions/18154\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "152eecf3-6bef-4718-af71-a0b3c5a3b009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:01:18.675720Z",
     "start_time": "2024-05-23T10:01:17.313390Z"
    }
   },
   "source": [
    "calculate.invoke(\n",
    "    {\n",
    "        \"problem\": \"What's the temp of sf + 5?\",\n",
    "        \"context\": [\"The tempreature of sf is 32 degrees\"],\n",
    "    }\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'37'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "1abdedbd-d81b-4ee9-b46f-f29439ed1350",
   "metadata": {},
   "source": [
    "# Part 2: Planner\n",
    "\n",
    "\n",
    "Largely adapted from [the original source code](https://github.com/SqueezeAILab/LLMCompiler/blob/main/src/llm_compiler/output_parser.py), the planner  accepts the input question and generates a task list to execute.\n",
    "\n",
    "If it is provided with a previous plan, it is instructed to re-plan, which is useful if, upon completion of the first batch of tasks, the agent must take more actions.\n",
    "\n",
    "The code below composes constructs the prompt template for the planner and composes it with LLM and output parser, defined in [output_parser.py](./output_parser.py). The output parser processes a task list in the following form:\n",
    "\n",
    "```plaintext\n",
    "1. tool_1(arg1=\"arg1\", arg2=3.5, ...)\n",
    "Thought: I then want to find out Y by using tool_2\n",
    "2. tool_2(arg1=\"\", arg2=\"${1}\")'\n",
    "3. join()<END_OF_PLAN>\"\n",
    "```\n",
    "\n",
    "The \"Thought\" lines are optional. The `${#}` placeholders are variables. These are used to route tool (task) outputs to other tools."
   ]
  },
  {
   "cell_type": "code",
   "id": "15dd9639-691f-4906-9012-83fd6e9ac126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:10:35.696535Z",
     "start_time": "2024-05-23T10:10:34.569403Z"
    }
   },
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "from output_parser import LLMCompilerPlanParser, Task\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "prompt = hub.pull(\"wfh/llm-compiler\")\n",
    "print(prompt.pretty_print())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m System Message \u001B[0m================================\n",
      "\n",
      "Given a user query, create a plan to solve it with the utmost parallelizability. Each plan should comprise an action from the following \u001B[33;1m\u001B[1;3m{num_tools}\u001B[0m types:\n",
      "\u001B[33;1m\u001B[1;3m{tool_descriptions}\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m{num_tools}\u001B[0m. join(): Collects and combines results from prior actions.\n",
      "\n",
      " - An LLM agent is called upon invoking join() to either finalize the user query or wait until the plans are executed.\n",
      " - join should always be the last action in the plan, and will be called in two scenarios:\n",
      "   (a) if the answer can be determined by gathering the outputs from tasks to generate the final response.\n",
      "   (b) if the answer cannot be determined in the planning phase before you execute the plans. Guidelines:\n",
      " - Each action described above contains input/output types and description.\n",
      "    - You must strictly adhere to the input and output types for each action.\n",
      "    - The action descriptions contain the guidelines. You MUST strictly follow those guidelines when you use the actions.\n",
      " - Each action in the plan should strictly be one of the above types. Follow the Python conventions for each action.\n",
      " - Each action MUST have a unique ID, which is strictly increasing.\n",
      " - Inputs for actions can either be constants or outputs from preceding actions. In the latter case, use the format $id to denote the ID of the previous action whose output will be the input.\n",
      " - Always call join as the last action in the plan. Say '<END_OF_PLAN>' after you call join\n",
      " - Ensure the plan maximizes parallelizability.\n",
      " - Only use the provided action types. If a query cannot be addressed using these, invoke the join action for the next steps.\n",
      " - Never introduce new actions other than the ones provided.\n",
      "\n",
      "=============================\u001B[1m Messages Placeholder \u001B[0m=============================\n",
      "\n",
      "\u001B[33;1m\u001B[1;3m{messages}\u001B[0m\n",
      "\n",
      "================================\u001B[1m System Message \u001B[0m================================\n",
      "\n",
      "Remember, ONLY respond with the task list in the correct format! E.g.:\n",
      "idx. tool(arg_name=args)\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "45689d40-d8df-4316-a121-6ea9c87d2efe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:11:46.792056Z",
     "start_time": "2024-05-23T10:11:46.787120Z"
    }
   },
   "source": [
    "def create_planner(\n",
    "    llm: BaseChatModel, tools: Sequence[BaseTool], base_prompt: ChatPromptTemplate\n",
    "):\n",
    "    tool_descriptions = \"\\n\".join(\n",
    "        f\"{i+1}. {tool.description}\\n\"\n",
    "        for i, tool in enumerate(\n",
    "            tools\n",
    "        )  # +1 to offset the 0 starting index, we want it count normally from 1.\n",
    "    )\n",
    "    planner_prompt = base_prompt.partial(\n",
    "        replan=\"\",\n",
    "        num_tools=len(tools)\n",
    "        + 1,  # Add one because we're adding the join() tool at the end.\n",
    "        tool_descriptions=tool_descriptions,\n",
    "    )\n",
    "    replanner_prompt = base_prompt.partial(\n",
    "        replan=' - You are given \"Previous Plan\" which is the plan that the previous agent created along with the execution results '\n",
    "        \"(given as Observation) of each plan and a general thought (given as Thought) about the executed results.\"\n",
    "        'You MUST use these information to create the next plan under \"Current Plan\".\\n'\n",
    "        ' - When starting the Current Plan, you should start with \"Thought\" that outlines the strategy for the next plan.\\n'\n",
    "        \" - In the Current Plan, you should NEVER repeat the actions that are already executed in the Previous Plan.\\n\"\n",
    "        \" - You must continue the task index from the end of the previous one. Do not repeat task indices.\",\n",
    "        num_tools=len(tools) + 1,\n",
    "        tool_descriptions=tool_descriptions,\n",
    "    )\n",
    "\n",
    "    def should_replan(state: list):\n",
    "        # Context is passed as a system message\n",
    "        return isinstance(state[-1], SystemMessage)\n",
    "\n",
    "    def wrap_messages(state: list):\n",
    "        return {\"messages\": state}\n",
    "\n",
    "    def wrap_and_get_last_index(state: list):\n",
    "        next_task = 0\n",
    "        for message in state[::-1]:\n",
    "            if isinstance(message, FunctionMessage):\n",
    "                next_task = message.additional_kwargs[\"idx\"] + 1\n",
    "                break\n",
    "        state[-1].content = state[-1].content + f\" - Begin counting at : {next_task}\"\n",
    "        return {\"messages\": state}\n",
    "\n",
    "    return (\n",
    "        RunnableBranch(\n",
    "            (should_replan, wrap_and_get_last_index | replanner_prompt),\n",
    "            wrap_messages | planner_prompt,\n",
    "        )\n",
    "        | llm\n",
    "        | LLMCompilerPlanParser(tools=tools)\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "bbdcb57b-5362-4b9e-88db-fb3fae443fb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:12:12.289344Z",
     "start_time": "2024-05-23T10:12:12.266303Z"
    }
   },
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "# This is the primary \"agent\" in our application\n",
    "planner = create_planner(llm, tools, prompt)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "730490c6-6e3a-4173-82a1-9eb9d5eeff20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:13:23.141910Z",
     "start_time": "2024-05-23T10:13:21.303749Z"
    }
   },
   "source": [
    "example_question = \"What's the temperature in SF raised to the 3rd power?\"\n",
    "\n",
    "for task in planner.stream([HumanMessage(content=example_question)]):\n",
    "    print(task[\"tool\"], task[\"args\"])\n",
    "    print(\"---\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description='tavily_search_results_json(query=\"the search query\") - a search engine.' max_results=1 {'query': 'current temperature in San Francisco'}\n",
      "---\n",
      "name='math' description='math(problem: str, context: Optional[list[str]]) -> float:\\n - Solves the provided math problem.\\n - `problem` can be either a simple math problem (e.g. \"1 + 3\") or a word problem (e.g. \"how many apples are there if there are 3 apples and 2 apples\").\\n - You cannot calculate multiple expressions in one call. For instance, `math(\\'1 + 3, 2 + 4\\')` does not work. If you need to calculate multiple expressions, you need to call them separately like `math(\\'1 + 3\\')` and then `math(\\'2 + 4\\')`\\n - Minimize the number of `math` actions as much as possible. For instance, instead of calling 2. math(\"what is the 10% of $1\") and then call 3. math(\"$1 + $2\"), you MUST call 2. math(\"what is the 110% of $1\") instead, which will reduce the number of math actions.\\n - You can optionally provide a list of strings as `context` to help the agent solve the problem. If there are multiple contexts you need to answer the question, you can provide them as a list of strings.\\n - `math` action will not see the output of the previous actions unless you provide it as `context`. You MUST provide the output of the previous actions as `context` if you need to do math on it.\\n - You MUST NEVER provide `search` type action\\'s outputs as a variable in the `problem` argument. This is because `search` returns a text blob that contains the information about the entity, not a number or value. Therefore, when you need to provide an output of `search` action, you MUST provide it as a `context` argument to `math` action. For example, 1. search(\"Barack Obama\") and then 2. math(\"age of $1\") is NEVER allowed. Use 2. math(\"age of Barack Obama\", context=[\"$1\"]) instead.\\n - When you ask a question about `context`, specify the units. For instance, \"what is xx in height?\" or \"what is xx in millions?\" instead of \"what is xx?\"' args_schema=<class 'pydantic.v1.main.mathSchema'> func=<function get_math_tool.<locals>.calculate_expression at 0x1156c2340> {'problem': 'cube the temperature', 'context': ['$1']}\n",
      "---\n",
      "join ()\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "5d0e795f-61ff-4553-9823-23e7624ca180",
   "metadata": {},
   "source": [
    "## 3. Task Fetching Unit\n",
    "\n",
    "This component schedules the tasks. It receives a stream of tools of the following format:\n",
    "\n",
    "```typescript\n",
    "{\n",
    "    tool: BaseTool,\n",
    "    dependencies: number[],\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "The basic idea is to begin executing tools as soon as their dependencies are met. This is done through multi-threading. We will combine the task fetching unit and executor below:\n",
    "\n",
    "![diagram](./img/diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "c1fbafdd-42d4-4575-8466-e5951cee71f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T10:15:45.264403Z",
     "start_time": "2024-05-23T10:15:45.256898Z"
    }
   },
   "source": [
    "from typing import Any, Union, Iterable, List, Tuple, Dict\n",
    "from typing_extensions import TypedDict\n",
    "import re\n",
    "\n",
    "from langchain_core.runnables import (\n",
    "    chain as as_runnable,\n",
    ")\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "import time\n",
    "\n",
    "\n",
    "def _get_observations(messages: List[BaseMessage]) -> Dict[int, Any]:\n",
    "    # Get all previous tool responses\n",
    "    results = {}\n",
    "    for message in messages[::-1]:\n",
    "        if isinstance(message, FunctionMessage):\n",
    "            results[int(message.additional_kwargs[\"idx\"])] = message.content\n",
    "    return results\n",
    "\n",
    "\n",
    "class SchedulerInput(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    tasks: Iterable[Task]\n",
    "\n",
    "\n",
    "def _execute_task(task, observations, config):\n",
    "    tool_to_use = task[\"tool\"]\n",
    "    if isinstance(tool_to_use, str):\n",
    "        return tool_to_use\n",
    "    args = task[\"args\"]\n",
    "    try:\n",
    "        if isinstance(args, str):\n",
    "            resolved_args = _resolve_arg(args, observations)\n",
    "        elif isinstance(args, dict):\n",
    "            resolved_args = {\n",
    "                key: _resolve_arg(val, observations) for key, val in args.items()\n",
    "            }\n",
    "        else:\n",
    "            # This will likely fail\n",
    "            resolved_args = args\n",
    "    except Exception as e:\n",
    "        return (\n",
    "            f\"ERROR(Failed to call {tool_to_use.name} with args {args}.)\"\n",
    "            f\" Args could not be resolved. Error: {repr(e)}\"\n",
    "        )\n",
    "    try:\n",
    "        return tool_to_use.invoke(resolved_args, config)\n",
    "    except Exception as e:\n",
    "        return (\n",
    "            f\"ERROR(Failed to call {tool_to_use.name} with args {args}.\"\n",
    "            + f\" Args resolved to {resolved_args}. Error: {repr(e)})\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _resolve_arg(arg: Union[str, Any], observations: Dict[int, Any]):\n",
    "    # $1 or ${1} -> 1\n",
    "    ID_PATTERN = r\"\\$\\{?(\\d+)\\}?\"\n",
    "\n",
    "    def replace_match(match):\n",
    "        # If the string is ${123}, match.group(0) is ${123}, and match.group(1) is 123.\n",
    "\n",
    "        # Return the match group, in this case the index, from the string. This is the index\n",
    "        # number we get back.\n",
    "        idx = int(match.group(1))\n",
    "        return str(observations.get(idx, match.group(0)))\n",
    "\n",
    "    # For dependencies on other tasks\n",
    "    if isinstance(arg, str):\n",
    "        return re.sub(ID_PATTERN, replace_match, arg)\n",
    "    elif isinstance(arg, list):\n",
    "        return [_resolve_arg(a, observations) for a in arg]\n",
    "    else:\n",
    "        return str(arg)\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def schedule_task(task_inputs, config):\n",
    "    task: Task = task_inputs[\"task\"]\n",
    "    observations: Dict[int, Any] = task_inputs[\"observations\"]\n",
    "    try:\n",
    "        observation = _execute_task(task, observations, config)\n",
    "    except Exception:\n",
    "        import traceback\n",
    "\n",
    "        observation = traceback.format_exception()  # repr(e) +\n",
    "    observations[task[\"idx\"]] = observation\n",
    "\n",
    "\n",
    "def schedule_pending_task(\n",
    "    task: Task, observations: Dict[int, Any], retry_after: float = 0.2\n",
    "):\n",
    "    while True:\n",
    "        deps = task[\"dependencies\"]\n",
    "        if deps and (any([dep not in observations for dep in deps])):\n",
    "            # Dependencies not yet satisfied\n",
    "            time.sleep(retry_after)\n",
    "            continue\n",
    "        schedule_task.invoke({\"task\": task, \"observations\": observations})\n",
    "        break\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def schedule_tasks(scheduler_input: SchedulerInput) -> List[FunctionMessage]:\n",
    "    \"\"\"Group the tasks into a DAG schedule.\"\"\"\n",
    "    # For streaming, we are making a few simplifying assumption:\n",
    "    # 1. The LLM does not create cyclic dependencies\n",
    "    # 2. That the LLM will not generate tasks with future deps\n",
    "    # If this ceases to be a good assumption, you can either\n",
    "    # adjust to do a proper topological sort (not-stream)\n",
    "    # or use a more complicated data structure\n",
    "    tasks = scheduler_input[\"tasks\"]\n",
    "    args_for_tasks = {}\n",
    "    messages = scheduler_input[\"messages\"]\n",
    "    # If we are re-planning, we may have calls that depend on previous\n",
    "    # plans. Start with those.\n",
    "    observations = _get_observations(messages)\n",
    "    task_names = {}\n",
    "    originals = set(observations)\n",
    "    # ^^ We assume each task inserts a different key above to\n",
    "    # avoid race conditions...\n",
    "    futures = []\n",
    "    retry_after = 0.25  # Retry every quarter second\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for task in tasks:\n",
    "            deps = task[\"dependencies\"]\n",
    "            task_names[task[\"idx\"]] = (\n",
    "                task[\"tool\"] if isinstance(task[\"tool\"], str) else task[\"tool\"].name\n",
    "            )\n",
    "            args_for_tasks[task[\"idx\"]] = task[\"args\"]\n",
    "            if (\n",
    "                # Depends on other tasks\n",
    "                deps\n",
    "                and (any([dep not in observations for dep in deps]))\n",
    "            ):\n",
    "                futures.append(\n",
    "                    executor.submit(\n",
    "                        schedule_pending_task, task, observations, retry_after\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # No deps or all deps satisfied\n",
    "                # can schedule now\n",
    "                schedule_task.invoke(dict(task=task, observations=observations))\n",
    "                # futures.append(executor.submit(schedule_task.invoke dict(task=task, observations=observations)))\n",
    "\n",
    "        # All tasks have been submitted or enqueued\n",
    "        # Wait for them to complete\n",
    "        wait(futures)\n",
    "    # Convert observations to new tool messages to add to the state\n",
    "    new_observations = {\n",
    "        k: (task_names[k], args_for_tasks[k], observations[k])\n",
    "        for k in sorted(observations.keys() - originals)\n",
    "    }\n",
    "    tool_messages = [\n",
    "        FunctionMessage(\n",
    "            name=name, content=str(obs), additional_kwargs={\"idx\": k, \"args\": task_args}\n",
    "        )\n",
    "        for k, (name, task_args, obs) in new_observations.items()\n",
    "    ]\n",
    "    return tool_messages"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "052f6b16-103a-40e9-94dd-8fcc37e77ba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:15:47.012258Z",
     "start_time": "2024-05-23T10:15:47.009466Z"
    }
   },
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "def plan_and_schedule(messages: List[BaseMessage], config):\n",
    "    tasks = planner.stream(messages, config)\n",
    "    # Begin executing the planner immediately\n",
    "    try:\n",
    "        tasks = itertools.chain([next(tasks)], tasks)\n",
    "    except StopIteration:\n",
    "        # Handle the case where tasks is empty.\n",
    "        tasks = iter([])\n",
    "    scheduled_tasks = schedule_tasks.invoke(\n",
    "        {\n",
    "            \"messages\": messages,\n",
    "            \"tasks\": tasks,\n",
    "        },\n",
    "        config,\n",
    "    )\n",
    "    return scheduled_tasks"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "9efa15ae-817a-48c6-86ed-16bc112fedc5",
   "metadata": {},
   "source": [
    "#### Example Plan\n",
    "\n",
    "We still haven't introduced any cycles in our computation graph, so this is all easily expressed in LCEL."
   ]
  },
  {
   "cell_type": "code",
   "id": "55142257-2674-4a47-988e-0d2810917329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:15:58.039311Z",
     "start_time": "2024-05-23T10:15:53.489614Z"
    }
   },
   "source": [
    "tool_messages = plan_and_schedule.invoke([HumanMessage(content=example_question)])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "a98e0525-2fcf-4fa1-baf6-79858bb8a6bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:15:59.144191Z",
     "start_time": "2024-05-23T10:15:59.141829Z"
    }
   },
   "source": [
    "tool_messages"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionMessage(content=\"[{'url': 'http://www.sfchronicle.com/weather-forecast/article/sf-bay-area-heat-19468160.php', 'content': 'Advertisement Article continues below this ad Highs will reach the mid-60s in the Richmond and Sunset districts, upper 60s in the Presidio and the low 70s in Pacific Heights, Glen Park, the Marina District and the Embarcadero. He joins the Chronicle from the University of Washington where he was previously the president of the campus weather forecasting team and an editor at the student newspaper, The Daily UW.  It will be warmer away from the beaches, in the low 70s in San Bruno and South San Francisco, the mid-70s in San Mateo and near 80 in Redwood City and Menlo Park. Tuesday will likely be the city’s warmest day since May 10, when the high was 78. Advertisement Article continues below this ad Inland portions of the North Bay, East Bay and South Bay will be even hotter. The sea breeze should become stronger as the week progresses, and Thursday afternoon may be particularly windy through the Golden Gate, along the Peninsula, near the delta and over Altamont Pass. '}]\", additional_kwargs={'idx': 1, 'args': {'query': 'current temperature in San Francisco'}}, name='tavily_search_results_json'),\n",
       " FunctionMessage(content='512000', additional_kwargs={'idx': 2, 'args': {'problem': 'what is the temperature raised to the 3rd power?', 'context': ['$1']}}, name='math'),\n",
       " FunctionMessage(content='join', additional_kwargs={'idx': 3, 'args': ()}, name='join')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "563d5311-55f0-4ca1-afbd-01fd970cf3e3",
   "metadata": {},
   "source": [
    "## 4. \"Joiner\" \n",
    "\n",
    "So now we have the planning and initial execution done. We need a component to process these outputs and either:\n",
    "\n",
    "1. Respond with the correct answer.\n",
    "2. Loop with a new plan.\n",
    "\n",
    "The paper refers to this as the \"joiner\". It's another LLM call. We are using function calling to improve parsing reliability."
   ]
  },
  {
   "cell_type": "code",
   "id": "942dab42-ad42-4ba2-90d5-49edbe4fae68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:16:45.905231Z",
     "start_time": "2024-05-23T10:16:44.986492Z"
    }
   },
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.chains.openai_functions import create_structured_output_runnable\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "class FinalResponse(BaseModel):\n",
    "    \"\"\"The final response/answer.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Replan(BaseModel):\n",
    "    feedback: str = Field(\n",
    "        description=\"Analysis of the previous attempts and recommendations on what needs to be fixed.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class JoinOutputs(BaseModel):\n",
    "    \"\"\"Decide whether to replan or whether you can return the final response.\"\"\"\n",
    "\n",
    "    thought: str = Field(\n",
    "        description=\"The chain of thought reasoning for the selected action\"\n",
    "    )\n",
    "    action: Union[FinalResponse, Replan]\n",
    "\n",
    "\n",
    "joiner_prompt = hub.pull(\"wfh/llm-compiler-joiner\").partial(\n",
    "    examples=\"\"\n",
    ")  # You can optionally add examples\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "runnable = create_structured_output_runnable(JoinOutputs, llm, joiner_prompt)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "fb50c4cd-947c-4a5d-a9f7-f0d92a10600f",
   "metadata": {},
   "source": [
    "We will select only the most recent messages in the state, and format the output to be more useful for\n",
    "the planner, should the agent need to loop."
   ]
  },
  {
   "cell_type": "code",
   "id": "951a33cf-2a05-4a33-899a-0ab1d97122fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:16:47.938995Z",
     "start_time": "2024-05-23T10:16:47.936323Z"
    }
   },
   "source": [
    "def _parse_joiner_output(decision: JoinOutputs) -> List[BaseMessage]:\n",
    "    response = [AIMessage(content=f\"Thought: {decision.thought}\")]\n",
    "    if isinstance(decision.action, Replan):\n",
    "        return response + [\n",
    "            SystemMessage(\n",
    "                content=f\"Context from last attempt: {decision.action.feedback}\"\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        return response + [AIMessage(content=decision.action.response)]\n",
    "\n",
    "\n",
    "def select_recent_messages(messages: list) -> dict:\n",
    "    selected = []\n",
    "    for msg in messages[::-1]:\n",
    "        selected.append(msg)\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            break\n",
    "    return {\"messages\": selected[::-1]}\n",
    "\n",
    "\n",
    "joiner = select_recent_messages | runnable | _parse_joiner_output"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "1e49d4b1-8266-4520-a566-1448b1c31c8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:16:49.277066Z",
     "start_time": "2024-05-23T10:16:49.275228Z"
    }
   },
   "source": [
    "input_messages = [HumanMessage(content=example_question)] + tool_messages"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "31854dfd-b82f-4c24-9b58-6bae66777909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:16:51.955299Z",
     "start_time": "2024-05-23T10:16:49.860455Z"
    }
   },
   "source": [
    "joiner.invoke(input_messages)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Thought: The temperature in San Francisco is in the range of low 70s. For calculation purposes, we'll use 70°F. Raising it to the 3rd power results in 70^3, which is 343,000.\"),\n",
       " AIMessage(content='The temperature in San Francisco raised to the 3rd power is approximately 343,000.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "b099e5ee-2c23-47d9-9387-0f64e02627d3",
   "metadata": {},
   "source": [
    "## 5. Compose using LangGraph\n",
    "\n",
    "We'll define the agent as a stateful graph, with the main nodes being:\n",
    "\n",
    "1. Plan and execute (the DAG from the first step above)\n",
    "2. Join: determine if we should finish or replan\n",
    "3. Recontextualize: update the graph state based on the output from the joiner"
   ]
  },
  {
   "cell_type": "code",
   "id": "768b5f11-e3d2-47be-8143-a7dcd8765243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:27:59.601978Z",
     "start_time": "2024-05-23T10:27:59.598901Z"
    }
   },
   "source": [
    "from langgraph.graph import MessageGraph, END\n",
    "from typing import Dict\n",
    "\n",
    "graph_builder = MessageGraph()\n",
    "\n",
    "# 1.  Define vertices\n",
    "# We defined plan_and_schedule above already\n",
    "# Assign each node to a state variable to update\n",
    "graph_builder.add_node(\"plan_and_schedule\", plan_and_schedule)\n",
    "graph_builder.add_node(\"join\", joiner)\n",
    "\n",
    "\n",
    "## Define edges\n",
    "graph_builder.add_edge(\"plan_and_schedule\", \"join\")\n",
    "\n",
    "### This condition determines looping logic\n",
    "\n",
    "\n",
    "def should_continue(state: List[BaseMessage]):\n",
    "    if isinstance(state[-1], AIMessage):\n",
    "        return END\n",
    "    return \"plan_and_schedule\"\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"join\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "graph_builder.set_entry_point(\"plan_and_schedule\")\n",
    "chain = graph_builder.compile()"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:28:06.954705Z",
     "start_time": "2024-05-23T10:28:05.960621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(chain.get_graph(xray=True).draw_mermaid_png()))"
   ],
   "id": "90cb08a00131c9c5",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to render the graph using the Mermaid.INK API. Status code: 400.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image, display\n\u001B[0;32m----> 3\u001B[0m display(Image(\u001B[43mchain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxray\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw_mermaid_png\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m))\n",
      "File \u001B[0;32m~/.virtualenvs/generative_ai/lib/python3.11/site-packages/langchain_core/runnables/graph.py:454\u001B[0m, in \u001B[0;36mGraph.draw_mermaid_png\u001B[0;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding)\u001B[0m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrunnables\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraph_mermaid\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m draw_mermaid_png\n\u001B[1;32m    449\u001B[0m mermaid_syntax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdraw_mermaid(\n\u001B[1;32m    450\u001B[0m     curve_style\u001B[38;5;241m=\u001B[39mcurve_style,\n\u001B[1;32m    451\u001B[0m     node_colors\u001B[38;5;241m=\u001B[39mnode_colors,\n\u001B[1;32m    452\u001B[0m     wrap_label_n_words\u001B[38;5;241m=\u001B[39mwrap_label_n_words,\n\u001B[1;32m    453\u001B[0m )\n\u001B[0;32m--> 454\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw_mermaid_png\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmermaid_syntax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmermaid_syntax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_file_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_file_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdraw_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdraw_method\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbackground_color\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackground_color\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/generative_ai/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:156\u001B[0m, in \u001B[0;36mdraw_mermaid_png\u001B[0;34m(mermaid_syntax, output_file_path, draw_method, background_color, padding)\u001B[0m\n\u001B[1;32m    150\u001B[0m     img_bytes \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mrun(\n\u001B[1;32m    151\u001B[0m         _render_mermaid_using_pyppeteer(\n\u001B[1;32m    152\u001B[0m             mermaid_syntax, output_file_path, background_color, padding\n\u001B[1;32m    153\u001B[0m         )\n\u001B[1;32m    154\u001B[0m     )\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m draw_method \u001B[38;5;241m==\u001B[39m MermaidDrawMethod\u001B[38;5;241m.\u001B[39mAPI:\n\u001B[0;32m--> 156\u001B[0m     img_bytes \u001B[38;5;241m=\u001B[39m \u001B[43m_render_mermaid_using_api\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmermaid_syntax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_file_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackground_color\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    160\u001B[0m     supported_methods \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([m\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m MermaidDrawMethod])\n",
      "File \u001B[0;32m~/.virtualenvs/generative_ai/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:279\u001B[0m, in \u001B[0;36m_render_mermaid_using_api\u001B[0;34m(mermaid_syntax, output_file_path, background_color)\u001B[0m\n\u001B[1;32m    277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img_bytes\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 279\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to render the graph using the Mermaid.INK API. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStatus code: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Failed to render the graph using the Mermaid.INK API. Status code: 400."
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "9f8c9849-8531-463d-a0ef-dcc3d9888b2d",
   "metadata": {},
   "source": [
    "#### Simple question\n",
    "\n",
    "Let's ask a simple question of the agent."
   ]
  },
  {
   "cell_type": "code",
   "id": "5bc4584a-e31c-4065-805e-76a6db30676a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:23:39.008057Z",
     "start_time": "2024-05-23T10:23:15.223270Z"
    }
   },
   "source": [
    "for step in chain.stream([HumanMessage(content=\"What's the GDP of New York?\")]):\n",
    "    print(step)\n",
    "    print(\"---\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://www.nbcnewyork.com/news/national-international/many-large-u-s-cities-are-in-deep-financial-trouble-heres-why/5352780/\\', \\'content\\': \\'\"If I don\\\\\\'t pay that invoice, I don\\\\\\'t have to include it in my balanced budget,\" said Sheila Weinberg, the group\\\\\\'s founder and CEO. Truth in Accounting estimates that 53 of the largest cities in the U.S. were not generating enough revenue to pay their bills at the end of fiscal year 2022. For example, New York City had a total public debt of $177.6 billion at the end of fiscal year 2022, according to researchers at Truth in Accounting, a nonprofit that partners with the University of Denver to promote transparency in public accounting. Lander in 2024 voiced support for a $12 billion expansion of New York City\\\\\\'s debt limit to fund existing city services like community colleges and the police department, alongside an expansionary capital program in the face of issues such as the climate crisis. That estimate comes in higher than the one quoted by New York City Comptroller Brad Lander, who says the Big Apple has a public debt burden of roughly $96 billion in 2024 — about $30 billion shy of the city\\\\\\'s debt limit.  In New York City, Mayor Eric Adams has introduced a \"Program to Eliminate the Gap\" which called for three separate 5% city program spending cuts that will affect services including sanitation, library access, public education, stewardships of jails and more. \\'}]', additional_kwargs={'idx': 1, 'args': {'query': 'GDP of New York'}}, name='tavily_search_results_json', id='de8e0d71-23e9-4848-b366-3977199c52ee'), FunctionMessage(content='join', additional_kwargs={'idx': 2, 'args': ()}, name='join', id='71ff3445-ae00-4bb3-99a6-f76e1756262e')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join': [AIMessage(content=\"Thought: The search results provided information on New York City's public debt but did not include the GDP of New York.\", id='b14a712c-cefc-4d74-9b2f-f95512969b34'), SystemMessage(content=\"Context from last attempt: The search results did not provide the GDP of New York. We need to search again specifically for New York's GDP.\", id='0715ff2c-5994-48c1-8f07-acf2c3fdf8c6')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://www.nbcnewyork.com/news/national-international/many-large-u-s-cities-are-in-deep-financial-trouble-heres-why/5352780/\\', \\'content\\': \\'\"If I don\\\\\\'t pay that invoice, I don\\\\\\'t have to include it in my balanced budget,\" said Sheila Weinberg, the group\\\\\\'s founder and CEO. Truth in Accounting estimates that 53 of the largest cities in the U.S. were not generating enough revenue to pay their bills at the end of fiscal year 2022. For example, New York City had a total public debt of $177.6 billion at the end of fiscal year 2022, according to researchers at Truth in Accounting, a nonprofit that partners with the University of Denver to promote transparency in public accounting. Lander in 2024 voiced support for a $12 billion expansion of New York City\\\\\\'s debt limit to fund existing city services like community colleges and the police department, alongside an expansionary capital program in the face of issues such as the climate crisis. That estimate comes in higher than the one quoted by New York City Comptroller Brad Lander, who says the Big Apple has a public debt burden of roughly $96 billion in 2024 — about $30 billion shy of the city\\\\\\'s debt limit.  In New York City, Mayor Eric Adams has introduced a \"Program to Eliminate the Gap\" which called for three separate 5% city program spending cuts that will affect services including sanitation, library access, public education, stewardships of jails and more. \\'}]', additional_kwargs={'idx': 3, 'args': {'query': 'GDP of New York 2023'}}, name='tavily_search_results_json', id='446af1ab-14fa-4922-9f52-94bda1ec06c8')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join': [AIMessage(content=\"Thought: The search results still did not provide the GDP of New York. We need to search again specifically for New York's GDP.\", id='749983b6-ae37-4370-a2b2-d33ed1623338'), SystemMessage(content=\"Context from last attempt: The search results provided information on New York City's public debt and fiscal challenges but did not include the GDP of New York. We need to refine the search to find the specific GDP information.\", id='e8f86c70-c5fe-4371-9fad-322743277590')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://www.nbcnewyork.com/news/national-international/many-large-u-s-cities-are-in-deep-financial-trouble-heres-why/5352780/\\', \\'content\\': \\'\"If I don\\\\\\'t pay that invoice, I don\\\\\\'t have to include it in my balanced budget,\" said Sheila Weinberg, the group\\\\\\'s founder and CEO. Truth in Accounting estimates that 53 of the largest cities in the U.S. were not generating enough revenue to pay their bills at the end of fiscal year 2022. For example, New York City had a total public debt of $177.6 billion at the end of fiscal year 2022, according to researchers at Truth in Accounting, a nonprofit that partners with the University of Denver to promote transparency in public accounting. Lander in 2024 voiced support for a $12 billion expansion of New York City\\\\\\'s debt limit to fund existing city services like community colleges and the police department, alongside an expansionary capital program in the face of issues such as the climate crisis. That estimate comes in higher than the one quoted by New York City Comptroller Brad Lander, who says the Big Apple has a public debt burden of roughly $96 billion in 2024 — about $30 billion shy of the city\\\\\\'s debt limit.  In New York City, Mayor Eric Adams has introduced a \"Program to Eliminate the Gap\" which called for three separate 5% city program spending cuts that will affect services including sanitation, library access, public education, stewardships of jails and more. \\'}]', additional_kwargs={'idx': 4, 'args': {'query': 'GDP of New York 2023'}}, name='tavily_search_results_json', id='6ce2ccdb-1e3a-4ffd-a0f1-90e027a3d42e')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join': [AIMessage(content=\"Thought: The search results repeatedly provided information on New York City's public debt and fiscal challenges but did not include the GDP of New York. We need to refine the search to find the specific GDP information.\", id='94a13556-6e53-4d9d-b084-7477e6d80483'), SystemMessage(content=\"Context from last attempt: The search results continue to provide information on New York City's public debt and fiscal issues without addressing the GDP. A more targeted search or different source may be necessary to retrieve the correct data.\", id='d246df95-e8b8-4ad7-b6e6-9aae6046da76')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://www.nbcnewyork.com/news/national-international/many-large-u-s-cities-are-in-deep-financial-trouble-heres-why/5352780/\\', \\'content\\': \\'\"If I don\\\\\\'t pay that invoice, I don\\\\\\'t have to include it in my balanced budget,\" said Sheila Weinberg, the group\\\\\\'s founder and CEO. Truth in Accounting estimates that 53 of the largest cities in the U.S. were not generating enough revenue to pay their bills at the end of fiscal year 2022. For example, New York City had a total public debt of $177.6 billion at the end of fiscal year 2022, according to researchers at Truth in Accounting, a nonprofit that partners with the University of Denver to promote transparency in public accounting. Lander in 2024 voiced support for a $12 billion expansion of New York City\\\\\\'s debt limit to fund existing city services like community colleges and the police department, alongside an expansionary capital program in the face of issues such as the climate crisis. That estimate comes in higher than the one quoted by New York City Comptroller Brad Lander, who says the Big Apple has a public debt burden of roughly $96 billion in 2024 — about $30 billion shy of the city\\\\\\'s debt limit.  In New York City, Mayor Eric Adams has introduced a \"Program to Eliminate the Gap\" which called for three separate 5% city program spending cuts that will affect services including sanitation, library access, public education, stewardships of jails and more. \\'}]', additional_kwargs={'idx': 5, 'args': {'query': 'New York GDP 2023'}}, name='tavily_search_results_json', id='89564f20-4c72-43f0-ad44-a96d31acd1f2')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join': [AIMessage(content='Thought: The repeated search results have not provided the GDP of New York, only details on its public debt and fiscal issues. Further attempts have not yielded the needed information.', id='fbd58e9c-7704-4f4b-8952-2c34004ab94f'), SystemMessage(content=\"Context from last attempt: The previous attempts to find the GDP of New York have repeatedly resulted in information about the city's public debt and fiscal issues. A different approach or source is needed to retrieve the correct data.\", id='a440bfa9-7d06-47e8-ba83-a55cde9b56cf')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://www.nbcnewyork.com/news/national-international/many-large-u-s-cities-are-in-deep-financial-trouble-heres-why/5352780/\\', \\'content\\': \\'\"If I don\\\\\\'t pay that invoice, I don\\\\\\'t have to include it in my balanced budget,\" said Sheila Weinberg, the group\\\\\\'s founder and CEO. Truth in Accounting estimates that 53 of the largest cities in the U.S. were not generating enough revenue to pay their bills at the end of fiscal year 2022. For example, New York City had a total public debt of $177.6 billion at the end of fiscal year 2022, according to researchers at Truth in Accounting, a nonprofit that partners with the University of Denver to promote transparency in public accounting. Lander in 2024 voiced support for a $12 billion expansion of New York City\\\\\\'s debt limit to fund existing city services like community colleges and the police department, alongside an expansionary capital program in the face of issues such as the climate crisis. That estimate comes in higher than the one quoted by New York City Comptroller Brad Lander, who says the Big Apple has a public debt burden of roughly $96 billion in 2024 — about $30 billion shy of the city\\\\\\'s debt limit.  In New York City, Mayor Eric Adams has introduced a \"Program to Eliminate the Gap\" which called for three separate 5% city program spending cuts that will affect services including sanitation, library access, public education, stewardships of jails and more. \\'}]', additional_kwargs={'idx': 6, 'args': {'query': 'GDP of New York 2023'}}, name='tavily_search_results_json', id='73181dfe-7e90-459e-9f9f-a98738926bb2'), FunctionMessage(content='join', additional_kwargs={'idx': 7, 'args': ()}, name='join', id='0672193b-fb43-4588-af61-7f3a2078f421')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join': [AIMessage(content=\"Thought: Repeated searches have not provided the GDP of New York, only details on its public debt and fiscal issues. I will inform the user about the difficulty in finding the exact GDP information and suggest they search for specific sources like the U.S. Bureau of Economic Analysis or New York City's official economic reports.\", id='b7aa595b-77a4-4180-89ea-e49eb96b7c46'), AIMessage(content=\"I wasn't able to find the specific GDP of New York from the search results. You might want to check official sources like the U.S. Bureau of Economic Analysis or New York City's official economic reports for the most accurate information.\", id='f6f4c593-b87e-4c15-bffe-e028b4de449f')]}\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "b96efd08-5314-44f0-a694-3073b638adad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:24:30.561267Z",
     "start_time": "2024-05-23T10:24:30.553410Z"
    }
   },
   "source": [
    "# Final answer\n",
    "print(step[END][-1].content)"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__end__'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Final answer\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mstep\u001B[49m\u001B[43m[\u001B[49m\u001B[43mEND\u001B[49m\u001B[43m]\u001B[49m[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mcontent)\n",
      "\u001B[0;31mKeyError\u001B[0m: '__end__'"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "33c65ef5-b4b2-4ab2-8c78-a551da7819b9",
   "metadata": {},
   "source": [
    "#### Multi-hop question\n",
    "\n",
    "This question requires that the agent perform multiple searches."
   ]
  },
  {
   "cell_type": "code",
   "id": "0b3a0916-d8ca-4092-b91c-d9e2b05259d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:28:38.397796Z",
     "start_time": "2024-05-23T10:28:18.300384Z"
    }
   },
   "source": [
    "steps = chain.stream(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"What's the oldest parrot alive, and how much longer is that than the average?\"\n",
    "        )\n",
    "    ],\n",
    "    {\n",
    "        \"recursion_limit\": 100,\n",
    "    },\n",
    ")\n",
    "for step in steps:\n",
    "    print(step)\n",
    "    print(\"---\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://www.foxnews.com/world/worlds-oldest-known-gorilla-turns-67-berlin-zoo\\', \\'content\\': \\'Berlin\\\\\\'s zoo is celebrating the 67th birthday of Fatou the gorilla, its oldest resident, who it believes is also the oldest gorilla in the world.  Berlin\\\\\\'s zoo is celebrating the 67th birthday of Fatou the gorilla, its oldest resident, who it believes is also the oldest gorilla in the world. (Paul Zinken/dpa via AP) Vet Andre Schüle said there is no gorilla older than Fatou in any other zoo, \"and we have to assume that there is no animal older than her in the wild,\" where animals do not live so long.  CLICK HERE TO GET THE FOX NEWS APP Fatou became the zoo\\\\\\'s oldest resident only recently, following the death earlier this year of Ingo the flamingo. NEW ENGLAND AQUARIUM\\\\\\'S 500-POUND, 95-YEAR-OLD SEA TURTLE GETS CLEAN BILL OF HEALTH Fatou was born in 1957 and came to the zoo in what was then West Berlin in 1959.\\'}]', additional_kwargs={'idx': 1, 'args': {'query': 'oldest parrot alive'}}, name='tavily_search_results_json', id='1a96f7d1-5238-4fed-ad9a-50d76b9be9a9'), FunctionMessage(content=\"[{'url': 'https://www.engadget.com/parrots-in-captivity-seem-to-enjoy-video-chatting-with-their-friends-on-messenger-165911437.html', 'content': 'In each session, the parrots were allowed to make up to two calls, and the researchers found that those chatting over Messenger hit this limit 46 percent of the time, compared to almost half that when they were watching pre-recorded videos. The research builds on findings from a series of small studies over the last few years, including one in which the team trained pet parrots to make video calls to each other (with human assistance) and another where they were taught to play tablet games. “The internet holds a great deal of potential for giving animals agency to interact with each other in new ways, but the systems we build to help them do that need to be designed around their specific needs and physical and mental abilities,” said Dr. Hirskyj-Douglas. During that time, the parrots — who’d been introduced to each other at the beginning over video chat — were able to engage in calls amongst themselves of up to three hours long over a total of 12 sessions. “The appearance of ‘liveness’ really did seem to make a difference to the parrots’ engagement with their screens,” said Dr. Ilyena Hirskyj-Douglas, though noting that further study would be needed before definite conclusions can be drawn.'}]\", additional_kwargs={'idx': 2, 'args': {'query': 'average lifespan of a parrot'}}, name='tavily_search_results_json', id='e3380aa7-4b83-4de3-b8a1-824bda587c60'), FunctionMessage(content='join', additional_kwargs={'idx': 3, 'args': ()}, name='join', id='0b012f8b-99ad-4cb7-bc6e-90b3418e0eba')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join': [AIMessage(content='Thought: The search results do not provide any information about the oldest parrot alive or how much longer it has lived compared to the average lifespan of parrots.', id='2232465b-dab1-4319-8b73-03309bde1ecb'), SystemMessage(content='Context from last attempt: The search results did not return relevant information about the oldest parrot alive or its age compared to the average lifespan of parrots. A more specific search focused on parrots is needed.', id='1685770e-ce68-4c5d-b9fd-c640191f5ed0')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://www.foxnews.com/world/worlds-oldest-known-gorilla-turns-67-berlin-zoo\\', \\'content\\': \\'Berlin\\\\\\'s zoo is celebrating the 67th birthday of Fatou the gorilla, its oldest resident, who it believes is also the oldest gorilla in the world.  Berlin\\\\\\'s zoo is celebrating the 67th birthday of Fatou the gorilla, its oldest resident, who it believes is also the oldest gorilla in the world. (Paul Zinken/dpa via AP) Vet Andre Schüle said there is no gorilla older than Fatou in any other zoo, \"and we have to assume that there is no animal older than her in the wild,\" where animals do not live so long.  CLICK HERE TO GET THE FOX NEWS APP Fatou became the zoo\\\\\\'s oldest resident only recently, following the death earlier this year of Ingo the flamingo. NEW ENGLAND AQUARIUM\\\\\\'S 500-POUND, 95-YEAR-OLD SEA TURTLE GETS CLEAN BILL OF HEALTH Fatou was born in 1957 and came to the zoo in what was then West Berlin in 1959.\\'}]', additional_kwargs={'idx': 4, 'args': {'query': 'oldest parrot alive 2023'}}, name='tavily_search_results_json', id='2adc5707-9548-4cf0-80bb-1c95cf55168e'), FunctionMessage(content=\"[{'url': 'https://www.engadget.com/parrots-in-captivity-seem-to-enjoy-video-chatting-with-their-friends-on-messenger-165911437.html', 'content': 'In each session, the parrots were allowed to make up to two calls, and the researchers found that those chatting over Messenger hit this limit 46 percent of the time, compared to almost half that when they were watching pre-recorded videos. The research builds on findings from a series of small studies over the last few years, including one in which the team trained pet parrots to make video calls to each other (with human assistance) and another where they were taught to play tablet games. “The internet holds a great deal of potential for giving animals agency to interact with each other in new ways, but the systems we build to help them do that need to be designed around their specific needs and physical and mental abilities,” said Dr. Hirskyj-Douglas. During that time, the parrots — who’d been introduced to each other at the beginning over video chat — were able to engage in calls amongst themselves of up to three hours long over a total of 12 sessions. “The appearance of ‘liveness’ really did seem to make a difference to the parrots’ engagement with their screens,” said Dr. Ilyena Hirskyj-Douglas, though noting that further study would be needed before definite conclusions can be drawn.'}]\", additional_kwargs={'idx': 5, 'args': {'query': 'average lifespan of parrots'}}, name='tavily_search_results_json', id='c4e4ae20-72bd-4613-ae43-3292a8932275'), FunctionMessage(content='join', additional_kwargs={'idx': 6, 'args': ()}, name='join', id='022f0eba-791c-4750-a60e-e3d5e318cf5f')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join': [AIMessage(content='Thought: The search results still do not provide any information about the oldest parrot alive or its age compared to the average lifespan of parrots. A more targeted search is needed to find this specific information.', id='13caecba-0a36-459f-aadf-d7f6ec0439ef'), SystemMessage(content='Context from last attempt: The current search results are irrelevant. A more focused search on the oldest parrot alive and the average lifespan of parrots is required.', id='fe521f22-0a31-4f62-ad77-99bbde04c0fc')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='[{\\'url\\': \\'https://www.foxnews.com/world/worlds-oldest-known-gorilla-turns-67-berlin-zoo\\', \\'content\\': \\'Berlin\\\\\\'s zoo is celebrating the 67th birthday of Fatou the gorilla, its oldest resident, who it believes is also the oldest gorilla in the world.  Berlin\\\\\\'s zoo is celebrating the 67th birthday of Fatou the gorilla, its oldest resident, who it believes is also the oldest gorilla in the world. (Paul Zinken/dpa via AP) Vet Andre Schüle said there is no gorilla older than Fatou in any other zoo, \"and we have to assume that there is no animal older than her in the wild,\" where animals do not live so long.  CLICK HERE TO GET THE FOX NEWS APP Fatou became the zoo\\\\\\'s oldest resident only recently, following the death earlier this year of Ingo the flamingo. NEW ENGLAND AQUARIUM\\\\\\'S 500-POUND, 95-YEAR-OLD SEA TURTLE GETS CLEAN BILL OF HEALTH Fatou was born in 1957 and came to the zoo in what was then West Berlin in 1959.\\'}]', additional_kwargs={'idx': 7, 'args': {'query': 'oldest parrot alive'}}, name='tavily_search_results_json', id='2c31b459-72be-4460-93b7-e003ef883a7d'), FunctionMessage(content=\"[{'url': 'https://www.engadget.com/parrots-in-captivity-seem-to-enjoy-video-chatting-with-their-friends-on-messenger-165911437.html', 'content': 'In each session, the parrots were allowed to make up to two calls, and the researchers found that those chatting over Messenger hit this limit 46 percent of the time, compared to almost half that when they were watching pre-recorded videos. The research builds on findings from a series of small studies over the last few years, including one in which the team trained pet parrots to make video calls to each other (with human assistance) and another where they were taught to play tablet games. “The internet holds a great deal of potential for giving animals agency to interact with each other in new ways, but the systems we build to help them do that need to be designed around their specific needs and physical and mental abilities,” said Dr. Hirskyj-Douglas. During that time, the parrots — who’d been introduced to each other at the beginning over video chat — were able to engage in calls amongst themselves of up to three hours long over a total of 12 sessions. “The appearance of ‘liveness’ really did seem to make a difference to the parrots’ engagement with their screens,” said Dr. Ilyena Hirskyj-Douglas, though noting that further study would be needed before definite conclusions can be drawn.'}]\", additional_kwargs={'idx': 8, 'args': {'query': 'average lifespan of parrots'}}, name='tavily_search_results_json', id='12cb554a-3a46-4c58-b2aa-d8ca42cc0802'), FunctionMessage(content='join', additional_kwargs={'idx': 9, 'args': ()}, name='join', id='54a66130-dff6-4ccf-98e0-2130715145bd')]}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join': [AIMessage(content='Thought: The search results are still irrelevant and do not provide information on the oldest parrot alive or its age relative to the average lifespan of parrots. As we have made multiple attempts without success, it is best to inform the user of our current status.', id='6dbf683a-3ead-411c-88ab-1fb0911b2f28'), AIMessage(content=\"I wasn't able to find specific information on the oldest parrot alive or how much longer it has lived compared to the average lifespan of parrots. You might want to try a more targeted search on this topic or consult a reliable database or expert on parrot lifespans.\", id='87bb461a-8358-4697-816d-82096f2efd47')]}\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "6c65c414-7668-4fdf-ba97-f42f659b1317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:28:45.129599Z",
     "start_time": "2024-05-23T10:28:45.122135Z"
    }
   },
   "source": [
    "# Final answer\n",
    "print(step[END][-1].content)"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__end__'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Final answer\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mstep\u001B[49m\u001B[43m[\u001B[49m\u001B[43mEND\u001B[49m\u001B[43m]\u001B[49m[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mcontent)\n",
      "\u001B[0;31mKeyError\u001B[0m: '__end__'"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "1b859bc7-1a85-4d35-b57b-f67c87282403",
   "metadata": {},
   "source": [
    "#### Multi-step  math"
   ]
  },
  {
   "cell_type": "code",
   "id": "38d3ea91-59ba-4267-8060-ed75bbc840c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:28:57.789187Z",
     "start_time": "2024-05-23T10:28:51.295989Z"
    }
   },
   "source": [
    "for step in chain.stream(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"What's ((3*(4+5)/0.5)+3245) + 8? What's 32/4.23? What's the sum of those two values?\"\n",
    "        )\n",
    "    ]\n",
    "):\n",
    "    print(step)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan_and_schedule': [FunctionMessage(content='3299.0', additional_kwargs={'idx': 1, 'args': {'problem': '3*(4+5)/0.5 + 3245'}}, name='math', id='996c6417-b012-4584-bc66-7467b6688666'), FunctionMessage(content='7.565011820330969', additional_kwargs={'idx': 2, 'args': {'problem': '32/4.23'}}, name='math', id='4ee57a16-eaee-4fda-ab68-5cafb626ab19'), FunctionMessage(content='join', additional_kwargs={'idx': 3, 'args': ()}, name='join', id='2b6df2f4-645e-491c-919d-efec894a76d9')]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join': [AIMessage(content='Thought: I have calculated the two values successfully. Now, I need to add them together to give the final answer.', id='fd5df46f-b757-4fae-8653-1854071f6ee2'), AIMessage(content='The sum of ((3*(4+5)/0.5)+3245) + 8 and 32/4.23 is 3306.565011820330969.', id='9a6b1a47-7d64-44c7-a88b-0f0a7f12eb29')]}\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "a6cf5fe0-f178-4197-950f-257711bff8d2",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T10:29:09.715245Z",
     "start_time": "2024-05-23T10:29:09.706971Z"
    }
   },
   "source": [
    "# Final answer\n",
    "print(step[END][-1].content)"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'__end__'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Final answer\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mstep\u001B[49m\u001B[43m[\u001B[49m\u001B[43mEND\u001B[49m\u001B[43m]\u001B[49m[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mcontent)\n",
      "\u001B[0;31mKeyError\u001B[0m: '__end__'"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "c647d5f3-5e00-4449-9cec-5a9f438c9cff",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congrats on building your first LLMCompiler agent! I'll leave you with some known limitations to the implementation above:\n",
    "\n",
    "1. The planner output parsing format is fragile if your function requires more than 1 or 2 arguments. We could make it more robust by using streaming tool calling.\n",
    "2. Variable substitution is fragile in the example above. It could be made more robust by using a fine-tuned model and a more robust syntax (using e.g., Lark or a tool calling schema)\n",
    "3. The state can grow quite long if you require multiple re-planning runs. To handle, you could add a message compressor once you go above a certain token limit.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
