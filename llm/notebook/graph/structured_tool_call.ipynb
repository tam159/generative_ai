{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-18T04:12:02.515521Z",
     "start_time": "2024-07-18T04:12:02.512928Z"
    }
   },
   "source": [
    "from typing import Optional\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.output_parsers import PydanticToolsParser, PydanticOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:08.657607Z",
     "start_time": "2024-07-18T04:06:08.652746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "9433bacbf912b873",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:08.688268Z",
     "start_time": "2024-07-18T04:06:08.658841Z"
    }
   },
   "cell_type": "code",
   "source": "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")",
   "id": "366ba7497d347025",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Structured Output",
   "id": "e7e8e9158036419"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tool Calling",
   "id": "7d0b8ea14acaf5a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:10.499672Z",
     "start_time": "2024-07-18T02:48:09.440050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(description=\"How funny the joke is, from 1 to 10\")\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ],
   "id": "72c3d7b07c021506",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why was the cat sitting on the computer?', punchline='To keep an eye on the mouse.', rating=7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Nested Schema (No Parallelism)",
   "id": "12c021cf4b7a6a5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:11.691891Z",
     "start_time": "2024-07-18T02:48:11.688638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConversationalResponse(BaseModel):\n",
    "    \"\"\"Respond in a conversational manner. Be kind and helpful.\"\"\"\n",
    "\n",
    "    response: str = Field(description=\"A conversational response to the user's query\")"
   ],
   "id": "8dfd786a5778cff2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:12.198190Z",
     "start_time": "2024-07-18T02:48:12.195728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Response(BaseModel):\n",
    "    output: Joke | ConversationalResponse"
   ],
   "id": "99ff6537d4ee58e3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:13.111851Z",
     "start_time": "2024-07-18T02:48:13.107859Z"
    }
   },
   "cell_type": "code",
   "source": "structured_llm = llm.with_structured_output(Response)",
   "id": "6953f92928b2b22",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:14.256937Z",
     "start_time": "2024-07-18T02:48:13.411438Z"
    }
   },
   "cell_type": "code",
   "source": "structured_llm.invoke(\"Tell me a joke about cats\")",
   "id": "f3167201466694ce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(output=Joke(setup='Why was the cat sitting on the computer?', punchline='To keep an eye on the mouse.', rating=8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:16.034318Z",
     "start_time": "2024-07-18T02:48:14.885279Z"
    }
   },
   "cell_type": "code",
   "source": "structured_llm.invoke(\"How are you today?\")",
   "id": "4d35b51897a09e2b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(output=ConversationalResponse(response=\"I'm just a computer program, so I don't have feelings, but I'm here to help you with anything you need. How can I assist you today?\"))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Streaming",
   "id": "2d0e08551c9c7d56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:20.686428Z",
     "start_time": "2024-07-18T02:48:20.682150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "json_schema = {\n",
    "    \"title\": \"joke\",\n",
    "    \"description\": \"Joke to tell user.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"setup\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The setup of the joke\",\n",
    "        },\n",
    "        \"punchline\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The punchline to the joke\",\n",
    "        },\n",
    "        \"rating\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"How funny the joke is, from 1 to 10\",\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"setup\", \"punchline\"],\n",
    "}\n",
    "structured_llm = llm.with_structured_output(json_schema)"
   ],
   "id": "8b96390d00f521ea",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:22.114029Z",
     "start_time": "2024-07-18T02:48:21.127384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in structured_llm.stream(\"Tell me a joke about cats\"):\n",
    "    print(chunk)"
   ],
   "id": "687452bca820cd0a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'setup': ''}\n",
      "{'setup': 'Why'}\n",
      "{'setup': 'Why was'}\n",
      "{'setup': 'Why was the'}\n",
      "{'setup': 'Why was the cat'}\n",
      "{'setup': 'Why was the cat sitting'}\n",
      "{'setup': 'Why was the cat sitting on'}\n",
      "{'setup': 'Why was the cat sitting on the'}\n",
      "{'setup': 'Why was the cat sitting on the computer'}\n",
      "{'setup': 'Why was the cat sitting on the computer?'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': ''}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'To'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'To keep'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'To keep an'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'To keep an eye'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'To keep an eye on'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'To keep an eye on the'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'To keep an eye on the mouse'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'To keep an eye on the mouse!'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'To keep an eye on the mouse!', 'rating': 8}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Few-Shot Learning",
   "id": "4ea4adec1318a53b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:23.535993Z",
     "start_time": "2024-07-18T02:48:22.632956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
    "Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\n",
    "\n",
    "Here are some examples of jokes:\n",
    "\n",
    "example_user: Tell me a joke about planes\n",
    "example_assistant: {{\"setup\": \"Why don't planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2}}\n",
    "\n",
    "example_user: Tell me another joke about planes\n",
    "example_assistant: {{\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10}}\n",
    "\n",
    "example_user: Now about caterpillars\n",
    "example_assistant: {{\"setup\": \"Caterpillar\", \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\", \"rating\": 5}}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")])\n",
    "\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke(\"what's something funny about woodpeckers\")"
   ],
   "id": "63e02e403d66696a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'setup': 'Wooden shoe',\n",
       " 'punchline': 'Wooden shoe like to know where all the woodpeckers have gone!',\n",
       " 'rating': 8}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:25.252434Z",
     "start_time": "2024-07-18T02:48:24.316440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "examples = [\n",
    "    HumanMessage(\"Tell me a joke about planes\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Why don't planes ever get tired?\",\n",
    "                    \"punchline\": \"Because they have rest wings!\",\n",
    "                    \"rating\": 2,\n",
    "                },\n",
    "                \"id\": \"1\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    # Most tool-calling models expect a ToolMessage(s) to follow an AIMessage with tool calls.\n",
    "    ToolMessage(\"\", tool_call_id=\"1\"),\n",
    "    # Some models also expect an AIMessage to follow any ToolMessages,\n",
    "    # so you may need to add an AIMessage here.\n",
    "    HumanMessage(\"Tell me another joke about planes\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Cargo\",\n",
    "                    \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\",\n",
    "                    \"rating\": 10,\n",
    "                },\n",
    "                \"id\": \"2\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"\", tool_call_id=\"2\"),\n",
    "    HumanMessage(\"Now about caterpillars\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Caterpillar\",\n",
    "                    \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\",\n",
    "                    \"rating\": 5,\n",
    "                },\n",
    "                \"id\": \"3\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"\", tool_call_id=\"3\"),\n",
    "]\n",
    "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
    "Return a joke which has the setup (the response to \"Who's there?\") \\\n",
    "and the final punchline (the response to \"<setup> who?\").\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system), (\"placeholder\", \"{examples}\"), (\"human\", \"{input}\")]\n",
    ")\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke({\"input\": \"crocodiles\", \"examples\": examples})"
   ],
   "id": "5f7aa912868e7a13",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'setup': 'Crocodile',\n",
       " 'punchline': \"Crocodile that's who! Don't mess with me, I snap back!\",\n",
       " 'rating': 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## JSON Mode (Not Recommended)",
   "id": "69da77c94668efe5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:27.070083Z",
     "start_time": "2024-07-18T02:48:26.212132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If using JSON mode you'll have to still specify the desired schema in the model prompt. The schema you pass to with_structured_output will only be used for parsing the model outputs, it will not be passed to the model the way it is with tool calling.\n",
    "structured_llm = llm.with_structured_output(Joke, method=\"json_mode\")\n",
    "\n",
    "structured_llm.invoke(\n",
    "    \"Tell me a joke about cats, respond in JSON with `setup` and `punchline` keys\"\n",
    ")"
   ],
   "id": "8135789c36ef3d6a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why was the cat sitting on the computer?', punchline='It wanted to keep an eye on the mouse!', rating=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Raw Outputs",
   "id": "3b3db97f8770cb5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:28.847342Z",
     "start_time": "2024-07-18T02:48:27.987478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "structured_llm = llm.with_structured_output(Joke, include_raw=True)\n",
    "\n",
    "structured_llm.invoke(\n",
    "    \"Tell me a joke about cats, respond in JSON with `setup` and `punchline` keys\"\n",
    ")"
   ],
   "id": "e058204bf2c4de82",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'raw': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WjbGYBOO8rd5HDq8yK4BhNr8', 'function': {'arguments': '{\"setup\":\"Why was the cat sitting on the computer?\",\"punchline\":\"It wanted to keep an eye on the mouse!\"}', 'name': 'Joke'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 114, 'total_tokens': 142}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0072665b-395c-4e64-be7c-5bc2801f985d-0', tool_calls=[{'name': 'Joke', 'args': {'setup': 'Why was the cat sitting on the computer?', 'punchline': 'It wanted to keep an eye on the mouse!'}, 'id': 'call_WjbGYBOO8rd5HDq8yK4BhNr8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 114, 'output_tokens': 28, 'total_tokens': 142}),\n",
       " 'parsed': Joke(setup='Why was the cat sitting on the computer?', punchline='It wanted to keep an eye on the mouse!', rating=None),\n",
       " 'parsing_error': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Schema in Prompt (Not Recommended)",
   "id": "8b3f5f95b38a0a3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:29.910396Z",
     "start_time": "2024-07-18T02:48:29.905877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    height_in_meters: float = Field(\n",
    "        ..., description=\"The height of the person expressed in meters.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: list[Person]\n",
    "\n",
    "\n",
    "# Set up a parser\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())"
   ],
   "id": "3e27f90e9be8758d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:31.180771Z",
     "start_time": "2024-07-18T02:48:31.175908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"Anna is 23 years old and she is 6 feet tall\"\n",
    "\n",
    "print(prompt.invoke(query).to_string())"
   ],
   "id": "a832e4d3d14a87cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Answer the user query. Wrap the output in `json` tags\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Identifying information about all people in a text.\", \"properties\": {\"people\": {\"title\": \"People\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Person\"}}}, \"required\": [\"people\"], \"definitions\": {\"Person\": {\"title\": \"Person\", \"description\": \"Information about a person.\", \"type\": \"object\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"The name of the person\", \"type\": \"string\"}, \"height_in_meters\": {\"title\": \"Height In Meters\", \"description\": \"The height of the person expressed in meters.\", \"type\": \"number\"}}, \"required\": [\"name\", \"height_in_meters\"]}}}\n",
      "```\n",
      "Human: Anna is 23 years old and she is 6 feet tall\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:33.816041Z",
     "start_time": "2024-07-18T02:48:32.912767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"query\": query})"
   ],
   "id": "dd6aa155deda66b5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Anna', height_in_meters=1.83)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Custom Parsing",
   "id": "9295bee17fd1c774"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:38.846167Z",
     "start_time": "2024-07-18T02:48:38.840054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    height_in_meters: float = Field(\n",
    "        ..., description=\"The height of the person expressed in meters.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: list[Person]\n",
    "\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Output your answer as JSON that  \"\n",
    "            \"matches the given schema: ```json\\n{schema}\\n```. \"\n",
    "            \"Make sure to wrap the answer in ```json and ``` tags\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(schema=People.schema())\n",
    "\n",
    "\n",
    "# Custom parser\n",
    "def extract_json(message: AIMessage) -> list[dict]:\n",
    "    \"\"\"Extracts JSON content from a string where JSON is embedded between ```json and ``` tags.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text containing the JSON content.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted JSON strings.\n",
    "    \"\"\"\n",
    "    text = message.content\n",
    "    # Define the regular expression pattern to match JSON blocks\n",
    "    pattern = r\"```json(.*?)```\"\n",
    "\n",
    "    # Find all non-overlapping matches of the pattern in the string\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    # Return the list of matched JSON strings, stripping any leading or trailing whitespace\n",
    "    try:\n",
    "        return [json.loads(match.strip()) for match in matches]\n",
    "    except Exception:\n",
    "        raise ValueError(f\"Failed to parse: {message}\")"
   ],
   "id": "3cdd1122abed5676",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:39.877666Z",
     "start_time": "2024-07-18T02:48:39.875058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"Anna is 23 years old and she is 6 feet tall\"\n",
    "\n",
    "print(prompt.format_prompt(query=query).to_string())"
   ],
   "id": "f9f9b7dd46ee1e0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Answer the user query. Output your answer as JSON that  matches the given schema: ```json\n",
      "{'title': 'People', 'description': 'Identifying information about all people in a text.', 'type': 'object', 'properties': {'people': {'title': 'People', 'type': 'array', 'items': {'$ref': '#/definitions/Person'}}}, 'required': ['people'], 'definitions': {'Person': {'title': 'Person', 'description': 'Information about a person.', 'type': 'object', 'properties': {'name': {'title': 'Name', 'description': 'The name of the person', 'type': 'string'}, 'height_in_meters': {'title': 'Height In Meters', 'description': 'The height of the person expressed in meters.', 'type': 'number'}}, 'required': ['name', 'height_in_meters']}}}\n",
      "```. Make sure to wrap the answer in ```json and ``` tags\n",
      "Human: Anna is 23 years old and she is 6 feet tall\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:49.012441Z",
     "start_time": "2024-07-18T02:48:40.437101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = prompt | ChatOpenAI(model=\"gpt-4o\") | extract_json\n",
    "\n",
    "chain.invoke({\"query\": query})"
   ],
   "id": "94039cc7346d192a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'People',\n",
       "  'description': 'Identifying information about all people in a text.',\n",
       "  'type': 'object',\n",
       "  'properties': {'people': {'title': 'People',\n",
       "    'type': 'array',\n",
       "    'items': {'$ref': '#/definitions/Person'}}},\n",
       "  'required': ['people'],\n",
       "  'definitions': {'Person': {'title': 'Person',\n",
       "    'description': 'Information about a person.',\n",
       "    'type': 'object',\n",
       "    'properties': {'name': {'title': 'Name',\n",
       "      'description': 'The name of the person',\n",
       "      'type': 'string'},\n",
       "     'height_in_meters': {'title': 'Height In Meters',\n",
       "      'description': 'The height of the person expressed in meters.',\n",
       "      'type': 'number'}},\n",
       "    'required': ['name', 'height_in_meters']}},\n",
       "  'people': [{'name': 'Anna', 'height_in_meters': 1.8288}]}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T02:48:53.080516Z",
     "start_time": "2024-07-18T02:48:53.078070Z"
    }
   },
   "cell_type": "code",
   "source": "# https://python.langchain.com/v0.2/docs/how_to/structured_output/",
   "id": "360d4a0d41d491dd",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Function/Tool Calling",
   "id": "712e82cd173d76f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:17.536825Z",
     "start_time": "2024-07-18T04:06:17.487273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ],
   "id": "87c2113ab75eb6b6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:17.958557Z",
     "start_time": "2024-07-18T04:06:17.954637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Note that the docstrings here are crucial, as they will be passed along\n",
    "# to the model along with the class name.\n",
    "class Add(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class Multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "tools = [Add, Multiply]"
   ],
   "id": "751f3af5ad930217",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:18.338132Z",
     "start_time": "2024-07-18T04:06:18.289590Z"
    }
   },
   "cell_type": "code",
   "source": "llm_with_tools = llm.bind_tools(tools)",
   "id": "630f6eb47ee98ff3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:20.048827Z",
     "start_time": "2024-07-18T04:06:18.732338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "llm_with_tools.invoke(query)"
   ],
   "id": "fa0f6b539a769dbc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_f1PxtpRgftli2RwvsStMsVfB', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'Multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 95, 'total_tokens': 113}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-02e3fc6a-7083-497d-a6c1-bb04bb109484-0', tool_calls=[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_f1PxtpRgftli2RwvsStMsVfB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 18, 'total_tokens': 113})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:21.024786Z",
     "start_time": "2024-07-18T04:06:20.050101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "llm_with_tools.invoke(query).tool_calls"
   ],
   "id": "5021708cc021d94b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'Multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': 'call_HTNCLsCAYrblmsGVLYVPtzfw',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'Add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': 'call_gpAnjFsjoJi2EnGlzYkzEV60',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:22.559222Z",
     "start_time": "2024-07-18T04:06:21.026437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = llm_with_tools | PydanticToolsParser(tools=[Multiply, Add])\n",
    "chain.invoke(query)"
   ],
   "id": "a6b6ba62af63a32a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Multiply(a=3, b=12), Add(a=11, b=49)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:23.270278Z",
     "start_time": "2024-07-18T04:06:22.560985Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke(\"what is 12 + 50\")",
   "id": "f175883b9f77fe74",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Add(a=12, b=50)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Streaming",
   "id": "c01a5ad7e2041131"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:24.873714Z",
     "start_time": "2024-07-18T04:06:23.662720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async for chunk in llm_with_tools.astream(query):\n",
    "    print(chunk.tool_call_chunks)"
   ],
   "id": "2ff8b9ecedb0b5ad",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'name': 'Multiply', 'args': '', 'id': 'call_U4OQHBNj2sXG9LJgfkygmWKt', 'index': 0}]\n",
      "[{'name': None, 'args': '{\"a\"', 'id': None, 'index': 0}]\n",
      "[{'name': None, 'args': ': 3, ', 'id': None, 'index': 0}]\n",
      "[{'name': None, 'args': '\"b\": 1', 'id': None, 'index': 0}]\n",
      "[{'name': None, 'args': '2}', 'id': None, 'index': 0}]\n",
      "[{'name': 'Add', 'args': '', 'id': 'call_vzgujgEVypRTk6ycOyzzT05t', 'index': 1}]\n",
      "[{'name': None, 'args': '{\"a\"', 'id': None, 'index': 1}]\n",
      "[{'name': None, 'args': ': 11,', 'id': None, 'index': 1}]\n",
      "[{'name': None, 'args': ' \"b\": ', 'id': None, 'index': 1}]\n",
      "[{'name': None, 'args': '49}', 'id': None, 'index': 1}]\n",
      "[]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:26.680177Z",
     "start_time": "2024-07-18T04:06:24.874752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first = True\n",
    "async for chunk in llm_with_tools.astream(query):\n",
    "    if first:\n",
    "        gathered = chunk\n",
    "        first = False\n",
    "    else:\n",
    "        gathered = gathered + chunk\n",
    "\n",
    "    print(gathered.tool_call_chunks)"
   ],
   "id": "4a451a3ce23d94c3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'name': 'Multiply', 'args': '', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}]\n",
      "[{'name': 'Multiply', 'args': '{\"a\"', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}]\n",
      "[{'name': 'Multiply', 'args': '{\"a\": 3, ', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}]\n",
      "[{'name': 'Multiply', 'args': '{\"a\": 3, \"b\": 1', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}]\n",
      "[{'name': 'Multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}]\n",
      "[{'name': 'Multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}, {'name': 'Add', 'args': '', 'id': 'call_7OnQPGvdRRXbyYIMPKob0Jbn', 'index': 1}]\n",
      "[{'name': 'Multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}, {'name': 'Add', 'args': '{\"a\"', 'id': 'call_7OnQPGvdRRXbyYIMPKob0Jbn', 'index': 1}]\n",
      "[{'name': 'Multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}, {'name': 'Add', 'args': '{\"a\": 11,', 'id': 'call_7OnQPGvdRRXbyYIMPKob0Jbn', 'index': 1}]\n",
      "[{'name': 'Multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}, {'name': 'Add', 'args': '{\"a\": 11, \"b\": ', 'id': 'call_7OnQPGvdRRXbyYIMPKob0Jbn', 'index': 1}]\n",
      "[{'name': 'Multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}, {'name': 'Add', 'args': '{\"a\": 11, \"b\": 49}', 'id': 'call_7OnQPGvdRRXbyYIMPKob0Jbn', 'index': 1}]\n",
      "[{'name': 'Multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}, {'name': 'Add', 'args': '{\"a\": 11, \"b\": 49}', 'id': 'call_7OnQPGvdRRXbyYIMPKob0Jbn', 'index': 1}]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:26.684100Z",
     "start_time": "2024-07-18T04:06:26.681281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(type(gathered.tool_call_chunks[0]))\n",
    "print(gathered.tool_call_chunks[0])"
   ],
   "id": "166f6deb49418d9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'name': 'Multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_9yYoF74VeFBjybqScmXyhzA7', 'index': 0}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:27.753510Z",
     "start_time": "2024-07-18T04:06:26.684824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first = True\n",
    "async for chunk in llm_with_tools.astream(query):\n",
    "    if first:\n",
    "        gathered = chunk\n",
    "        first = False\n",
    "    else:\n",
    "        gathered = gathered + chunk\n",
    "\n",
    "    print(gathered.tool_calls)"
   ],
   "id": "f86006f2be1718e6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'name': 'Multiply', 'args': {}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}]\n",
      "[{'name': 'Multiply', 'args': {}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}]\n",
      "[{'name': 'Multiply', 'args': {'a': 3}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}]\n",
      "[{'name': 'Multiply', 'args': {'a': 3, 'b': 1}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}]\n",
      "[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}]\n",
      "[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}, {'name': 'Add', 'args': {}, 'id': 'call_mluQdWP54le5rYboGvZz543n'}]\n",
      "[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}, {'name': 'Add', 'args': {}, 'id': 'call_mluQdWP54le5rYboGvZz543n'}]\n",
      "[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}, {'name': 'Add', 'args': {'a': 11}, 'id': 'call_mluQdWP54le5rYboGvZz543n'}]\n",
      "[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}, {'name': 'Add', 'args': {'a': 11}, 'id': 'call_mluQdWP54le5rYboGvZz543n'}]\n",
      "[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}, {'name': 'Add', 'args': {'a': 11, 'b': 49}, 'id': 'call_mluQdWP54le5rYboGvZz543n'}]\n",
      "[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}, {'name': 'Add', 'args': {'a': 11, 'b': 49}, 'id': 'call_mluQdWP54le5rYboGvZz543n'}]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:28.140666Z",
     "start_time": "2024-07-18T04:06:28.138182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(type(gathered.tool_calls[0]))\n",
    "print(gathered.tool_calls[0])"
   ],
   "id": "57dc12aaa55095e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_tUJ3Kni8UBW1fdhgVHOaOpNx'}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Passing tool outputs to model",
   "id": "10d2e80a66e0cf97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:29.797862Z",
     "start_time": "2024-07-18T04:06:28.691943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))"
   ],
   "id": "d228183fb68e7d68",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:29.804532Z",
     "start_time": "2024-07-18T04:06:29.799753Z"
    }
   },
   "cell_type": "code",
   "source": "messages",
   "id": "99efcbf851b773f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_65AUsuXSCS9oB4WlGPw5bzp8', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'Multiply'}, 'type': 'function'}, {'id': 'call_CHiyDLA9cOQNwVwUXjrw8Biw', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'Add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 105, 'total_tokens': 155}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d77aaeb1-ba55-4b25-bd67-f504a854a0c1-0', tool_calls=[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_65AUsuXSCS9oB4WlGPw5bzp8', 'type': 'tool_call'}, {'name': 'Add', 'args': {'a': 11, 'b': 49}, 'id': 'call_CHiyDLA9cOQNwVwUXjrw8Biw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 105, 'output_tokens': 50, 'total_tokens': 155}),\n",
       " ToolMessage(content='36', tool_call_id='call_65AUsuXSCS9oB4WlGPw5bzp8'),\n",
       " ToolMessage(content='60', tool_call_id='call_CHiyDLA9cOQNwVwUXjrw8Biw')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:29.811982Z",
     "start_time": "2024-07-18T04:06:29.805976Z"
    }
   },
   "cell_type": "code",
   "source": "messages[-2:]",
   "id": "af0b5233209e6ed3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolMessage(content='36', tool_call_id='call_65AUsuXSCS9oB4WlGPw5bzp8'),\n",
       " ToolMessage(content='60', tool_call_id='call_CHiyDLA9cOQNwVwUXjrw8Biw')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:06:31.447518Z",
     "start_time": "2024-07-18T04:06:30.694357Z"
    }
   },
   "cell_type": "code",
   "source": "llm_with_tools.invoke(messages)",
   "id": "ac6d1041bdb26f12",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='3 * 12 is 36 and 11 + 49 is 60.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 171, 'total_tokens': 189}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-fc2dfd84-24f5-4db9-893c-e25037ab6116-0', usage_metadata={'input_tokens': 171, 'output_tokens': 18, 'total_tokens': 189})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Few-shot prompting",
   "id": "f59a202471caff6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:12:23.687121Z",
     "start_time": "2024-07-18T04:12:22.121764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Wrong answer\n",
    "llm_with_tools.invoke(\n",
    "    \"Whats 119 times 8 minus 20. Don't do any math yourself, only use tools for math. Respect order of operations\"\n",
    ").tool_calls"
   ],
   "id": "3901ba11be3fb17",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'Multiply',\n",
       "  'args': {'a': 119, 'b': 8},\n",
       "  'id': 'call_aXN8LMyObpM31FSVR3VxOVRV',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'Add',\n",
       "  'args': {'a': 952, 'b': -20},\n",
       "  'id': 'call_gS9UVJJsojvPrRlesmdt3WhN',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:13:16.500865Z",
     "start_time": "2024-07-18T04:13:15.657162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "examples = [\n",
    "    HumanMessage(\n",
    "        \"What's the product of 317253 and 128472 plus four\", name=\"example_user\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\"name\": \"Multiply\", \"args\": {\"x\": 317253, \"y\": 128472}, \"id\": \"1\"}\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"16505054784\", tool_call_id=\"1\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[{\"name\": \"Add\", \"args\": {\"x\": 16505054784, \"y\": 4}, \"id\": \"2\"}],\n",
    "    ),\n",
    "    ToolMessage(\"16505054788\", tool_call_id=\"2\"),\n",
    "    AIMessage(\n",
    "        \"The product of 317253 and 128472 plus four is 16505054788\",\n",
    "        name=\"example_assistant\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are bad at math but are an expert at using a calculator. \n",
    "\n",
    "Use past tool usage as an example of how to correctly use the tools.\"\"\"\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        *examples,\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = {\"query\": RunnablePassthrough()} | few_shot_prompt | llm_with_tools\n",
    "chain.invoke(\"Whats 119 times 8 minus 20\").tool_calls"
   ],
   "id": "1cf1114f39624be8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'Multiply',\n",
       "  'args': {'a': 119, 'b': 8},\n",
       "  'id': 'call_eMcwplZtUDDgoaAKGrMGXM03',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:14:14.998948Z",
     "start_time": "2024-07-18T04:14:14.102689Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke(\"Whats 119 times 8 minus 20\")",
   "id": "390388cbcfa38aae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_RjZgpRYfEaCyDgbjKNQ3J675', 'function': {'arguments': '{\"a\":119,\"b\":8}', 'name': 'Multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 243, 'total_tokens': 261}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c89e9ef0-797a-43cf-9910-81517e0af370-0', tool_calls=[{'name': 'Multiply', 'args': {'a': 119, 'b': 8}, 'id': 'call_RjZgpRYfEaCyDgbjKNQ3J675', 'type': 'tool_call'}], usage_metadata={'input_tokens': 243, 'output_tokens': 18, 'total_tokens': 261})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:41:31.180533Z",
     "start_time": "2024-07-18T04:41:31.177532Z"
    }
   },
   "cell_type": "code",
   "source": "# https://python.langchain.com/v0.2/docs/how_to/function_calling/",
   "id": "ef555fd8808bc553",
   "outputs": [],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
