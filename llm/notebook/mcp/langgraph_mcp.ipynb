{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-14T05:11:43.849632Z",
     "start_time": "2025-04-14T05:11:42.602885Z"
    }
   },
   "source": [
    "import re, os\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:11:58.042013Z",
     "start_time": "2025-04-14T05:11:58.011566Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "4b04896cce0e518c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:13:55.703574Z",
     "start_time": "2025-04-14T05:13:55.696551Z"
    }
   },
   "cell_type": "code",
   "source": "openai_api_key = os.getenv(\"OPENAI_API_KEY\")",
   "id": "664260f44985ad74",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T04:26:11.790296Z",
     "start_time": "2025-04-14T04:26:11.776694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_tokens(text, model=\"cl100k_base\"):\n",
    "    \"\"\"\n",
    "    Count the number of tokens in the text using tiktoken.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to count tokens for\n",
    "        model (str): The tokenizer model to use (default: cl100k_base for GPT-4)\n",
    "\n",
    "    Returns:\n",
    "        int: Number of tokens in the text\n",
    "    \"\"\"\n",
    "    encoder = tiktoken.get_encoding(model)\n",
    "    return len(encoder.encode(text))\n",
    "\n",
    "def bs4_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    # Target the main article content for LangGraph documentation\n",
    "    main_content = soup.find(\"article\", class_=\"md-content__inner\")\n",
    "\n",
    "    # If found, use that, otherwise fall back to the whole document\n",
    "    content = main_content.get_text() if main_content else soup.text\n",
    "\n",
    "    # Clean up whitespace\n",
    "    content = re.sub(r\"\\n\\n+\", \"\\n\\n\", content).strip()\n",
    "\n",
    "    return content\n",
    "\n",
    "def load_langgraph_docs():\n",
    "    \"\"\"\n",
    "    Load LangGraph documentation from the official website.\n",
    "\n",
    "    This function:\n",
    "    1. Uses RecursiveUrlLoader to fetch pages from the LangGraph website\n",
    "    2. Counts the total documents and tokens loaded\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Document objects containing the loaded content\n",
    "        list: A list of tokens per document\n",
    "    \"\"\"\n",
    "    print(\"Loading LangGraph documentation...\")\n",
    "\n",
    "    # Load the documentation\n",
    "    urls = [\"https://langchain-ai.github.io/langgraph/concepts/\",\n",
    "     \"https://langchain-ai.github.io/langgraph/how-tos/\",\n",
    "     \"https://langchain-ai.github.io/langgraph/tutorials/workflows/\",\n",
    "     \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\",\n",
    "     \"https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/\",\n",
    "    ]\n",
    "\n",
    "    docs = []\n",
    "    for url in urls:\n",
    "\n",
    "        loader = RecursiveUrlLoader(\n",
    "            url,\n",
    "            max_depth=5,\n",
    "            extractor=bs4_extractor,\n",
    "        )\n",
    "\n",
    "        # Load documents using lazy loading (memory efficient)\n",
    "        docs_lazy = loader.lazy_load()\n",
    "\n",
    "        # Load documents and track URLs\n",
    "        for d in docs_lazy:\n",
    "            docs.append(d)\n",
    "\n",
    "    print(f\"Loaded {len(docs)} documents from LangGraph documentation.\")\n",
    "    print(\"\\nLoaded URLs:\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"{i+1}. {doc.metadata.get('source', 'Unknown URL')}\")\n",
    "\n",
    "    # Count total tokens in documents\n",
    "    total_tokens = 0\n",
    "    tokens_per_doc = []\n",
    "    for doc in docs:\n",
    "        total_tokens += count_tokens(doc.page_content)\n",
    "        tokens_per_doc.append(count_tokens(doc.page_content))\n",
    "    print(f\"Total tokens in loaded documents: {total_tokens}\")\n",
    "\n",
    "    return docs, tokens_per_doc\n",
    "\n",
    "def save_llms_full(documents):\n",
    "    \"\"\" Save the documents to a file \"\"\"\n",
    "\n",
    "    # Open the output file\n",
    "    output_filename = \"llms_full.txt\"\n",
    "\n",
    "    with open(output_filename, \"w\") as f:\n",
    "        # Write each document\n",
    "        for i, doc in enumerate(documents):\n",
    "            # Get the source (URL) from metadata\n",
    "            source = doc.metadata.get('source', 'Unknown URL')\n",
    "\n",
    "            # Write the document with proper formatting\n",
    "            f.write(f\"DOCUMENT {i+1}\\n\")\n",
    "            f.write(f\"SOURCE: {source}\\n\")\n",
    "            f.write(\"CONTENT:\\n\")\n",
    "            f.write(doc.page_content)\n",
    "            f.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")\n",
    "\n",
    "    print(f\"Documents concatenated into {output_filename}\")\n",
    "\n",
    "def split_documents(documents):\n",
    "    \"\"\"\n",
    "    Split documents into smaller chunks for improved retrieval.\n",
    "\n",
    "    This function:\n",
    "    1. Uses RecursiveCharacterTextSplitter with tiktoken to create semantically meaningful chunks\n",
    "    2. Ensures chunks are appropriately sized for embedding and retrieval\n",
    "    3. Counts the resulting chunks and their total tokens\n",
    "\n",
    "    Args:\n",
    "        documents (list): List of Document objects to split\n",
    "\n",
    "    Returns:\n",
    "        list: A list of split Document objects\n",
    "    \"\"\"\n",
    "    print(\"Splitting documents...\")\n",
    "\n",
    "    # Initialize text splitter using tiktoken for accurate token counting\n",
    "    # chunk_size=8,000 creates relatively large chunks for comprehensive context\n",
    "    # chunk_overlap=500 ensures continuity between chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=8000,\n",
    "        chunk_overlap=500\n",
    "    )\n",
    "\n",
    "    # Split documents into chunks\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    print(f\"Created {len(split_docs)} chunks from documents.\")\n",
    "\n",
    "    # Count total tokens in split documents\n",
    "    total_tokens = 0\n",
    "    for doc in split_docs:\n",
    "        total_tokens += count_tokens(doc.page_content)\n",
    "\n",
    "    print(f\"Total tokens in split documents: {total_tokens}\")\n",
    "\n",
    "    return split_docs\n",
    "\n",
    "def create_vectorstore(splits):\n",
    "    \"\"\"\n",
    "    Create a vector store from document chunks using SKLearnVectorStore.\n",
    "\n",
    "    This function:\n",
    "    1. Initializes an embedding model to convert text into vector representations\n",
    "    2. Creates a vector store from the document chunks\n",
    "\n",
    "    Args:\n",
    "        splits (list): List of split Document objects to embed\n",
    "\n",
    "    Returns:\n",
    "        SKLearnVectorStore: A vector store containing the embedded documents\n",
    "    \"\"\"\n",
    "    print(\"Creating SKLearnVectorStore...\")\n",
    "\n",
    "    # Initialize OpenAI embeddings\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "    # Create vector store from documents using SKLearn\n",
    "    persist_path = os.getcwd()+\"/sklearn_vectorstore.parquet\"\n",
    "    vectorstore = SKLearnVectorStore.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=embeddings,\n",
    "        persist_path=persist_path   ,\n",
    "        serializer=\"parquet\",\n",
    "    )\n",
    "    print(\"SKLearnVectorStore created successfully.\")\n",
    "\n",
    "    vectorstore.persist()\n",
    "    print(\"SKLearnVectorStore was persisted to\", persist_path)\n",
    "\n",
    "    return vectorstore"
   ],
   "id": "6e5e3253ea9291a0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T04:27:05.643834Z",
     "start_time": "2025-04-14T04:26:12.847760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the documents\n",
    "documents, tokens_per_doc = load_langgraph_docs()"
   ],
   "id": "21f17664b6e1bba4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LangGraph documentation...\n",
      "Loaded 129 documents from LangGraph documentation.\n",
      "\n",
      "Loaded URLs:\n",
      "1. https://langchain-ai.github.io/langgraph/concepts/\n",
      "2. https://langchain-ai.github.io/langgraph/concepts/langgraph_control_plane/\n",
      "3. https://langchain-ai.github.io/langgraph/concepts/langgraph_data_plane/\n",
      "4. https://langchain-ai.github.io/langgraph/concepts/langgraph_data_plane/&\n",
      "5. https://langchain-ai.github.io/langgraph/concepts/sdk/\n",
      "6. https://langchain-ai.github.io/langgraph/concepts/langgraph_server/\n",
      "7. https://langchain-ai.github.io/langgraph/concepts/faq/\n",
      "8. https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/\n",
      "9. https://langchain-ai.github.io/langgraph/concepts/langgraph_cli/\n",
      "10. https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/\n",
      "11. https://langchain-ai.github.io/langgraph/concepts/langgraph_self_hosted_control_plane/\n",
      "12. https://langchain-ai.github.io/langgraph/concepts/langgraph_cloud/\n",
      "13. https://langchain-ai.github.io/langgraph/concepts/langgraph_self_hosted_data_plane/\n",
      "14. https://langchain-ai.github.io/langgraph/concepts/langgraph_standalone_container/\n",
      "15. https://langchain-ai.github.io/langgraph/concepts/auth/\n",
      "16. https://langchain-ai.github.io/langgraph/concepts/application_structure/\n",
      "17. https://langchain-ai.github.io/langgraph/concepts/double_texting/\n",
      "18. https://langchain-ai.github.io/langgraph/concepts/assistants/\n",
      "19. https://langchain-ai.github.io/langgraph/concepts/platform_architecture/\n",
      "20. https://langchain-ai.github.io/langgraph/concepts/persistence/\n",
      "21. https://langchain-ai.github.io/langgraph/concepts/template_applications/\n",
      "22. https://langchain-ai.github.io/langgraph/concepts/deployment_options/\n",
      "23. https://langchain-ai.github.io/langgraph/concepts/plans/\n",
      "24. https://langchain-ai.github.io/langgraph/concepts/langgraph_control_plane/&\n",
      "25. https://langchain-ai.github.io/langgraph/concepts/breakpoints/\n",
      "26. https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/\n",
      "27. https://langchain-ai.github.io/langgraph/concepts/breakpoints\n",
      "28. https://langchain-ai.github.io/langgraph/concepts/time-travel/\n",
      "29. https://langchain-ai.github.io/langgraph/concepts/functional_api/\n",
      "30. https://langchain-ai.github.io/langgraph/concepts/pregel/\n",
      "31. https://langchain-ai.github.io/langgraph/concepts/streaming/\n",
      "32. https://langchain-ai.github.io/langgraph/concepts/multi_agent/\n",
      "33. https://langchain-ai.github.io/langgraph/concepts/memory/\n",
      "34. https://langchain-ai.github.io/langgraph/concepts/low_level/\n",
      "35. https://langchain-ai.github.io/langgraph/concepts/durable_execution/\n",
      "36. https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/\n",
      "37. https://langchain-ai.github.io/langgraph/concepts/high_level/\n",
      "38. https://langchain-ai.github.io/langgraph/concepts/v0-human-in-the-loop/\n",
      "39. https://langchain-ai.github.io/langgraph/concepts/scalability_and_resilience/\n",
      "40. https://langchain-ai.github.io/langgraph/how-tos/\n",
      "41. https://langchain-ai.github.io/langgraph/how-tos/review-tool-calls-functional/\n",
      "42. https://langchain-ai.github.io/langgraph/how-tos/streaming/\n",
      "43. https://langchain-ai.github.io/langgraph/how-tos/streaming-subgraphs/\n",
      "44. https://langchain-ai.github.io/langgraph/how-tos/subgraph\n",
      "45. https://langchain-ai.github.io/langgraph/how-tos/streaming-events-from-within-tools/\n",
      "46. https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/\n",
      "47. https://langchain-ai.github.io/langgraph/how-tos/disable-streaming/\n",
      "48. https://langchain-ai.github.io/langgraph/how-tos/streaming-specific-nodes/\n",
      "49. https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens\n",
      "50. https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/dynamic_breakpoints/\n",
      "51. https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/\n",
      "52. https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/\n",
      "53. https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/\n",
      "54. https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/\n",
      "55. https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/review-tool-calls/\n",
      "56. https://langchain-ai.github.io/langgraph/how-tos/wait-user-input-functional/\n",
      "57. https://langchain-ai.github.io/langgraph/how-tos/memory/semantic-search/\n",
      "58. https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch-functional\n",
      "59. https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch-functional/\n",
      "60. https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-structured-output/\n",
      "61. https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-system-prompt/\n",
      "62. https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-memory/\n",
      "63. https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/\n",
      "64. https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-manage-message-history/\n",
      "65. https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-hitl/\n",
      "66. https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/\n",
      "67. https://langchain-ai.github.io/langgraph/how-tos/subgraph/\n",
      "68. https://langchain-ai.github.io/langgraph/how-tos/many-tools/\n",
      "69. https://langchain-ai.github.io/langgraph/how-tos/update-state-from-tools/\n",
      "70. https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/\n",
      "71. https://langchain-ai.github.io/langgraph/how-tos/pass-config-to-tools/\n",
      "72. https://langchain-ai.github.io/langgraph/how-tos/tool-calling-errors/\n",
      "73. https://langchain-ai.github.io/langgraph/how-tos/tool-calling/\n",
      "74. https://langchain-ai.github.io/langgraph/how-tos/subgraph-transform-state/\n",
      "75. https://langchain-ai.github.io/langgraph/how-tos/agent-handoffs/\n",
      "76. https://langchain-ai.github.io/langgraph/how-tos/command\n",
      "77. https://langchain-ai.github.io/langgraph/how-tos/multi-agent-network-functional/\n",
      "78. https://langchain-ai.github.io/langgraph/how-tos/multi-agent-network/\n",
      "79. https://langchain-ai.github.io/langgraph/how-tos/multi-agent-multi-turn-convo/\n",
      "80. https://langchain-ai.github.io/langgraph/how-tos/multi-agent-multi-turn-convo-functional/\n",
      "81. https://langchain-ai.github.io/langgraph/how-tos/subgraphs-manage-state/\n",
      "82. https://langchain-ai.github.io/langgraph/how-tos/subgraph-persistence\n",
      "83. https://langchain-ai.github.io/langgraph/how-tos/memory/add-summary-conversation-history/\n",
      "84. https://langchain-ai.github.io/langgraph/how-tos/memory/manage-conversation-history/\n",
      "85. https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence-functional/\n",
      "86. https://langchain-ai.github.io/langgraph/how-tos/subgraph-persistence/\n",
      "87. https://langchain-ai.github.io/langgraph/how-tos/persistence_redis/\n",
      "88. https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence\n",
      "89. https://langchain-ai.github.io/langgraph/how-tos/persistence_postgres/\n",
      "90. https://langchain-ai.github.io/langgraph/how-tos/persistence-functional/\n",
      "91. https://langchain-ai.github.io/langgraph/how-tos/persistence_mongodb/\n",
      "92. https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence/\n",
      "93. https://langchain-ai.github.io/langgraph/how-tos/persistence/\n",
      "94. https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/\n",
      "95. https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages\n",
      "96. https://langchain-ai.github.io/langgraph/how-tos/add-summary-conversation-history/\n",
      "97. https://langchain-ai.github.io/langgraph/how-tos/manage-conversation-history/\n",
      "98. https://langchain-ai.github.io/langgraph/how-tos/memory/\n",
      "99. https://langchain-ai.github.io/langgraph/how-tos/semantic-search/\n",
      "100. https://langchain-ai.github.io/langgraph/how-tos/use-remote-graph/\n",
      "101. https://langchain-ai.github.io/langgraph/how-tos/return-when-recursion-limit-hits/\n",
      "102. https://langchain-ai.github.io/langgraph/how-tos/configuration/\n",
      "103. https://langchain-ai.github.io/langgraph/how-tos/node-retries/\n",
      "104. https://langchain-ai.github.io/langgraph/how-tos/map-reduce/\n",
      "105. https://langchain-ai.github.io/langgraph/how-tos/command/\n",
      "106. https://langchain-ai.github.io/langgraph/how-tos/recursion-limit/\n",
      "107. https://langchain-ai.github.io/langgraph/how-tos/visualization/\n",
      "108. https://langchain-ai.github.io/langgraph/how-tos/state-reducers/\n",
      "109. https://langchain-ai.github.io/langgraph/how-tos/branching/\n",
      "110. https://langchain-ai.github.io/langgraph/how-tos/sequence/\n",
      "111. https://langchain-ai.github.io/langgraph/how-tos/http/custom_lifespan/\n",
      "112. https://langchain-ai.github.io/langgraph/how-tos/http/custom_middleware/\n",
      "113. https://langchain-ai.github.io/langgraph/how-tos/http/custom_routes/\n",
      "114. https://langchain-ai.github.io/langgraph/how-tos/state-model/\n",
      "115. https://langchain-ai.github.io/langgraph/how-tos/input_output_schema/\n",
      "116. https://langchain-ai.github.io/langgraph/how-tos/pass_private_state/\n",
      "117. https://langchain-ai.github.io/langgraph/how-tos/async/\n",
      "118. https://langchain-ai.github.io/langgraph/how-tos/auth/custom_auth/\n",
      "119. https://langchain-ai.github.io/langgraph/how-tos/react-agent-structured-output/\n",
      "120. https://langchain-ai.github.io/langgraph/how-tos/autogen-integration/\n",
      "121. https://langchain-ai.github.io/langgraph/how-tos/autogen-integration-functional/\n",
      "122. https://langchain-ai.github.io/langgraph/how-tos/run-id-langsmith/\n",
      "123. https://langchain-ai.github.io/langgraph/how-tos/local-studio/\n",
      "124. https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/\n",
      "125. https://langchain-ai.github.io/langgraph/how-tos/ttl/configure_ttl/\n",
      "126. https://langchain-ai.github.io/langgraph/how-tos/auth/openapi_security/\n",
      "127. https://langchain-ai.github.io/langgraph/tutorials/workflows/\n",
      "128. https://langchain-ai.github.io/langgraph/tutorials/introduction/\n",
      "129. https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/\n",
      "Total tokens in loaded documents: 301950\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T04:27:40.560675Z",
     "start_time": "2025-04-14T04:27:40.536188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the documents to a file\n",
    "save_llms_full(documents)"
   ],
   "id": "3584ad392e286fe3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents concatenated into llms_full.txt\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T04:27:42.159940Z",
     "start_time": "2025-04-14T04:27:41.681953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the documents\n",
    "split_docs = split_documents(documents)"
   ],
   "id": "63487999278ba736",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting documents...\n",
      "Created 141 chunks from documents.\n",
      "Total tokens in split documents: 304641\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T04:27:54.330256Z",
     "start_time": "2025-04-14T04:27:43.991511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the vector store\n",
    "vectorstore = create_vectorstore(split_docs)"
   ],
   "id": "64671f1da08cd5fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SKLearnVectorStore...\n",
      "SKLearnVectorStore created successfully.\n",
      "SKLearnVectorStore was persisted to /Users/may/TechLearning/generative_ai/llm/notebook/mcp/sklearn_vectorstore.parquet\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T04:28:13.591865Z",
     "start_time": "2025-04-14T04:28:12.557751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create retriever to get relevant documents (k=3 means return top 3 matches)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Get relevant documents for the query\n",
    "query = \"What is LangGraph?\"\n",
    "relevant_docs = retriever.invoke(query)\n",
    "print(f\"Retrieved {len(relevant_docs)} relevant documents\")\n",
    "\n",
    "for d in relevant_docs:\n",
    "    print(d.metadata['source'])\n",
    "    print(d.page_content[0:500])\n",
    "    print(\"\\n--------------------------------\\n\")"
   ],
   "id": "769e1762c6ffa4d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 relevant documents\n",
      "https://langchain-ai.github.io/langgraph/concepts/high_level/\n",
      "Why LangGraph?¶\n",
      "LLM applications¶\n",
      "LLMs make it possible to embed intelligence into a new class of applications. There are many patterns for building applications that use LLMs. Workflows have scaffolding of predefined code paths around LLM calls. LLMs can direct the control flow through these predefined code paths, which some consider to be an \"agentic system\". In other cases, it's possible to remove this scaffolding, creating autonomous agents that can plan, take actions via tool calls, and dir\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "https://langchain-ai.github.io/langgraph/concepts/faq/\n",
      "FAQ¶\n",
      "Common questions and their answers!\n",
      "Do I need to use LangChain to use LangGraph? What’s the difference?¶\n",
      "No. LangGraph is an orchestration framework for complex agentic systems and is more low-level and controllable than LangChain agents. LangChain provides a standard interface to interact with models and other components, useful for straight-forward chains and retrieval flows.\n",
      "How is LangGraph different from other agent frameworks?¶\n",
      "Other agentic frameworks can work for simple, generic tas\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/\n",
      "LangGraph Platform¶\n",
      "Watch this 4-minute overview of LangGraph Platform to see how it helps you build, deploy, and evaluate agentic applications.\n",
      "\n",
      "Overview¶\n",
      "LangGraph Platform is a commercial solution for deploying agentic applications to production, built on the open-source LangGraph framework.\n",
      "The LangGraph Platform consists of several components that work together to support the development, deployment, debugging, and monitoring of LangGraph applications:\n",
      "\n",
      "LangGraph Server: The server defines \n",
      "\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:12:06.741068Z",
     "start_time": "2025-04-14T05:12:06.734454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tool(parse_docstring=True)\n",
    "def langgraph_query_tool(query: str):\n",
    "    \"\"\"\n",
    "    Query the LangGraph documentation using a retriever.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query to search the documentation with\n",
    "\n",
    "    Returns:\n",
    "        str: A str of the retrieved documents\n",
    "    \"\"\"\n",
    "    retriever = SKLearnVectorStore(\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-large\"),\n",
    "    persist_path=os.getcwd()+\"/sklearn_vectorstore.parquet\",\n",
    "    serializer=\"parquet\").as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "    relevant_docs = retriever.invoke(query)\n",
    "    print(f\"Retrieved {len(relevant_docs)} relevant documents\")\n",
    "    formatted_context = \"\\n\\n\".join([f\"==DOCUMENT {i+1}==\\n{doc.page_content}\" for i, doc in enumerate(relevant_docs)])\n",
    "    return formatted_context"
   ],
   "id": "90157812deeafb6c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:12:09.473634Z",
     "start_time": "2025-04-14T05:12:07.960615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "augmented_llm = llm.bind_tools([langgraph_query_tool])\n",
    "\n",
    "instructions = \"\"\"You are a helpful assistant that can answer questions about the LangGraph documentation.\n",
    "Use the langgraph_query_tool for any questions about the documentation.\n",
    "If you don't know the answer, say \"I don't know.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": instructions},\n",
    "    {\"role\": \"user\", \"content\": \"What is LangGraph?\"}\n",
    "]\n",
    "\n",
    "message = augmented_llm.invoke(messages)\n",
    "message.pretty_print()"
   ],
   "id": "119275f8fa6be83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  langgraph_query_tool (call_TYngJCABn3qTh8OXlVQURl86)\n",
      " Call ID: call_TYngJCABn3qTh8OXlVQURl86\n",
      "  Args:\n",
      "    query: What is LangGraph?\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MCP",
   "id": "2a6d217ca743d2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:12:12.544517Z",
     "start_time": "2025-04-14T05:12:12.542270Z"
    }
   },
   "cell_type": "code",
   "source": "# npx @modelcontextprotocol/inspector",
   "id": "e307e8dd1f026551",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:12:16.622622Z",
     "start_time": "2025-04-14T05:12:16.618865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_path = os.getcwd()\n",
    "user_home_path = os.path.expanduser(\"~\")"
   ],
   "id": "a90e62d3b3455099",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:22:30.226616Z",
     "start_time": "2025-04-14T05:22:30.197191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "command = f\"{user_home_path}/.virtualenvs/generative_ai/bin/python3\"\n",
    "documents_sever_stdio = f\"{current_path}/langgraph-mcp-stdio.py\""
   ],
   "id": "6ac265fadb8ca299",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:25:18.363739Z",
     "start_time": "2025-04-14T05:25:11.846505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        # \"documents-stdio\": {\n",
    "        #     \"command\": command,\n",
    "        #     \"args\": [documents_sever_stdio],\n",
    "        #     \"env\": {\n",
    "        #         \"OPENAI_API_KEY\": openai_api_key,\n",
    "        #     },\n",
    "        #     \"transport\": \"stdio\",\n",
    "        # },\n",
    "        \"documents-sse\": {\n",
    "            \"url\": \"http://localhost:8000/sse\",\n",
    "            # \"env\": {\n",
    "            #     \"OPENAI_API_KEY\": openai_api_key,\n",
    "            # },\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    agent = create_react_agent(model, client.get_tools())\n",
    "    documents_response = await agent.ainvoke({\"messages\": \"what is LangGraph?\"})"
   ],
   "id": "fc9d8f48666693fe",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:19:23.632974Z",
     "start_time": "2025-04-14T05:19:23.629420Z"
    }
   },
   "cell_type": "code",
   "source": "print(documents_response)",
   "id": "899fbad82f861be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='what is LangGraph?', additional_kwargs={}, response_metadata={}, id='8a8d7d35-d63b-40ca-955d-00a1223b3120'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4qdGXMOYZdgBYAWlYOPnmnCa', 'function': {'arguments': '{\"query\":\"LangGraph\"}', 'name': 'langgraph_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 80, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa860cbac8', 'id': 'chatcmpl-BM6W00nyqUZ93MhMXzsvw3r6OSqCg', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4316eec3-e603-4c69-ba35-db18ea31be1a-0', tool_calls=[{'name': 'langgraph_query_tool', 'args': {'query': 'LangGraph'}, 'id': 'call_4qdGXMOYZdgBYAWlYOPnmnCa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 80, 'output_tokens': 18, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"Error: ToolException('Error executing tool langgraph_query_tool: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable')\\n Please fix your mistakes.\", name='langgraph_query_tool', id='a8fa5350-da79-4601-ae4a-6747b3fbd164', tool_call_id='call_4qdGXMOYZdgBYAWlYOPnmnCa', status='error'), AIMessage(content='It seems there was an issue accessing the LangGraph documentation. However, I can provide a general idea based on my training data.\\n\\nLangGraph is typically a framework or tool used for natural language processing (NLP) and understanding. It might involve graph-based methods to represent and process language data, enabling more efficient querying, analysis, and manipulation of text. If you have specific questions about LangGraph, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 152, 'total_tokens': 239, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa860cbac8', 'id': 'chatcmpl-BM6W04LEYSbtdEofPmjbHKdNNIE1y', 'finish_reason': 'stop', 'logprobs': None}, id='run-d9a06bfc-55c6-4983-8d39-d9b9eadf9c41-0', usage_metadata={'input_tokens': 152, 'output_tokens': 87, 'total_tokens': 239, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T05:25:38.975499Z",
     "start_time": "2025-04-14T05:25:32.340957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"documents-stdio\": {\n",
    "            \"command\": command,\n",
    "            \"args\": [documents_sever_stdio],\n",
    "            \"env\": {\n",
    "                \"OPENAI_API_KEY\": openai_api_key,\n",
    "            },\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        # \"documents-sse\": {\n",
    "        #     \"url\": \"http://localhost:8000/sse\",\n",
    "            # \"env\": {\n",
    "            #     \"OPENAI_API_KEY\": openai_api_key,\n",
    "            # },\n",
    "            # \"transport\": \"sse\",\n",
    "        # }\n",
    "    }\n",
    ") as client:\n",
    "    agent = create_react_agent(model, client.get_tools())\n",
    "    documents_response = await agent.ainvoke({\"messages\": \"what is LangGraph?\"})"
   ],
   "id": "be3de7e4ff9be9ac",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8c9bf74540bb1c54"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
